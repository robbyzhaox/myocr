{"config":{"lang":["en","zh"],"separator":"[\\s\\u200b\\-_,:!=\\[\\: )\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MyOCR Documentation","text":"<p>MyOCR is a highly extensible and customizable framework for streamline development and deployment of production-ready OCR systems.</p> <p>MyOCR makes it easy to train your custom models and seamlessly integrate them into your own OCR pipeline.</p>"},{"location":"#key-features","title":"Key Features","text":"<p>\u26a1\ufe0f End-to-End OCR Development Framework \u2013 Designed for developers to build and integrate detection, recognition and custom OCR models in a unified and flexible pipeline.</p> <p>\ud83d\udee0\ufe0f Modular &amp; Extensible \u2013 Mix and match components - swap models, predictors, or input output processors with minimal changes.</p> <p>\ud83d\udd0c Developer-Friendly by Design - Clean Python APIs, prebuilt pipelines and processors, and straightforward customization for training and inference.</p> <p>\ud83d\ude80 Production-Ready Performance \u2013 ONNX runtime support for fast CPU/GPU inference, support various ways of deployment.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Installation: Set up MyOCR and download necessary models.</li> <li>Overview: Understand the core concepts (Models, Predictors, Pipelines) for building your OCR capabilities.</li> <li>Inference Guide: Learn how to run OCR tasks using MyOCR.</li> </ol>"},{"location":"#core-concepts","title":"Core Concepts","text":"<ul> <li>Models: Learn about the supported model types (ONNX, PyTorch, Custom) and architectures.</li> <li>Predictors: Understand how models are wrapped with input/output processors to <code>Predictor</code>.</li> <li>Pipelines: Explore the high-level pipelines that orchestrate predictors for end-to-end OCR.</li> </ul>"},{"location":"#additional-resources","title":"Additional Resources","text":"<ul> <li>FAQ: Find answers to common questions.</li> <li>Changelog: See recent updates and changes.</li> <li>Contributing Guidelines: Learn how to contribute to the project.</li> <li>GitHub Repository: Source code, issues, and discussions.</li> </ul>"},{"location":"#license","title":"License","text":"<p>MyOCR is open-sourced under the Apache 2.0 License.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#v011-2025-05-17","title":"v0.1.1 - 2025-05-17","text":""},{"location":"CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Fix error and optimize code for structured output pipeline</li> </ul>"},{"location":"CHANGELOG/#v010-2025-05-14","title":"v0.1.0 - 2025-05-14","text":""},{"location":"CHANGELOG/#changed_1","title":"Changed","text":"<ul> <li>Optimize the code to cope with situations of no text detection</li> <li>Polish documentation for release</li> </ul>"},{"location":"CHANGELOG/#v010-beta-2025-05-12","title":"v0.1.0-beta - 2025-05-12","text":""},{"location":"CHANGELOG/#added","title":"Added","text":"<ul> <li>Unify data structure of OCR result</li> </ul>"},{"location":"CHANGELOG/#changed_2","title":"Changed","text":"<ul> <li>Refactoring CommonOCRPipeline to use the new type OCRResult</li> <li>Polish code for CommonOCRPipeline &amp; HTTP endpoint</li> </ul>"},{"location":"CHANGELOG/#v010-alpha4-2025-05-08","title":"v0.1.0-alpha.4 - 2025-05-08","text":""},{"location":"CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>fixed recognized text confidence</li> </ul>"},{"location":"CHANGELOG/#v010-alpha3-2025-05-07","title":"v0.1.0-alpha.3 - 2025-05-07","text":""},{"location":"CHANGELOG/#fixed_1","title":"Fixed","text":"<ul> <li>fixed workflow for building docker image</li> </ul>"},{"location":"CHANGELOG/#v010-alpha2-2025-05-07","title":"v0.1.0-alpha.2 - 2025-05-07","text":""},{"location":"CHANGELOG/#added_1","title":"Added","text":"<ul> <li>add workflow for releasing docker image</li> <li>update readme</li> <li>add config for release doc manually</li> </ul>"},{"location":"CHANGELOG/#fixed_2","title":"Fixed","text":"<ul> <li>fixed char decode for black space</li> </ul>"},{"location":"CHANGELOG/#v010-alpha1-2025-05-06","title":"v0.1.0-alpha.1 - 2025-05-06","text":""},{"location":"CHANGELOG/#added_2","title":"Added","text":"<ul> <li>version check in releash.sh</li> <li>add demo url to readme</li> </ul>"},{"location":"CHANGELOG/#fixed_3","title":"Fixed","text":"<ul> <li>fix logging issue by moving logging config out from myocr package</li> </ul>"},{"location":"CHANGELOG/#v010-alpha-2025-05-04","title":"v0.1.0-alpha - 2025-05-04","text":""},{"location":"CONTRIBUTING/","title":"Contributing to MyOCR","text":"<p>Thank you for your interest in contributing to MyOCR! This document provides guidelines and instructions for contributing to this project.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating in this project, you agree to maintain a respectful and inclusive environment for everyone. Please be kind, considerate, and constructive in your communication.</p>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository: Create your own fork of the repository on GitHub.</li> <li>Clone your fork:     <pre><code>git clone https://github.com/your-username/myocr.git\ncd myocr\n</code></pre></li> <li>Add the upstream repository:    <pre><code>git remote add upstream https://github.com/robbyzhaox/myocr.git\n</code></pre></li> <li>Create a branch: Create a new branch for your work.    <pre><code>git checkout -b feature/your-feature-name\n</code></pre></li> </ol>"},{"location":"CONTRIBUTING/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Install dependencies:    <pre><code>pip install -e \".[dev]\"\n</code></pre>    This installs the package in development mode with all development dependencies.</p> </li> <li> <p>Set up pre-commit hooks (optional but recommended):    <pre><code>pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Keep changes focused: Each PR should address a specific feature, bug fix, or improvement.</li> <li>Update documentation: Ensure that documentation is updated to reflect your changes.</li> <li>Write tests: Add or update tests for the changes you've made.</li> <li>Run tests locally: Make sure all tests pass before submitting your PR.    <pre><code>pytest\n</code></pre></li> <li>Submit the PR: Push your changes to your fork and create a PR against the main repository.    <pre><code>git push origin feature/your-feature-name\n</code></pre></li> <li>PR Description: Provide a clear description of the changes and reference any related issues.</li> <li>Code Review: Be responsive to code review comments and make necessary adjustments.</li> </ol>"},{"location":"CONTRIBUTING/#coding-standards","title":"Coding Standards","text":"<p>We use several tools to enforce coding standards. The easiest way to ensure your code meets these standards is by using the provided Makefile commands:</p>"},{"location":"CONTRIBUTING/#development-utilities","title":"\ud83d\udce6 Development Utilities","text":"<p>MyOCR includes several Makefile commands to help with development:</p> <pre><code># Format code (runs isort, black, and ruff fix)\nmake run-format\n\n# Run code quality checks (isort, black, ruff, mypy, pytest)\nmake run-checks\n\n# Preview documentation in local\ncd documentation\nmkdocs serve -a 127.0.0.1:8001\n</code></pre> <p>If you prefer to run the tools individually:</p> <p>Black: For code formatting    <pre><code>black .\n</code></pre></p> <p>isort: For import sorting    <pre><code>isort .\n</code></pre></p> <p>Ruff: For linting    <pre><code>ruff check .\n</code></pre></p> <p>mypy: For type checking    <pre><code>mypy myocr\n</code></pre></p> <p>The configuration for these tools is in the <code>pyproject.toml</code> file.</p>"},{"location":"CONTRIBUTING/#testing-guidelines","title":"Testing Guidelines","text":"<ol> <li>Write unit tests: Write comprehensive tests for new features and bug fixes.</li> <li>Test Coverage: Aim for high test coverage for all new code.</li> <li>Test Directory Structure: </li> <li>Place tests in the <code>tests/</code> directory</li> <li>Follow the same directory structure as the source code</li> </ol>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<p>Good documentation is crucial for the project:</p> <ol> <li>Docstrings: Add docstrings to all public classes and functions.</li> <li>Example Usage: Include example usage in docstrings where appropriate.</li> <li>README Updates: Update the README if you add major features or change functionality.</li> <li>API Documentation: For significant additions, consider updating the API documentation.</li> </ol>"},{"location":"CONTRIBUTING/#building-documentation","title":"Building Documentation","text":"<p>You can build the documentation locally using:</p> <pre><code>cd documentation\nmkdocs build\n</code></pre> <p>This command will generate HTML documentation and start a local server to view it.</p>"},{"location":"CONTRIBUTING/#issue-reporting","title":"Issue Reporting","text":"<p>Before creating a new issue:</p> <ol> <li>Check existing issues: Make sure the issue hasn't already been reported.</li> <li>Provide information: Include detailed information about the problem:</li> <li>Steps to reproduce</li> <li>Expected behavior</li> <li>Actual behavior</li> <li>Environment (OS, Python version, etc.)</li> <li>Logs or error messages</li> <li>Use templates: If available, use the issue templates provided in the repository.</li> </ol>"},{"location":"CONTRIBUTING/#adding-new-features","title":"Adding New Features","text":"<p>When proposing new features:</p> <ol> <li>Discuss first: For major features, open an issue to discuss the feature before implementing it.</li> <li>Modular approach: Keep the modular architecture in mind when designing new features.</li> <li>Pipeline integration: Ensure that new components integrate well with the existing pipeline structure.</li> <li>Model compatibility: If adding new models, ensure they can be loaded with the existing ModelZoo system.</li> </ol>"},{"location":"CONTRIBUTING/#license","title":"License","text":"<p>By contributing to MyOCR, you agree that your contributions will be licensed under the project's  Apache 2.0 license.</p> <p>Thank you for contributing to MyOCR! Your efforts help make this project better for everyone. </p>"},{"location":"faq/","title":"FAQ - Frequently Asked Questions","text":""},{"location":"faq/#q-where-does-myocr-look-for-models-by-default","title":"Q: Where does MyOCR look for models by default?","text":"<p>A: The default path is configured in <code>myocr/config.py</code> (<code>MODEL_PATH</code>) and usually resolves to <code>~/.MyOCR/models/</code> on Linux/macOS. Pipeline configuration files (<code>myocr/pipelines/config/*.yaml</code>) reference model filenames relative to this directory. You can change <code>MODEL_PATH</code> or use absolute paths in the YAML configuration if you store models elsewhere.</p>"},{"location":"faq/#q-how-do-i-switch-between-cpu-and-gpu-inference","title":"Q: How do I switch between CPU and GPU inference?","text":"<p>A: When initializing pipelines or models, pass a <code>Device</code> object from <code>myocr.modeling.model</code>. </p> <ul> <li> <p>For GPU (assuming CUDA is set up): <code>Device('cuda:0')</code> (for the first GPU).</p> </li> <li> <p>For CPU: <code>Device('cpu')</code>.</p> </li> </ul> <p>Ensure you have the correct <code>onnxruntime</code> package installed (<code>onnxruntime</code> for CPU, <code>onnxruntime-gpu</code> for GPU) and compatible CUDA drivers for GPU usage.</p>"},{"location":"faq/#q-the-structuredoutputocrpipeline-isnt-working-or-gives-errors","title":"Q: The <code>StructuredOutputOCRPipeline</code> isn't working or gives errors.","text":"<p>A: This pipeline relies on an external Large Language Model (LLM).</p> <ol> <li> <p>Check Configuration: Ensure the <code>myocr/pipelines/config/structured_output_pipeline.yaml</code> file has the correct <code>model</code>, <code>base_url</code>, and <code>api_key</code> for your chosen LLM provider (e.g., OpenAI, Ollama, a local server).</p> </li> <li> <p>API Key: Make sure the API key is correctly specified (either directly in the YAML or via an environment variable if the YAML points to one, like <code>OPENAI_API_KEY</code>).</p> </li> <li> <p>Connectivity: Verify that your environment can reach the <code>base_url</code> specified for the LLM API.</p> </li> <li> <p>Schema: Ensure the Pydantic <code>json_schema</code> passed during initialization is valid and the descriptions guide the LLM effectively.</p> </li> </ol>"},{"location":"faq/#q-whats-the-difference-between-a-predictor-and-a-pipeline","title":"Q: What's the difference between a Predictor and a Pipeline?","text":"<p>A:</p> <ul> <li> <p>Predictor: A lower-level component that wraps a single <code>Model</code> with its specific pre-processing and post-processing logic (defined in a <code>CompositeProcessor</code>). It handles one specific task (e.g., text detection).</p> </li> <li> <p>Pipeline: A higher-level component that orchestrates multiple <code>Predictors</code> to perform a complete workflow (e.g., end-to-end OCR combining detection, classification, and recognition). Pipelines provide the main user-facing interface for common tasks.</p> </li> </ul>"},{"location":"faq/#q-how-can-i-use-my-own-custom-models","title":"Q: How can I use my own custom models?","text":"<p>A:</p> <ul> <li> <p>ONNX Models: Place your <code>.onnx</code> file in the model directory and update the relevant pipeline configuration YAML file (<code>myocr/pipelines/config/*.yaml</code>) to point to your model's filename. See the Overview section.</p> </li> <li> <p>Custom PyTorch Models: Define your model architecture using components from <code>myocr/modeling/</code> (backbones, necks, heads) and create a YAML configuration file specifying the architecture. Load it using <code>ModelLoader().load(model_format='custom', ...)</code> or create a custom pipeline/predictor. See the Models Documentation for details on <code>CustomModel</code> and YAML configuration.</p> </li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers the necessary steps to install MyOCR and its dependencies.</p>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python: Version 3.11 or higher is required.</li> <li>CUDA: Version 12.6 or higher is recommended for GPU acceleration. CPU-only mode is also supported.</li> <li>Operating System: Linux, macOS, or Windows.</li> </ul>"},{"location":"getting-started/installation/#installation-steps","title":"Installation Steps","text":"<ol> <li> <p>Clone the Repository:</p> <pre><code>git clone https://github.com/robbyzhaox/myocr.git\ncd myocr\n</code></pre> </li> <li> <p>Install Dependencies:</p> <ul> <li>For standard usage: <pre><code># Installs the package and required dependencies\npip install -e .\n</code></pre></li> <li>For development (including testing, linting, etc.): <pre><code># Installs standard dependencies plus development tools\npip install -e \".[dev]\"\n\n# Installs dependencies for documentation\npip install -e \".[docs]\"\n</code></pre></li> </ul> </li> <li> <p>Download Pre-trained Models:</p> <p>MyOCR relies on pre-trained models for its default pipelines. These need to be downloaded manually.</p> <pre><code># Create the default model directory if it doesn't exist\n# On Linux/macOS:\nmkdir -p ~/.MyOCR/models/\n# On Windows (using Git Bash or similar):\n# mkdir -p ~/AppData/Local/MyOCR/models/\n# or just create the models directory in current path\n# Note: Adjust the Windows path if needed based on your environment.\n\n# Download weights from following links to models directory: \n# https://drive.google.com/drive/folders/1RXppgx4XA_pBX9Ll4HFgWyhECh5JtHnY\n# or\n# https://pan.baidu.com/s/122p9zqepWfbEmZPKqkzGBA?pwd=yq6j\n</code></pre> <ul> <li>Note: The default location where MyOCR expects models is <code>~/.MyOCR/models/</code>. This path is defined in <code>myocr/config.py</code>. You can modify this configuration or place models elsewhere if needed, but you would need to adjust the paths in the pipeline configuration files (<code>myocr/pipelines/config/*.yaml</code>).</li> </ul> </li> </ol>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Once installation is complete and models are downloaded, you can proceed to:</p> <ul> <li>Inference Guide: See examples of how to run OCR tasks.</li> </ul>"},{"location":"getting-started/overview/","title":"Overview","text":"<p>MyOCR provides a powerful and flexible framework for building and deploying your own OCR pipelines. This library is designed with production readiness and developer experience in mind, it offers a high-level component architecture for easy integration and extension.</p>"},{"location":"getting-started/overview/#core-components","title":"Core Components","text":"<p>MyOCR is built around several key concepts:</p> <p></p> <ul> <li>Model: Represents a neural network model. MyOCR supports loading ONNX models (<code>OrtModel</code>), standard PyTorch models (<code>PyTorchModel</code>), and custom PyTorch models defined by YAML configurations (<code>CustomModel</code>). Models handle the core computation.<ul> <li>See the Models Section for more details.</li> </ul> </li> <li>Processor (<code>CompositeProcessor</code>): Prepares input data for a model and processes the model's raw output into a more usable format. Each predictor uses a specific processor.<ul> <li>See the Predictors Section for processor specifics.</li> </ul> </li> <li>Predictor: Combines a <code>Model</code> and a <code>Processor</code> to perform a specific inference task (e.g., text detection). It provides a user-friendly interface, accepting standard inputs (like PIL Images) and returning processed results (like bounding boxes).<ul> <li>See the Predictors Section for available predictors.</li> </ul> </li> <li>Pipeline: Orchestrates multiple <code>Predictors</code> to perform complex, multi-step tasks like end-to-end OCR. Pipelines offer the highest-level interface for most common use cases.<ul> <li>See the Pipelines Section for available pipelines.</li> </ul> </li> </ul> <p>Class Diagram </p>"},{"location":"getting-started/overview/#customization-and-extension","title":"Customization and Extension","text":"<p>MyOCR's modular design allows for easy customization:</p> <ul> <li>Adding New Models: Learn about the ways to introduce a new model by the model loader.</li> <li>Creating Custom Predictors: Learn about how to create a custom <code>Predictor</code> by <code>Model</code> and <code>CompositeProcessor</code>.</li> <li>Building Custom Pipelines: Learn how to Orchestrates multiple <code>Predictor</code>'s to <code>Pipeline</code></li> </ul>"},{"location":"inference/local/","title":"Local Inference","text":"<p>This section describes how to perform inference using the MyOCR library, primarily by utilizing the pre-defined pipelines.</p>"},{"location":"inference/local/#using-pipelines-for-inference","title":"Using Pipelines for Inference","text":"<p>The recommended way to perform end-to-end OCR is through the pipeline classes provided in <code>myocr.pipelines</code>. These pipelines handle the loading of necessary models and the orchestration of detection, classification, and recognition steps.</p>"},{"location":"inference/local/#standard-ocr-with-commonocrpipeline","title":"Standard OCR with <code>CommonOCRPipeline</code>","text":"<p>This pipeline is suitable for general OCR tasks where the goal is to extract all text and its location from an image.</p> <pre><code>from myocr.pipelines import CommonOCRPipeline\n\n# Initialize common OCR pipeline (using GPU)\npipeline = CommonOCRPipeline(\"cuda:0\")  # Use \"cpu\" for CPU mode\n\n# Perform OCR recognition on an image\nresult = pipeline(\"path/to/your/image.jpg\")\nprint(result)\n</code></pre>"},{"location":"inference/local/#structured-data-extraction-with-structuredoutputocrpipeline","title":"Structured Data Extraction with <code>StructuredOutputOCRPipeline</code>","text":"<p>This pipeline is used when you need to extract specific information from a document and format it as JSON, based on a predefined schema.</p> <p>config chat_bot in myocr.pipelines.config.structured_output_pipeline.yaml <pre><code>chat_bot:\n  model: qwen2.5:14b\n  base_url: http://127.0.0.1:11434/v1\n  api_key: 'key'\n</code></pre></p> <pre><code>from pydantic import BaseModel, Field\nfrom myocr.pipelines import StructuredOutputOCRPipeline\n\n# Define output data model, refer to:\nfrom myocr.pipelines.response_format import InvoiceModel\n\n# Initialize structured OCR pipeline\npipeline = StructuredOutputOCRPipeline(\"cuda:0\", InvoiceModel)\n\n# Process image and get structured data\nresult = pipeline(\"path/to/invoice.jpg\")\nprint(result.to_dict())\n</code></pre>"},{"location":"inference/local/#direct-predictor-usage-advanced","title":"Direct Predictor Usage (Advanced)","text":"<p>While pipelines are recommended, you can use individual predictors directly if you need more granular control over the process (e.g., using only detection, or providing pre-processed inputs). Refer to the Predictors section documentation for details on initializing and using each predictor/processor pair.</p>"},{"location":"inference/local/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Device Selection: Using a CUDA-enabled GPU (<code>Device('cuda:0')</code>) significantly speeds up inference compared to CPU (<code>Device('cpu')</code>). Ensure you have the necessary drivers and ONNX Runtime GPU build installed.</li> <li>Model Choice: The specific ONNX models configured in the pipeline YAML files impact performance and accuracy.</li> <li>Batch Processing: While the current pipeline examples process single images, predictors often handle batch inputs internally (e.g., processing all detected boxes simultaneously in recognition). For processing many images, consider parallel execution or batching at the application level if needed. </li> </ul>"},{"location":"inference/rest/","title":"Inference via REST API","text":"<p>MyOCR provides a built-in RESTful API service, allowing you to perform OCR tasks via HTTP requests. This is useful for integrating MyOCR into web applications, microservices, or accessing it from different programming languages.</p> <p>You can run this API service directly for development or deploy it using Docker for production.</p>"},{"location":"inference/rest/#option-1-running-directly-for-development","title":"Option 1: Running Directly (for Development)","text":"<p>This method runs the API service directly on your host machine, typically suitable for local development and testing.</p> <p>1. Prerequisites:</p> <ul> <li>Ensure you have completed the Installation steps, including installing dependencies and downloading models.</li> <li>Make sure you are in the root directory of the <code>myocr</code> project.</li> </ul> <p>2. Start the Server:</p> <pre><code># Start the server using python (check main.py for the exact host/port)\n# This might use a development server (e.g., Flask's default) and port (e.g., 5000).\npython main.py \n</code></pre> <ul> <li>The server uses the models and configurations defined within the project.</li> <li>The port and host depend on how <code>main.py</code> is configured.</li> <li>Note: For production deployments, using Docker with Gunicorn (Option 2) is recommended.</li> </ul> <p>3. API Endpoints (using example port 5000 - adjust if needed):</p> <ul> <li> <p><code>GET /ping</code>: Checks if the service is running.     <pre><code>curl http://127.0.0.1:5000/ping\n</code></pre></p> </li> <li> <p><code>POST /ocr</code>: Performs basic OCR on an uploaded image.</p> <ul> <li> <p>Request: Send a <code>POST</code> request with the image as base64 encoded string. <pre><code>curl -X POST \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"image\": \"BASE64_IMAGE\"}'' \\\n    http://127.0.0.1:5000/ocr\n</code></pre></p> </li> <li> <p>Response: Returns a JSON object containing the recognized text and bounding box information (similar to the output of <code>CommonOCRPipeline</code>).</p> </li> </ul> </li> <li> <p><code>POST /ocr-json</code>: Performs OCR and extracts structured information based on a schema.</p> <ul> <li>Request: Send a <code>POST</code> request with the image base64 string</li> </ul> <pre><code>curl -X POST \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"image\": \"BASE64_IMAGE\"}'' \\\n    http://127.0.0.1:5000/ocr-json\n</code></pre> <ul> <li>Response: Returns a JSON object matching the provided schema, populated with the extracted data.</li> </ul> </li> </ul> <p>4. Optional UI:</p> <p>A separate Next.js based UI is available for interacting with these endpoints: doc-insight-ui.</p>"},{"location":"inference/rest/#option-2-deploying-with-docker-recommended-for-production","title":"Option 2: Deploying with Docker (Recommended for Production)","text":"<p>Docker provides a containerized environment for running the API service, ensuring consistency and leveraging Gunicorn for performance.</p> <p>1. Prerequisites:</p> <ul> <li>Docker installed.</li> <li>For GPU support: NVIDIA Container Toolkit installed.</li> <li>Ensure models are downloaded to the default location (<code>~/.MyOCR/models/</code>) on the host machine before building the image, as the Docker build process might copy them.</li> </ul> <p>2. Build the Docker Image using the Helper Script:</p> <p>The recommended way to build the image is using the provided script. It handles tagging with the correct version.</p> <pre><code># Ensure the script is executable\nchmod +x scripts/build_docker_image.sh\n\n# Determine the application version\nVERSION=$(python -c 'import myocr.version; print(myocr.version.VERSION)')\n\n# Build the desired image (replace [cpu|gpu] with 'cpu' or 'gpu')\nbash scripts/build_docker_image.sh [cpu|gpu]\n\n# Example: Build the CPU image for the current version\n# bash scripts/build_docker_image.sh cpu \n\n# The script will output the final image tag (e.g., myocr:cpu-0.1.0)\n</code></pre> <p>3. Run the Docker Container:</p> <p>Use the image tag generated by the build script (e.g., <code>myocr:cpu-X.Y.Z</code> or <code>myocr:gpu-X.Y.Z</code>). The service inside the container runs on port 8000.</p> <p>Tip</p> <p>Set these environment variables if necessary:</p> <p>CHAT_BOT_MODEL=qwen2.5:14b</p> <p>CHAT_BOT_BASEURL=http://127.0.0.1:11434/v1</p> <p>CHAT_BOT_APIKEY=key</p> <ul> <li>GPU Version (replace $IMAGE_TAG with the actual tag): <pre><code># Example: docker run -d --gpus all -p 8000:8000 --name myocr-service myocr:gpu-0.1.0\ndocker run -d --gpus all -p 8000:8000 --name myocr-service $IMAGE_TAG\n</code></pre></li> <li>CPU Version (replace $IMAGE_TAG with the actual tag): <pre><code># Example: docker run -d -p 8000:8000 --name myocr-service myocr:cpu-0.1.0\ndocker run -d -p 8000:8000 --name myocr-service $IMAGE_TAG\n</code></pre></li> <li>The <code>-p 8000:8000</code> flag maps port 8000 on your host machine to port 8000 inside the container.</li> </ul> <p>4. Accessing API Endpoints (Docker):</p> <p>Once the container is running, access the API endpoints using the host machine's IP/hostname (or <code>localhost</code>) and the mapped host port (8000 in the examples):</p> <pre><code># Example Ping\ncurl http://localhost:8000/ping \n\n# Image base64 encode\nIMAGE_PATH=\"your_image.jpg\"\n\nBASE64_IMAGE=$(base64 -w 0 \"$IMAGE_PATH\")  # Linux\n#BASE64_IMAGE=$(base64 -i \"$IMAGE_PATH\" | tr -d '\\n') # macOS\n\n# Example Basic OCR\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"image\\\": \\\"${BASE64_IMAGE}\\\"}\" \\\n  http://localhost:8000/ocr\n\n# Example Structured OCR\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"image\\\": \\\"${BASE64_IMAGE}\\\"}\" \\\n  http://localhost:8000/ocr-json\n</code></pre> <p>Remember to replace <code>/path/to/your/image.jpg</code> with the actual path on the machine where you are running the <code>curl</code> command.</p>"},{"location":"models/","title":"Models","text":"<p>This section provides details about the deep learning models used within the MyOCR project for tasks like text detection, recognition, and direction classification.</p>"},{"location":"models/#model-loading-and-management","title":"Model Loading and Management","text":"<p>MyOCR utilizes a flexible model loading system defined in <code>myocr/modeling/model.py</code>. It supports loading models in different formats:</p> <ul> <li>ONNX (<code>OrtModel</code>): Loads and runs optimized models using the ONNX Runtime (<code>onnxruntime</code>). This is often preferred for inference due to performance benefits.</li> <li>PyTorch (<code>PyTorchModel</code>): Loads standard PyTorch models, potentially leveraging pre-defined architectures from libraries like <code>torchvision</code>.</li> <li>Custom PyTorch (<code>CustomModel</code>): Loads custom PyTorch models defined via YAML configuration files. These configurations specify the model's architecture, including backbones, necks, and heads, using components defined within <code>myocr/modeling/</code>.</li> </ul> <p>A <code>ModelLoader</code> class acts as a factory to instantiate the correct model type based on the specified format (<code>onnx</code>, <code>pt</code>, <code>custom</code>).</p> <pre><code># Example (Conceptual)\nfrom myocr.modeling.model import ModelLoader, Device\n\n# Load an ONNX model for CPU inference\nloader = ModelLoader()\nonnx_model = loader.load(model_format='onnx', model_name_path='path/to/your/model.onnx', device=Device('cpu'))\n\n# Load a custom model defined by YAML for GPU inference\ncustom_model = loader.load(model_format='custom', model_name_path='path/to/your/config.yaml', device=Device('cuda:0'))\n</code></pre>"},{"location":"models/#model-architectures","title":"Model Architectures","text":"<p>The <code>myocr/modeling/</code> directory houses the building blocks for custom models:</p> <ul> <li><code>architectures/</code>: Defines the overall structure connecting backbones, necks, and heads. (e.g., <code>DBNet</code>, <code>CRNN</code>).</li> <li><code>backbones/</code>: Contains feature extraction networks (e.g., <code>ResNet</code>, <code>MobileNetV3</code>).</li> <li><code>necks/</code>: Includes feature fusion modules (e.g., <code>FPN</code> - Feature Pyramid Network).</li> <li><code>heads/</code>: Defines the final layers responsible for specific tasks (e.g., detection probability maps, sequence decoding).</li> </ul>"},{"location":"models/#available-models","title":"Available Models","text":""},{"location":"models/#text-detection-dbnet","title":"Text Detection (DBNet++)","text":"<ul> <li>DBNet++: A state-of-the-art text detection model based on DBNet architecture</li> <li>Input: RGB image</li> <li>Output: Text region polygons</li> <li>Features:<ul> <li>High accuracy for arbitrary-shaped text</li> <li>Fast inference speed</li> <li>Robust to various text orientations</li> </ul> </li> <li>Architecture:     <pre><code>Backbone: ResNet\nNeck: FPN\nHead: DBHead\n</code></pre></li> </ul>"},{"location":"models/#text-recognition-crnn","title":"Text Recognition (CRNN)","text":"<ul> <li>CRNN: A hybrid CNN-RNN model for text recognition</li> <li>Input: Cropped text region</li> <li>Output: Recognized text</li> <li>Features:<ul> <li>Supports Chinese and English characters</li> <li>Handles variable-length text</li> <li>Robust to different fonts and styles</li> </ul> </li> <li>Architecture:     <pre><code>Backbone: CNN\nNeck: BiLSTM\nHead: CTC\n</code></pre></li> </ul>"},{"location":"models/#text-classification-models","title":"Text Classification Models","text":"<ul> <li>Text Direction Classifier: Determines text orientation</li> <li>Input: Text region</li> <li>Output: Orientation angle</li> <li>Features:<ul> <li>0\u00b0 and 180\u00b0 classification</li> <li>Helps improve recognition accuracy</li> </ul> </li> </ul>"},{"location":"models/#model-performance","title":"Model Performance","text":"<ul> <li>coming</li> </ul>"},{"location":"models/add-model/","title":"Adding New Models","text":"<p>MyOCR's modular design allows you to integrate new or custom models into the system. The process depends on the type of model you are adding.</p>"},{"location":"models/add-model/#option-1-adding-a-custom-pytorch-model-architecture-weights","title":"Option 1: Adding a Custom PyTorch Model (Architecture &amp; Weights)","text":"<p>If you have a custom model defined in PyTorch (using components potentially from <code>myocr.modeling</code> or external libraries), you can integrate it using MyOCR's custom model loading. This will be the powerful way to define your own model.</p> <ol> <li> <p>Define Model Architecture (if new):</p> <ul> <li>If your architecture isn't already defined, you might need to implement its components (e.g., new backbones, heads) following the structure within <code>myocr/modeling/</code>.</li> </ul> </li> <li> <p>Create YAML Configuration:</p> <ul> <li>Create a <code>.yaml</code> file that defines how your architecture components are connected. This file specifies the classes for the backbone, neck (optional), and head, along with their parameters.</li> <li>Optionally, include a <code>pretrained:</code> key pointing to a <code>.pth</code> file containing the trained weights for the entire model.</li> </ul> <pre><code># Example: config/my_custom_detector.yaml\nArchitecture:\n  model_type: det\n  backbone:\n    name: YourCustomBackbone # Class name under myocr.modeling.backbones\n    param1: value1\n  neck:\n    name: YourCustomNeck\n    param2: value2\n  head:\n    name: YourCustomHead\n    param3: value3\n\npretrained: /path/to/your/custom_model_weights.pth # Optional: Full model weights\n</code></pre> </li> <li> <p>Load the Custom Model:</p> <ul> <li>Use the <code>ModelLoader</code> or <code>CustomModel</code> class to load your model using its YAML configuration.</li> </ul> <pre><code>from myocr.modeling.model import ModelLoader, Device\n\nloader = ModelLoader()\ndevice = Device('cuda:0')\ncustom_model = loader.load(\n    model_format='custom',\n    model_name_path='config/my_custom_detector.yaml',\n    device=device\n)\n</code></pre> </li> <li> <p>Create Predictor (with appropriate Processor):</p> <ul> <li>You will likely need a <code>CompositeProcessor</code> that matches your custom model's input pre-processing and output post-processing needs. You might be able to reuse an existing one (e.g., <code>TextDetectionProcessor</code> if your output is similar) or you may need to create a custom processor class inheriting from <code>myocr.base.CompositeProcessor</code>.</li> </ul> <pre><code># Option A: Reuse existing processor (if compatible)\nfrom myocr.processors import TextDetectionProcessor\npredictor = custom_model.predictor(TextDetectionProcessor(custom_model.device))\n\n# Option B: Create and use a custom processor\n# from my_custom_processors import MyCustomProcessor \n# predictor = custom_model.predictor(MyCustomProcessor(...))\n</code></pre> </li> <li> <p>Integrate into a Pipeline (Optional):</p> <ul> <li>You can use your custom predictor directly or integrate it into a custom pipeline class that inherits from <code>myocr.base.Pipeline</code>.</li> </ul> </li> </ol>"},{"location":"models/add-model/#option-2-adding-a-pre-trained-onnx-model","title":"Option 2: Adding a Pre-trained ONNX Model","text":"<p>This is the simplest way, you only need to put your model file to the model directory and load the model by <code>ModelLoader</code>.</p> <ol> <li> <p>Place the Model File:</p> <ul> <li>Copy your pre-trained <code>.onnx</code> model file into the default model directory (<code>~/.MyOCR/models/</code>) or another location accessible by your application.</li> </ul> </li> <li> <p>Load the Model:</p> <p><pre><code>from myocr.modeling.model import ModelLoader, Device\n\n# Load an ONNX model for CPU inference\nloader = ModelLoader()\nonnx_model = loader.load(model_format='onnx', model_name_path='path/to/your/model.onnx', device=Device('cpu'))\n</code></pre> Other steps are similar to Option 1</p> </li> </ol>"},{"location":"models/add-model/#option-3-load-existing-pytorch-models","title":"Option 3: Load Existing PyTorch Models","text":"<p>It's very easy to load a pre-trained PyTorch models with its weights like following:</p> <p><pre><code>from myocr.modeling.model import ModelZoo\nmodel = ModelZoo.load_model(\"pt\", \"resnet152\", \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n</code></pre> Other steps are similar to Option 1</p>"},{"location":"models/train-model/","title":"Training Custom Models","text":"<p>MyOCR allows training custom models defined using its PyTorch-based modeling components (<code>myocr.modeling</code>). The core idea is to leverage the <code>CustomModel</code> class loaded from a YAML configuration within a standard PyTorch training loop.</p> <p>Disclaimer: This guide outlines the general approach. The project includes a <code>myocr/training/</code> directory which might contain specific training scripts, utilities, loss functions, or dataset handlers tailored for MyOCR. It is highly recommended to explore the contents of <code>myocr/training/</code> for framework-specific implementations and helpers before writing a training loop from scratch.</p>"},{"location":"models/train-model/#1-prepare-your-data","title":"1. Prepare Your Data","text":"<ul> <li>Dataset: You'll need a labeled dataset suitable for your task (e.g., images with bounding boxes and transcriptions for OCR).</li> <li>PyTorch Dataset Class: Create a custom <code>torch.utils.data.Dataset</code> class to load your images and labels, and perform necessary initial transformations.</li> <li>DataLoader: Use <code>torch.utils.data.DataLoader</code> to create batches of data for training and validation.</li> </ul>"},{"location":"models/train-model/#2-configure-your-model-architecture-yaml","title":"2. Configure Your Model Architecture (YAML)","text":"<ul> <li>Define the architecture of the model you want to train in a YAML configuration file (e.g., <code>config/my_trainable_model.yaml</code>).</li> <li>You might start training from scratch or load pre-trained weights for specific components (e.g., a pre-trained backbone specified within the <code>backbone</code> section of the YAML).</li> </ul>"},{"location":"models/train-model/#3-set-up-the-training-loop","title":"3. Set Up the Training Loop","text":"<ul> <li>Load Model: Use <code>ModelLoader</code> to load your <code>CustomModel</code> from the YAML configuration.</li> <li>Define Loss: Choose or implement a suitable loss function for your task (e.g., <code>torch.nn.CTCLoss</code> for recognition, custom loss for detection based on DBNet principles). Check <code>myocr/modeling/</code> or <code>myocr/training/</code> for potentially pre-defined losses.</li> <li>Define Optimizer: Select a PyTorch optimizer (e.g., <code>torch.optim.Adam</code>, <code>SGD</code>).</li> <li>Training Device: Set the device (CPU or GPU).</li> </ul> <pre><code>import torch\nimport torch.optim as optim\nfrom myocr.modeling.model import ModelLoader, Device\n\n# --- Configuration ---\nMODEL_CONFIG_PATH = 'config/my_trainable_model.yaml'\nLEARNING_RATE = 1e-4\nNUM_EPOCHS = 50\nOUTPUT_DIR = \"./trained_models\"\n\n# --- Setup ---\ndevice = Device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Load the custom model structure\nloader = ModelLoader()\nmodel = loader.load(model_format='custom', model_name_path=MODEL_CONFIG_PATH, device=device)\n\n# Define Loss Function (Example for CTC)\n# criterion = torch.nn.CTCLoss(blank=0).to(device.name) \n# Or find/implement your specific loss\ncriterion = ... \n\n# Define Optimizer\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# Optional: Learning rate scheduler\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n</code></pre>"},{"location":"models/train-model/#4-run-the-training-loop","title":"4. Run the Training Loop","text":"<ul> <li>Iterate through epochs and batches.</li> <li>Set model to training mode (<code>model.train()</code>).</li> <li>Perform forward pass, calculate loss, perform backpropagation, and update optimizer.</li> <li>Include a validation loop using <code>model.eval()</code> and <code>torch.no_grad()</code> to monitor performance.</li> <li>Save model checkpoints periodically (e.g., save the best performing model based on validation loss).</li> </ul> <pre><code>import os\n\nprint(f\"Starting training on {device.name}...\")\ntrainer = Trainer(model,[], nn.CrossEntropyLoss(), optimizer=Adam(model.parameters(), lr=0.001), num_epochs=50, batch_size = 64)\ntrainer.fit(train_dataset, val_dataset)\n\nprint('Finished Training')\n\n# Save the final model\nfinal_model_path = os.path.join(OUTPUT_DIR, \"final_model.pth\")\ntorch.save(model.loaded_model.state_dict(), final_model_path)\nprint(f\"Saved final model to {final_model_path}\")\n</code></pre>"},{"location":"models/train-model/#5-after-training","title":"5. After Training","text":"<ul> <li>Evaluation: Load your saved weights (<code>.pth</code> file) into the <code>CustomModel</code> (potentially by setting the <code>pretrained</code> key in the YAML config to your saved path) and run evaluation.</li> <li>ONNX Export (Optional): For optimized inference, you can convert your trained PyTorch model to ONNX format using the <code>to_onnx</code> method of the <code>CustomModel</code>.</li> </ul> <p><pre><code># Load the trained model (assuming YAML points to the saved .pth via 'pretrained' key)\n# trained_model = loader.load('custom', MODEL_CONFIG_PATH, device)\n\n# --- Or load state dict manually after loading architecture --- \nmodel_for_export = loader.load('custom', MODEL_CONFIG_PATH, device)\nmodel_for_export.loaded_model.load_state_dict(torch.load(best_model_path, map_location=device.name))\nmodel_for_export.eval()\n\n# Create a dummy input with the correct shape and type\ndummy_input = torch.randn(1, 3, 640, 640).to(device.name) # Adjust shape as needed\n\nonnx_output_path = os.path.join(OUTPUT_DIR, \"trained_model.onnx\")\n\nmodel_for_export.to_onnx(onnx_output_path, dummy_input)\nprint(f\"Exported model to {onnx_output_path}\")\n</code></pre> *   You can then use this exported ONNX model following the steps in Adding New Models.</p>"},{"location":"pipelines/","title":"Pipelines","text":"<p>MyOCR pipelines orchestrate multiple components (predictors, models) to perform end-to-end OCR tasks. They provide a high-level interface for processing images or documents.</p>"},{"location":"pipelines/#available-pipelines","title":"Available Pipelines","text":""},{"location":"pipelines/#commonocrpipeline","title":"<code>CommonOCRPipeline</code>","text":"<p>Defined in <code>myocr/pipelines/common_ocr_pipeline.py</code>.</p> <p>This pipeline performs standard OCR: text detection, optional text direction classification, and text recognition.</p> <p>Initialization:</p> <pre><code>from myocr.pipelines import CommonOCRPipeline\nfrom myocr.modeling.model import Device\n\n# Initialize pipeline for GPU (or 'cpu')\npipeline = CommonOCRPipeline(device=Device('cuda:0'))\n</code></pre> <p>Configuration:</p> <p>The pipeline loads configuration from <code>myocr/pipelines/config/common_ocr_pipeline.yaml</code>. This file specifies the paths to the ONNX models used for detection, classification, and recognition relative to the <code>MODEL_PATH</code> defined in <code>myocr.config</code>.</p> <pre><code># Example: myocr/pipelines/config/common_ocr_pipeline.yaml\nmodel:\n  detection: \"dbnet++.onnx\"\n  cls_direction: \"cls.onnx\"\n  recognition: \"rec.onnx\"\n</code></pre> <p>Processing:</p> <p>The <code>__call__</code> method takes the path to an image file.</p> <pre><code>image_path = 'path/to/your/image.png'\nocr_results = pipeline(image_path)\n\nif ocr_results:\n    # Access recognized text and bounding boxes\n    print(ocr_results)\n</code></pre> <p>Workflow:</p> <ol> <li>Loads the image.</li> <li>Uses <code>TextDetectionPredictor</code> to find text regions.</li> <li>Uses <code>TextDirectionPredictor</code> to classify the orientation of detected regions.</li> <li>Uses <code>TextRecognitionPredictor</code> to recognize the text within each oriented region.</li> <li>Returns a result object containing bounding boxes, text, and potentially confidence scores (details depend on the <code>Predictor</code> implementation).</li> </ol>"},{"location":"pipelines/#structuredoutputocrpipeline","title":"<code>StructuredOutputOCRPipeline</code>","text":"<p>Defined in <code>myocr/pipelines/structured_output_pipeline.py</code>.</p> <p>This pipeline extends <code>CommonOCRPipeline</code> by adding a step to extract structured information (e.g., JSON) from the recognized text using a large language model (LLM) via the <code>OpenAiChatExtractor</code>.</p> <p>Initialization:</p> <p>Requires a device and a Pydantic model defining the desired JSON output schema.</p> <pre><code>from myocr.pipelines import StructuredOutputOCRPipeline\nfrom myocr.modeling.model import Device\nfrom pydantic import BaseModel, Field\n\n# Define your desired output structure\nclass InvoiceData(BaseModel):\n    invoice_number: str = Field(description=\"The invoice number\")\n    total_amount: float = Field(description=\"The total amount due\")\n    due_date: str = Field(description=\"The payment due date\")\n\n# Initialize pipeline\npipeline = StructuredOutputOCRPipeline(device=Device('cuda:0'), json_schema=InvoiceData)\n</code></pre> <p>Configuration:</p> <p>This pipeline loads its specific configuration from <code>myocr/pipelines/config/structured_output_pipeline.yaml</code>, which includes settings for the <code>OpenAiChatExtractor</code> (LLM model name, API base URL, API key).</p> <pre><code># Example: myocr/pipelines/config/structured_output_pipeline.yaml\nchat_bot:\n  model: \"gpt-4o\"\n  base_url: \"https://api.openai.com/v1\"\n  api_key: \"YOUR_API_KEY\"\n</code></pre> <p>Processing:</p> <p>The <code>__call__</code> method takes an image path.</p> <pre><code>image_path = 'path/to/your/invoice.pdf'\nstructured_data = pipeline(image_path)\n\nif structured_data:\n    print(structured_data)\n</code></pre> <p>Workflow:</p> <ol> <li>Performs standard OCR using the inherited <code>CommonOCRPipeline</code> to get the raw recognized text.</li> <li>If text is found, it passes the text content to the <code>OpenAiChatExtractor</code>.</li> <li>The extractor interacts with the configured LLM, providing the text and the desired <code>json_schema</code> (Pydantic model) as instructions.</li> <li>The LLM attempts to extract the relevant information and format it according to the schema.</li> <li>Returns an instance of the provided Pydantic model populated with the extracted data.</li> </ol>"},{"location":"pipelines/#performance-optimization","title":"Performance Optimization","text":""},{"location":"pipelines/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple images\nresults = [pipeline(img_path) for img_path in image_paths]\n</code></pre>"},{"location":"pipelines/#gpu-acceleration","title":"GPU Acceleration","text":"<pre><code># Use GPU for faster processing\npipeline = CommonOCRPipeline(\"cuda:0\")\n</code></pre>"},{"location":"pipelines/#memory-management","title":"Memory Management","text":"<pre><code># Clear GPU memory\nimport torch\ntorch.cuda.empty_cache()\n</code></pre>"},{"location":"pipelines/#error-handling","title":"Error Handling","text":"<p>Pipelines handle various error cases:</p> <ul> <li>Invalid image format</li> <li>Missing model files</li> <li>GPU out of memory</li> <li>Invalid configuration</li> </ul> <p>See the Troubleshooting Guide for common issues and solutions. </p>"},{"location":"pipelines/build-pipeline/","title":"Building Custom Pipelines","text":"<p>MyOCR's pipelines orchestrate multiple predictors to perform complex tasks. While the library provides standard pipelines like <code>CommonOCRPipeline</code> and <code>StructuredOutputOCRPipeline</code>, you might need to create a custom pipeline for specific workflows, such as:</p> <ul> <li>Using different combinations of models or predictors.</li> <li>Adding custom pre-processing or post-processing steps.</li> <li>Integrating components beyond standard OCR (e.g., image enhancement, layout analysis before OCR).</li> <li>Handling different input/output types.</li> </ul> <p>This guide explains the steps to build your own pipeline.</p>"},{"location":"pipelines/build-pipeline/#1-inherit-from-basepipeline","title":"1. Inherit from <code>base.Pipeline</code>","text":"<p>All pipelines should inherit from the abstract base class <code>myocr.base.Pipeline</code>.</p>"},{"location":"pipelines/build-pipeline/#2-initialize-predictors-in-__init__","title":"2. Initialize Predictors in <code>__init__</code>","text":"<p>The <code>__init__</code> method is where you typically load the models and create the predictor instances your pipeline will use.</p> <ul> <li>Load Models: Use <code>myocr.modeling.model.ModelLoader</code> to load the necessary ONNX or custom PyTorch models.</li> <li>Instantiate Processors: Create instances of the required <code>CompositeProcessor</code> classes (e.g., <code>TextDetectionProcessor</code>, <code>TextRecognitionProcessor</code>, or custom ones).</li> <li>Create Predictors: Combine the loaded models and <code>CompositeProcessor</code> using the <code>Predictor(processor)</code> method.</li> <li>Store Predictors: Store the created predictor instances as attributes of your pipeline class (e.g., <code>self.det_predictor</code>).</li> </ul>"},{"location":"pipelines/build-pipeline/#3-implement-the-process-method","title":"3. Implement the <code>process</code> Method","text":"<p>This method defines the core logic of your pipeline. It takes the input data (e.g., an image path, a PIL Image), calls the <code>predict</code> method of the initialized predictors in sequence, handles intermediate results, and returns the final output.</p> <p>After the above steps, the implementation code will be like: <pre><code>from PIL import Image\nfrom typing import Optional\nfrom myocr.base import Predictor\nfrom myocr.types import OCRResult # Import necessary data structures\n\nclass MyDetectionOnlyPipeline(Pipeline):\n    def __init__(self, device: Device, detection_model_name: str = \"dbnet++.onnx\"):\n        # ... (Initialization from previous step) ...\n        super().__init__()\n        self.device = device\n\n        det_model_path = MODEL_PATH + detection_model_name\n        det_model = ModelLoader().load(\"onnx\", det_model_path, self.device)\n        det_processor = TextDetectionProcessor(det_model.device)\n        self.det_predictor = Predictor(det_processor)\n        logger.info(f\"DetectionOnlyPipeline initialized with {detection_model_name} on {device.name}\")\n\n\n    def process(self, image_path: str) -&gt; OCRResult:\n        \"\"\"Processes an image file and returns detected objects.\"\"\"\n        # 1. Load Image (Example: handling path input)\n        image = Image.open(image_path).convert(\"RGB\")\n        if image is None:\n            return None\n\n        # 2. Run Detection Predictor\n        detected_objects = self.det_predictor.predict(image)\n\n        # 3. Return Results\n        if detected_objects:\n            logger.info(f\"Detection successful: Found {len(detected_objects.bounding_boxes)} boxes.\")\n        else:\n            logger.info(\"Detection successful: No text boxes found.\")\n\n        return buildOcrResult(detected_objects) # Return the output of the detection predictor\n</code></pre></p>"},{"location":"pipelines/build-pipeline/#4-using-your-custom-pipeline","title":"4. Using Your Custom Pipeline","text":"<p>Once defined, you can import and use your custom pipeline just like the built-in ones.</p> <pre><code># from your_module import MyDetectionOnlyPipeline # Or MyFullOCRPipeline\nfrom myocr.modeling.model import Device\n\npipeline = MyDetectionOnlyPipeline(device=Device('cuda:0'))\nresults = pipeline.process('path/to/image.jpg')\n\nif results:\n    # Process the results from your custom pipeline\n    print(f\"Found {len(results.bounding_boxes)} text regions.\")\n</code></pre> <p>Remember to handle potential errors during model loading or prediction steps within your pipeline logic.</p>"},{"location":"predictors/","title":"Predictors","text":"<p>Predictors are responsible for handling the inference logic for specific models within MyOCR. They bridge the gap between raw model outputs and usable results by incorporating pre-processing and post-processing steps.</p> <p>Predictors are typically associated with a <code>Model</code> object and a <code>CompositeProcessor</code>.</p> <ul> <li>Model: Provides the core <code>forward_internal</code> method (e.g., ONNX session run, PyTorch model forward pass).</li> <li>CompositeProcessor: Handles the conversion of input data into the format expected by the model, and the conversion of the model's raw output into a structured, meaningful format.</li> </ul>"},{"location":"predictors/#base-components","title":"Base Components","text":"<ul> <li><code>myocr.base.Predictor</code>: A simple wrapper that calls the <code>CompositeProcessor</code>'s input conversion, the <code>Model</code>'s forward pass, and the <code>CompositeProcessor</code>'s output conversion.</li> <li><code>myocr.base.CompositeProcessor</code>: An abstract base class defining <code>preprocess</code> and <code>postprocess</code> methods.</li> </ul>"},{"location":"predictors/#available-predictors-and-processors","title":"Available Predictors and Processors","text":"<p>Predictors are created by calling the <code>Predictor(model, processor)</code>. The key components are the <code>CompositeProcessor</code> implementations:</p>"},{"location":"predictors/#text-detection-textdetectionprocessor","title":"Text Detection (<code>TextDetectionProcessor</code>)","text":"<ul> <li>File: <code>myocr/processors/text_detection_processor.py</code></li> <li>Associated Model: Typically a DBNet/DBNet++ ONNX model.</li> </ul>"},{"location":"predictors/#text-direction-classification-textdirectionprocessor","title":"Text Direction Classification (<code>TextDirectionProcessor</code>)","text":"<ul> <li>File: <code>myocr/processors/text_direction_processor.py</code></li> <li>Associated Model: Typically a simple CNN classifier ONNX model.</li> </ul>"},{"location":"predictors/#text-recognition-textrecognitionprocessor","title":"Text Recognition (<code>TextRecognitionProcessor</code>)","text":"<ul> <li>File: <code>myocr/processors/text_recognition_processor.py</code></li> <li>Associated Model: Typically a CRNN-based ONNX model.</li> </ul>"},{"location":"predictors/#performance-tips","title":"Performance Tips","text":""},{"location":"predictors/#batch-processing","title":"Batch Processing","text":"<pre><code># Process multiple regions\nresults = [predictor.predict(region) for region in regions]\n</code></pre>"},{"location":"predictors/create-predictor/","title":"Creating Custom Predictors","text":"<p>Predictors in MyOCR act as the bridge between a loaded <code>Model</code> (ONNX or PyTorch) and the end-user or pipeline. They encapsulate the necessary pre-processing and post-processing logic required to make a model easily usable for a specific task.</p> <p>While MyOCR provides standard predictors (via processors like <code>TextDetectionProcessor</code>, <code>TextRecognitionProcessor</code>), you might need a custom predictor if:</p> <ul> <li>Your model requires unique input pre-processing (e.g., different normalization, resizing, input format).</li> <li>Your model produces output that needs custom decoding or formatting (e.g., different bounding box formats, specialized classification labels, structured output not handled by existing pipelines).</li> <li>You want to create a predictor for a completely new task beyond detection, recognition, or classification.</li> </ul> <p>The key to building a custom predictor is creating a custom <code>CompositeProcessor</code> class.</p>"},{"location":"predictors/create-predictor/#1-understand-the-role-of-compositeprocessor","title":"1. Understand the Role of <code>CompositeProcessor</code>","text":"<p>A predictor itself is a simple wrapper (defined in <code>myocr.base.Predictor</code>). The actual work happens within its associated <code>CompositeProcessor</code> (a class inheriting from <code>myocr.base.CompositeProcessor</code>). The Processor has two main jobs:</p> <ol> <li><code>preprocess(user_input)</code>: Takes the data provided by the user or pipeline (e.g., a PIL Image) and transforms it into the precise format expected by the model's inference method (e.g., a normalized, batch-dimensioned NumPy array).</li> <li><code>postprocess(model_output)</code>: Takes the raw output from the model's inference method (e.g., NumPy arrays representing heatmaps or sequence probabilities) and transforms it into a user-friendly, structured format (e.g., a list of bounding boxes with text and scores, like <code>TextRegion</code>).</li> </ol>"},{"location":"predictors/create-predictor/#2-create-a-custom-compositeprocessor-class","title":"2. Create a Custom <code>CompositeProcessor</code> Class","text":"<ol> <li>Inherit: Create a Python class that inherits from <code>myocr.base.CompositeProcessor</code>.</li> <li>Specify Types (Optional but Recommended): Use generics to indicate the expected input type for <code>preprocess</code> and the output type for <code>postprocess</code>. For example, <code>CompositeProcessor[PIL.Image.Image, List[RectBoundingBox]]</code> means it takes a PIL Image and returns <code>List[RectBoundingBox]</code>.</li> <li>Implement <code>__init__</code>: Initialize any necessary parameters, such as thresholds, label mappings, or references needed during conversion.</li> <li>Implement <code>preprocess</code>: Write the code to transform the input data into the model-ready format.</li> <li>Implement <code>postprocess</code>: Write the code to transform the raw model output into the desired structured result.</li> </ol> <p>Note: take the Available predictors for example</p>"},{"location":"predictors/create-predictor/#3-create-the-predictor-instance","title":"3. Create the Predictor Instance","text":"<p>Once you have your custom <code>CompositeProcessor</code> and have loaded your model, you can create the predictor instance.</p>"},{"location":"predictors/create-predictor/#4-integrate-into-a-pipeline-optional","title":"4. Integrate into a Pipeline (Optional)","text":"<p>If your custom predictor is part of a larger workflow, you can integrate it into a Custom Pipeline by initializing it within the pipeline's <code>__init__</code> method and calling its <code>predict</code> method within the pipeline's <code>process</code> method.</p> <p>By following these steps, you can create specialized predictors tailored to your specific models and tasks within the MyOCR framework. </p>"},{"location":"zh/","title":"\u6b22\u8fce\u200b\u6765\u5230\u200b MyOCR \u200b\u6587\u6863","text":"<p>MyOCR \u200b\u662f\u200b\u4e00\u4e2a\u200b\u9ad8\u5ea6\u200b\u53ef\u200b\u6269\u5c55\u200b\u4e14\u200b\u6613\u4e8e\u200b\u5b9a\u5236\u200b\u7684\u200b\u6846\u67b6\u200b\uff0c\u200b\u4e13\u200b\u4e3a\u200b\u7b80\u5316\u200b\u751f\u4ea7\u200b\u7ea7\u200b OCR \u200b\u7cfb\u7edf\u200b\u7684\u200b\u5f00\u53d1\u200b\u548c\u200b\u90e8\u7f72\u200b\u800c\u200b\u8bbe\u8ba1\u200b\u3002</p> <p>\u200b\u901a\u8fc7\u200b MyOCR\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u8f7b\u677e\u200b\u8bad\u7ec3\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u65e0\u7f1d\u200b\u96c6\u6210\u200b\u5230\u200b\u60a8\u200b\u7684\u200b OCR \u200b\u65b9\u6848\u200b\u4e2d\u200b\u3002</p>"},{"location":"zh/#_1","title":"\u4e3b\u8981\u200b\u7279\u6027","text":"<p>\u26a1\ufe0f \u200b\u7aef\u5230\u200b\u7aef\u200b OCR \u200b\u5f00\u53d1\u200b\u6846\u67b6\u200b \u2013 \u200b\u4e3a\u200b\u5f00\u53d1\u8005\u200b\u6253\u9020\u200b\uff0c\u200b\u5e2e\u52a9\u200b\u60a8\u200b\u5728\u200b\u7edf\u4e00\u200b\u7075\u6d3b\u200b\u7684\u200b\u6d41\u7a0b\u200b\u4e2d\u200b\u6784\u5efa\u200b\u548c\u200b\u96c6\u6210\u200b\u68c0\u6d4b\u200b\u3001\u200b\u8bc6\u522b\u200b\u4ee5\u53ca\u200b\u81ea\u5b9a\u4e49\u200b OCR \u200b\u6a21\u578b\u200b\u3002</p> <p>\ud83d\udee0\ufe0f \u200b\u6a21\u5757\u5316\u200b\u4e0e\u200b\u53ef\u6269\u5c55\u6027\u200b \u2013 \u200b\u81ea\u7531\u7ec4\u5408\u200b\u5404\u79cd\u200b\u7ec4\u4ef6\u200b\uff0c\u200b\u4ee5\u200b\u6700\u5c0f\u200b\u7684\u200b\u6539\u52a8\u200b\u5373\u53ef\u200b\u66ff\u6362\u200b\u6a21\u578b\u200b\u3001\u200b\u9884\u6d4b\u5668\u200b\u6216\u200b\u8f93\u5165\u8f93\u51fa\u200b\u5904\u7406\u5668\u200b\u3002</p> <p>\ud83d\udd0c \u200b\u5bf9\u200b\u5f00\u53d1\u8005\u200b\u53cb\u597d\u200b\u7684\u200b\u8bbe\u8ba1\u200b - \u200b\u6e05\u6670\u200b\u7684\u200b Python API\u3001\u200b\u9884\u200b\u6784\u5efa\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u548c\u200b\u5904\u7406\u5668\u200b\uff0c\u200b\u8ba9\u200b\u8bad\u7ec3\u200b\u548c\u200b\u63a8\u7406\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u53d8\u5f97\u200b\u7b80\u5355\u200b\u76f4\u89c2\u200b\u3002</p> <p>\ud83d\ude80 \u200b\u751f\u4ea7\u200b\u5c31\u7eea\u200b\u7684\u200b\u6027\u80fd\u200b\u8868\u73b0\u200b \u2013 \u200b\u652f\u6301\u200b ONNX runtime \u200b\u5b9e\u73b0\u200b\u5feb\u901f\u200b CPU/GPU \u200b\u63a8\u7406\u200b\uff0c\u200b\u63d0\u4f9b\u200b\u591a\u79cd\u200b\u90e8\u7f72\u200b\u65b9\u5f0f\u200b\u3002</p>"},{"location":"zh/#_2","title":"\u5feb\u901f\u200b\u5165\u95e8","text":"<ol> <li>\u200b\u5b89\u88c5\u200b: \u200b\u914d\u7f6e\u200b MyOCR \u200b\u5e76\u200b\u4e0b\u8f7d\u200b\u5fc5\u8981\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u6982\u89c8\u200b: \u200b\u4e86\u89e3\u200b\u6838\u5fc3\u200b\u6982\u5ff5\u200b\uff08\u200b\u6a21\u578b\u200b\u3001\u200b\u9884\u6d4b\u5668\u200b\u3001\u200b\u6d41\u6c34\u7ebf\u200b\uff09\uff0c\u200b\u4e3a\u200b\u6784\u5efa\u200b\u60a8\u200b\u7684\u200b OCR \u200b\u80fd\u529b\u200b\u6253\u4e0b\u57fa\u7840\u200b\u3002</li> <li>\u200b\u63a8\u7406\u200b\u6307\u5357\u200b: \u200b\u5b66\u4e60\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b MyOCR \u200b\u6267\u884c\u200b OCR \u200b\u4efb\u52a1\u200b\u3002</li> </ol>"},{"location":"zh/#_3","title":"\u6838\u5fc3\u200b\u6982\u5ff5","text":"<ul> <li>\u200b\u6a21\u578b\u200b: \u200b\u4e86\u89e3\u200b\u652f\u6301\u200b\u7684\u200b\u6a21\u578b\u200b\u7c7b\u578b\u200b\uff08ONNX\u3001PyTorch\u3001\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff09\u200b\u53ca\u5176\u200b\u67b6\u6784\u200b\u3002</li> <li>\u200b\u9884\u6d4b\u5668\u200b: \u200b\u4e86\u89e3\u200b\u6a21\u578b\u200b\u5982\u4f55\u200b\u4e0e\u200b\u8f93\u5165\u200b/\u200b\u8f93\u51fa\u200b\u5904\u7406\u5668\u200b\u7ed3\u5408\u200b\u6210\u4e3a\u200b <code>Predictor</code>\u3002</li> <li>\u200b\u6d41\u6c34\u7ebf\u200b: \u200b\u63a2\u7d22\u200b\u5982\u4f55\u200b\u534f\u8c03\u200b\u591a\u4e2a\u200b\u9884\u6d4b\u5668\u200b\uff0c\u200b\u5b9e\u73b0\u200b\u7aef\u5230\u200b\u7aef\u200b OCR \u200b\u7684\u200b\u9ad8\u7ea7\u200b\u6d41\u6c34\u7ebf\u200b\u3002</li> </ul>"},{"location":"zh/#_4","title":"\u5176\u4ed6\u200b\u8d44\u6e90","text":"<ul> <li>\u200b\u5e38\u89c1\u200b\u95ee\u9898\u89e3\u7b54\u200b: \u200b\u67e5\u627e\u200b\u5e38\u89c1\u95ee\u9898\u200b\u7684\u200b\u89e3\u7b54\u200b\u3002</li> <li>\u200b\u66f4\u65b0\u200b\u65e5\u5fd7\u200b: \u200b\u67e5\u770b\u200b\u6700\u8fd1\u200b\u7684\u200b\u66f4\u65b0\u200b\u548c\u200b\u53d8\u5316\u200b\u3002</li> <li>\u200b\u8d21\u732e\u200b\u6307\u5357\u200b: \u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u4e3a\u200b\u9879\u76ee\u200b\u505a\u51fa\u200b\u8d21\u732e\u200b\u3002</li> <li>GitHub \u200b\u4ed3\u5e93\u200b: \u200b\u6e90\u4ee3\u7801\u200b\u3001\u200b\u95ee\u9898\u200b\u548c\u200b\u8ba8\u8bba\u200b\u3002</li> </ul>"},{"location":"zh/#_5","title":"\u8bb8\u53ef\u8bc1","text":"<p>MyOCR \u200b\u91c7\u7528\u200b Apache 2.0 \u200b\u8bb8\u53ef\u8bc1\u200b \u200b\u5f00\u6e90\u200b\u3002</p>"},{"location":"zh/CHANGELOG/","title":"\u66f4\u65b0\u200b\u65e5\u5fd7","text":"<p>\u200b\u672c\u200b\u9879\u76ee\u200b\u6240\u6709\u200b\u91cd\u8981\u200b\u7684\u200b\u53d8\u66f4\u200b\u90fd\u200b\u5c06\u200b\u8bb0\u5f55\u200b\u5728\u200b\u6b64\u200b\u6587\u4ef6\u200b\u4e2d\u200b\u3002</p> <p>\u200b\u8be5\u200b\u683c\u5f0f\u200b\u57fa\u4e8e\u200b Keep a Changelog\uff0c \u200b\u5e76\u4e14\u200b\u672c\u200b\u9879\u76ee\u200b\u9075\u5faa\u200b \u200b\u8bed\u4e49\u200b\u5316\u200b\u7248\u672c\u200b\u3002</p>"},{"location":"zh/CHANGELOG/#_2","title":"\u672a\u200b\u53d1\u5e03","text":""},{"location":"zh/CHANGELOG/#_3","title":"\u6dfb\u52a0","text":"<ul> <li>\u200b\u5f15\u5165\u200b\u5e03\u5c40\u200b\u68c0\u6d4b\u200b</li> <li>\u200b\u5f15\u5165\u200b\u8868\u683c\u200b\u68c0\u6d4b\u200b</li> <li>\u200b\u6d4b\u8bd5\u200b OCR \u200b\u7cbe\u5ea6\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_4","title":"\u6dfb\u52a0","text":"<ul> <li>\u200b\u7edf\u4e00\u200b OCR \u200b\u7ed3\u679c\u200b\u7684\u200b\u6570\u636e\u7ed3\u6784\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_5","title":"\u66f4\u6539","text":"<ul> <li>\u200b\u91cd\u6784\u200b CommonOCRPipeline \u200b\u4ee5\u200b\u4f7f\u7528\u200b\u65b0\u200b\u7684\u200b OCRResult \u200b\u7c7b\u578b\u200b</li> <li>\u200b\u4f18\u5316\u200b CommonOCRPipeline \u200b\u548c\u200b HTTP \u200b\u7aef\u70b9\u200b\u7684\u200b\u4ee3\u7801\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_6","title":"\u4fee\u590d","text":"<ul> <li>\u200b\u4fee\u590d\u200b\u8bc6\u522b\u200b\u6587\u672c\u200b\u7684\u200b\u7f6e\u4fe1\u5ea6\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_7","title":"\u4fee\u590d","text":"<ul> <li>\u200b\u4fee\u590d\u200b\u6784\u5efa\u200b Docker \u200b\u955c\u50cf\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6d41\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_8","title":"\u6dfb\u52a0","text":"<ul> <li>\u200b\u6dfb\u52a0\u200b\u53d1\u5e03\u200b Docker \u200b\u955c\u50cf\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6d41\u200b</li> <li>\u200b\u66f4\u65b0\u200b readme</li> <li>\u200b\u6dfb\u52a0\u200b\u624b\u52a8\u200b\u53d1\u5e03\u200b\u6587\u6863\u200b\u7684\u200b\u914d\u7f6e\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_9","title":"\u4fee\u590d","text":"<ul> <li>\u200b\u4fee\u590d\u200b\u9ed1\u8272\u200b\u7a7a\u683c\u200b\u7684\u200b\u5b57\u7b26\u200b\u89e3\u7801\u200b</li> </ul>"},{"location":"zh/CHANGELOG/#_10","title":"\u6dfb\u52a0","text":"<ul> <li>\u200b\u5728\u200b releash.sh \u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u7248\u672c\u200b\u68c0\u67e5\u200b</li> <li>\u200b\u5728\u200b readme \u200b\u4e2d\u200b\u6dfb\u52a0\u200b\u6f14\u793a\u200b URL</li> </ul>"},{"location":"zh/CHANGELOG/#_11","title":"\u4fee\u590d","text":"<ul> <li>\u200b\u901a\u8fc7\u200b\u5c06\u200b\u65e5\u5fd7\u200b\u914d\u7f6e\u200b\u79fb\u51fa\u200b myocr \u200b\u5305\u6765\u200b\u4fee\u590d\u200b\u65e5\u5fd7\u200b\u95ee\u9898\u200b</li> </ul>"},{"location":"zh/CONTRIBUTING/","title":"\u4e3a\u200b MyOCR \u200b\u505a\u51fa\u200b\u8d21\u732e","text":"<p>\u200b\u611f\u8c22\u60a8\u200b\u5bf9\u200b MyOCR \u200b\u9879\u76ee\u200b\u7684\u200b\u5173\u6ce8\u200b\uff01\u200b\u672c\u200b\u6587\u6863\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u53c2\u4e0e\u200b\u9879\u76ee\u200b\u8d21\u732e\u200b\u7684\u200b\u6307\u5357\u200b\u548c\u200b\u8bf4\u660e\u200b\u3002</p>"},{"location":"zh/CONTRIBUTING/#_1","title":"\u884c\u4e3a\u51c6\u5219","text":"<p>\u200b\u53c2\u4e0e\u200b\u672c\u200b\u9879\u76ee\u200b\u5373\u200b\u8868\u793a\u200b\u60a8\u200b\u540c\u610f\u200b\u4e3a\u200b\u6240\u6709\u200b\u53c2\u4e0e\u8005\u200b\u8425\u9020\u200b\u4e00\u4e2a\u200b\u5c0a\u91cd\u200b\u548c\u200b\u5305\u5bb9\u200b\u7684\u200b\u73af\u5883\u200b\u3002\u200b\u8bf7\u200b\u5728\u200b\u4ea4\u6d41\u200b\u4e2d\u200b\u4fdd\u6301\u200b\u53cb\u5584\u200b\u3001\u200b\u4f53\u8d34\u200b\u548c\u200b\u5efa\u8bbe\u6027\u200b\u7684\u200b\u6001\u5ea6\u200b\u3002</p>"},{"location":"zh/CONTRIBUTING/#_2","title":"\u5f00\u59cb\u200b\u8d21\u732e","text":"<ol> <li>Fork \u200b\u4ed3\u5e93\u200b: \u200b\u5728\u200b GitHub \u200b\u4e0a\u200bFork MyOCR \u200b\u4ed3\u5e93\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u8d26\u6237\u200b\u4e0b\u200b\u3002</li> <li>\u200b\u514b\u9686\u200b\u60a8\u200b\u7684\u200b\u4ed3\u5e93\u200b:      <pre><code>git clone https://github.com/your-username/myocr.git\ncd myocr\n</code></pre></li> <li>\u200b\u6dfb\u52a0\u200b\u4e0a\u6e38\u200b\u4ed3\u5e93\u200b:      <pre><code>git remote add upstream https://github.com/robbyzhaox/myocr.git\n</code></pre></li> <li>\u200b\u521b\u5efa\u200b\u5206\u652f\u200b: \u200b\u4e3a\u200b\u60a8\u200b\u7684\u200b\u5de5\u4f5c\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u65b0\u200b\u7684\u200b\u529f\u80fd\u200b\u5206\u652f\u200b\u3002     <pre><code>git checkout -b feature/your-feature-name\n</code></pre></li> </ol>"},{"location":"zh/CONTRIBUTING/#_3","title":"\u5f00\u53d1\u200b\u73af\u5883\u200b\u8bbe\u7f6e","text":"<ol> <li> <p>\u200b\u5b89\u88c5\u200b\u4f9d\u8d56\u200b\u9879\u200b:      <pre><code>pip install -e \".[dev]\"\n</code></pre>     \u200b\u8fd9\u200b\u5c06\u200b\u4ee5\u200b\u5f00\u53d1\u200b\u6a21\u5f0f\u200b\u5b89\u88c5\u200b\u8f6f\u4ef6\u5305\u200b\u53ca\u5176\u200b\u6240\u6709\u200b\u5f00\u53d1\u200b\u4f9d\u8d56\u200b\u9879\u200b\u3002</p> </li> <li> <p>\u200b\u8bbe\u7f6e\u200b pre-commit \u200b\u94a9\u5b50\u200b (\u200b\u53ef\u9009\u200b\u4f46\u200b\u63a8\u8350\u200b):      <pre><code>pre-commit install\n</code></pre></p> </li> </ol>"},{"location":"zh/CONTRIBUTING/#pull-request-pr","title":"Pull Request (PR) \u200b\u6d41\u7a0b","text":"<ol> <li>\u200b\u4fdd\u6301\u200b\u53d8\u66f4\u200b\u96c6\u4e2d\u200b: \u200b\u6bcf\u4e2a\u200b PR \u200b\u5e94\u200b\u9488\u5bf9\u200b\u4e00\u4e2a\u200b\u7279\u5b9a\u200b\u7684\u200b\u529f\u80fd\u200b\u3001\u200b\u9519\u8bef\u200b\u4fee\u590d\u200b\u6216\u200b\u6539\u8fdb\u200b\u3002</li> <li>\u200b\u66f4\u65b0\u200b\u6587\u6863\u200b: \u200b\u786e\u4fdd\u200b\u66f4\u65b0\u200b\u6587\u6863\u200b\u4ee5\u200b\u53cd\u6620\u200b\u60a8\u200b\u7684\u200b\u66f4\u6539\u200b\u3002</li> <li>\u200b\u7f16\u5199\u200b\u6d4b\u8bd5\u200b: \u200b\u4e3a\u200b\u60a8\u200b\u6240\u200b\u505a\u200b\u7684\u200b\u66f4\u6539\u200b\u6dfb\u52a0\u200b\u6216\u200b\u66f4\u65b0\u200b\u6d4b\u8bd5\u200b\u3002</li> <li>\u200b\u5728\u200b\u672c\u5730\u200b\u8fd0\u884c\u200b\u6d4b\u8bd5\u200b: \u200b\u5728\u200b\u63d0\u4ea4\u200b PR \u200b\u4e4b\u524d\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u6240\u6709\u200b\u6d4b\u8bd5\u200b\u90fd\u200b\u901a\u8fc7\u200b\u3002     <pre><code>pytest\n</code></pre></li> <li>\u200b\u63d0\u4ea4\u200b PR: \u200b\u5c06\u200b\u60a8\u200b\u7684\u200b\u66f4\u6539\u200b\u63a8\u9001\u200b\u5230\u200b\u60a8\u200b\u7684\u200b\u5206\u652f\u200b\uff0c\u200b\u5e76\u200b\u9488\u5bf9\u200b\u4e3b\u200b\u4ed3\u5e93\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b PR\u3002     <pre><code>git push origin feature/your-feature-name\n</code></pre></li> <li>PR \u200b\u63cf\u8ff0\u200b: \u200b\u63d0\u4f9b\u200b\u6e05\u6670\u200b\u7684\u200b\u66f4\u6539\u200b\u63cf\u8ff0\u200b\uff0c\u200b\u5e76\u200b\u5f15\u7528\u200b\u4efb\u4f55\u200b\u76f8\u5173\u200b\u7684\u200b\u95ee\u9898\u200b (Issue)\u3002</li> <li>\u200b\u4ee3\u7801\u200b\u5ba1\u67e5\u200b: \u200b\u79ef\u6781\u54cd\u5e94\u200b\u4ee3\u7801\u200b\u5ba1\u67e5\u200b\u610f\u89c1\u200b\uff0c\u200b\u5e76\u200b\u8fdb\u884c\u200b\u5fc5\u8981\u200b\u7684\u200b\u8c03\u6574\u200b\u3002</li> </ol>"},{"location":"zh/CONTRIBUTING/#_4","title":"\u7f16\u7801\u200b\u89c4\u8303","text":"<p>\u200b\u6211\u4eec\u200b\u4f7f\u7528\u200b\u591a\u79cd\u200b\u5de5\u5177\u200b\u6765\u200b\u5f3a\u5236\u6267\u884c\u200b\u7f16\u7801\u200b\u89c4\u8303\u200b\u3002\u200b\u786e\u4fdd\u60a8\u200b\u7684\u200b\u4ee3\u7801\u200b\u7b26\u5408\u200b\u8fd9\u4e9b\u200b\u6807\u51c6\u200b\u7684\u200b\u6700\u200b\u7b80\u5355\u200b\u65b9\u6cd5\u200b\u662f\u200b\u4f7f\u7528\u200b\u63d0\u4f9b\u200b\u7684\u200b Makefile \u200b\u547d\u4ee4\u200b\uff1a</p>"},{"location":"zh/CONTRIBUTING/#_5","title":"\ud83d\udce6 \u200b\u5f00\u53d1\u5de5\u5177","text":"<p>MyOCR \u200b\u5305\u542b\u200b\u51e0\u4e2a\u200b Makefile \u200b\u547d\u4ee4\u200b\u6765\u200b\u5e2e\u52a9\u200b\u5f00\u53d1\u200b\uff1a</p> <pre><code># \u200b\u683c\u5f0f\u5316\u200b\u4ee3\u7801\u200b\uff08\u200b\u8fd0\u884c\u200b isort\u3001black \u200b\u548c\u200b ruff fix\uff09\nmake run-format\n\n# \u200b\u8fd0\u884c\u200b\u4ee3\u7801\u200b\u8d28\u91cf\u68c0\u67e5\u200b\uff08isort\u3001black\u3001ruff\u3001mypy\u3001pytest\uff09\nmake run-checks\n\n# \u200b\u5728\u200b\u672c\u5730\u200b\u9884\u89c8\u200b\u6587\u6863\u200b\ncd documentation\nmkdocs serve -a 127.0.0.1:8001\n</code></pre> <p>\u200b\u5982\u679c\u200b\u60a8\u200b\u559c\u6b22\u200b\u5355\u72ec\u200b\u8fd0\u884c\u200b\u8fd9\u4e9b\u200b\u5de5\u5177\u200b\uff1a</p> <p>Black: \u200b\u7528\u4e8e\u200b\u4ee3\u7801\u200b\u683c\u5f0f\u5316\u200b    <pre><code>black .\n</code></pre></p> <p>isort: \u200b\u7528\u4e8e\u200b\u5bfc\u5165\u200b\u6392\u5e8f\u200b    <pre><code>isort .\n</code></pre></p> <p>Ruff: \u200b\u7528\u4e8e\u200b\u4ee3\u7801\u200b\u68c0\u67e5\u200b    <pre><code>ruff check .\n</code></pre></p> <p>mypy: \u200b\u7528\u4e8e\u200b\u7c7b\u578b\u200b\u68c0\u67e5\u200b    <pre><code>mypy myocr\n</code></pre></p> <p>\u200b\u8fd9\u4e9b\u200b\u5de5\u5177\u200b\u7684\u200b\u914d\u7f6e\u200b\u4f4d\u4e8e\u200b <code>pyproject.toml</code> \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u3002</p>"},{"location":"zh/CONTRIBUTING/#_6","title":"\u6d4b\u8bd5\u200b\u6307\u5357","text":"<ol> <li>\u200b\u7f16\u5199\u200b\u5355\u5143\u6d4b\u8bd5\u200b: \u200b\u4e3a\u200b\u65b0\u200b\u529f\u80fd\u200b\u548c\u200b\u9519\u8bef\u200b\u4fee\u590d\u200b\u7f16\u5199\u200b\u5168\u9762\u200b\u7684\u200b\u6d4b\u8bd5\u200b\u3002</li> <li>\u200b\u6d4b\u8bd5\u200b\u8986\u76d6\u7387\u200b: \u200b\u76ee\u6807\u200b\u662f\u200b\u4e3a\u200b\u6240\u6709\u200b\u65b0\u200b\u4ee3\u7801\u200b\u5b9e\u73b0\u200b\u9ad8\u200b\u6d4b\u8bd5\u200b\u8986\u76d6\u7387\u200b\u3002</li> <li>\u200b\u6d4b\u8bd5\u200b\u76ee\u5f55\u200b\u7ed3\u6784\u200b: <ul> <li>\u200b\u5c06\u200b\u6d4b\u8bd5\u200b\u653e\u5728\u200b <code>tests/</code> \u200b\u76ee\u5f55\u200b\u4e0b\u200b</li> <li>\u200b\u9075\u5faa\u200b\u4e0e\u200b\u6e90\u4ee3\u7801\u200b\u76f8\u540c\u200b\u7684\u200b\u76ee\u5f55\u200b\u7ed3\u6784\u200b</li> </ul> </li> </ol>"},{"location":"zh/CONTRIBUTING/#_7","title":"\u6587\u6863","text":"<p>\u200b\u826f\u597d\u200b\u7684\u200b\u6587\u6863\u200b\u5bf9\u200b\u9879\u76ee\u200b\u81f3\u5173\u91cd\u8981\u200b\uff1a</p> <ol> <li>\u200b\u6587\u6863\u200b\u5b57\u7b26\u4e32\u200b (Docstrings): \u200b\u4e3a\u200b\u6240\u6709\u200b\u516c\u5171\u200b\u7c7b\u200b\u548c\u200b\u51fd\u6570\u200b\u6dfb\u52a0\u200b\u6587\u6863\u200b\u5b57\u7b26\u4e32\u200b\u3002</li> <li>\u200b\u793a\u4f8b\u200b\u7528\u6cd5\u200b: \u200b\u5728\u200b\u9002\u5f53\u200b\u7684\u200b\u6587\u6863\u200b\u5b57\u7b26\u4e32\u200b\u4e2d\u200b\u5305\u542b\u200b\u793a\u4f8b\u200b\u7528\u6cd5\u200b\u3002</li> <li>README \u200b\u66f4\u65b0\u200b: \u200b\u5982\u679c\u200b\u60a8\u200b\u6dfb\u52a0\u200b\u4e86\u200b\u4e3b\u8981\u200b\u529f\u80fd\u200b\u6216\u200b\u66f4\u6539\u200b\u4e86\u200b\u529f\u80fd\u200b\uff0c\u200b\u8bf7\u200b\u66f4\u65b0\u200b README\u3002</li> <li>API \u200b\u6587\u6863\u200b: \u200b\u5bf9\u4e8e\u200b\u91cd\u8981\u200b\u7684\u200b\u8865\u5145\u200b\u5185\u5bb9\u200b\uff0c\u200b\u8bf7\u200b\u8003\u8651\u200b\u66f4\u65b0\u200b API \u200b\u6587\u6863\u200b\u3002</li> </ol>"},{"location":"zh/CONTRIBUTING/#_8","title":"\u6784\u5efa\u200b\u6587\u6863","text":"<p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u4ee5\u4e0b\u200b\u547d\u4ee4\u200b\u5728\u200b\u672c\u5730\u200b\u6784\u5efa\u200b\u6587\u6863\u200b\uff1a</p> <pre><code>cd documentation\nmkdocs build\n</code></pre> <p>\u200b\u6b64\u200b\u547d\u4ee4\u200b\u5c06\u200b\u751f\u6210\u200b HTML \u200b\u6587\u6863\u200b\u5e76\u200b\u542f\u52a8\u200b\u672c\u5730\u200b\u670d\u52a1\u5668\u200b\u4ee5\u4f9b\u200b\u67e5\u770b\u200b\u3002</p>"},{"location":"zh/CONTRIBUTING/#_9","title":"\u95ee\u9898\u200b\u62a5\u544a","text":"<p>\u200b\u5728\u200b\u521b\u5efa\u200b\u65b0\u200b\u95ee\u9898\u200b (Issue) \u200b\u4e4b\u524d\u200b\uff1a</p> <ol> <li>\u200b\u68c0\u67e5\u200b\u73b0\u6709\u200b\u95ee\u9898\u200b: \u200b\u786e\u4fdd\u200b\u8be5\u200b\u95ee\u9898\u200b\u5c1a\u672a\u200b\u88ab\u200b\u62a5\u544a\u200b\u3002</li> <li>\u200b\u63d0\u4f9b\u200b\u4fe1\u606f\u200b: \u200b\u5305\u542b\u200b\u6709\u5173\u200b\u95ee\u9898\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff1a<ul> <li>\u200b\u91cd\u73b0\u200b\u6b65\u9aa4\u200b</li> <li>\u200b\u9884\u671f\u200b\u884c\u4e3a\u200b</li> <li>\u200b\u5b9e\u9645\u200b\u884c\u4e3a\u200b</li> <li>\u200b\u73af\u5883\u200b\uff08\u200b\u64cd\u4f5c\u7cfb\u7edf\u200b\u3001Python \u200b\u7248\u672c\u200b\u7b49\u200b\uff09</li> <li>\u200b\u65e5\u5fd7\u200b\u6216\u200b\u9519\u8bef\u200b\u6d88\u606f\u200b</li> </ul> </li> <li>\u200b\u4f7f\u7528\u200b\u6a21\u677f\u200b: \u200b\u5982\u679c\u200b\u53ef\u7528\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b\u4ed3\u5e93\u200b\u4e2d\u200b\u63d0\u4f9b\u200b\u7684\u200b\u95ee\u9898\u200b\u6a21\u677f\u200b\u3002</li> </ol>"},{"location":"zh/CONTRIBUTING/#_10","title":"\u6dfb\u52a0\u200b\u65b0\u200b\u529f\u80fd","text":"<p>\u200b\u5728\u200b\u63d0\u51fa\u200b\u65b0\u200b\u529f\u80fd\u200b\u65f6\u200b\uff1a</p> <ol> <li>\u200b\u5148\u200b\u8ba8\u8bba\u200b: \u200b\u5bf9\u4e8e\u200b\u4e3b\u8981\u200b\u529f\u80fd\u200b\uff0c\u200b\u8bf7\u200b\u5728\u200b\u5b9e\u65bd\u200b\u4e4b\u524d\u200b\u5148\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b Issue \u200b\u8fdb\u884c\u200b\u8ba8\u8bba\u200b\u3002</li> <li>\u200b\u6a21\u5757\u5316\u200b\u65b9\u6cd5\u200b: \u200b\u5728\u200b\u8bbe\u8ba1\u200b\u65b0\u200b\u529f\u80fd\u200b\u65f6\u200b\uff0c\u200b\u8bf7\u200b\u7262\u8bb0\u200b\u6a21\u5757\u5316\u200b\u67b6\u6784\u200b\u3002</li> <li>\u200b\u6d41\u6c34\u7ebf\u200b\u96c6\u6210\u200b: \u200b\u786e\u4fdd\u200b\u65b0\u200b\u7ec4\u4ef6\u200b\u80fd\u200b\u4e0e\u200b\u73b0\u6709\u200b\u6d41\u6c34\u7ebf\u7ed3\u6784\u200b\u826f\u597d\u200b\u96c6\u6210\u200b\u3002</li> <li>\u200b\u6a21\u578b\u200b\u517c\u5bb9\u6027\u200b: \u200b\u5982\u679c\u200b\u6dfb\u52a0\u200b\u65b0\u200b\u6a21\u578b\u200b\uff0c\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u5b83\u4eec\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b\u73b0\u6709\u200b\u7684\u200b ModelZoo \u200b\u7cfb\u7edf\u200b\u52a0\u8f7d\u200b\u3002</li> </ol>"},{"location":"zh/CONTRIBUTING/#_11","title":"\u8bb8\u53ef\u8bc1","text":"<p>\u200b\u4e3a\u200b MyOCR \u200b\u505a\u51fa\u200b\u8d21\u732e\u200b\uff0c\u200b\u5373\u200b\u8868\u793a\u200b\u60a8\u200b\u540c\u610f\u200b\u60a8\u200b\u7684\u200b\u8d21\u732e\u200b\u5c06\u200b\u6839\u636e\u200b\u9879\u76ee\u200b\u7684\u200b Apache 2.0 \u200b\u8bb8\u53ef\u8bc1\u200b \u200b\u8fdb\u884c\u200b\u8bb8\u53ef\u200b\u3002</p> <p>\u200b\u611f\u8c22\u60a8\u200b\u4e3a\u200b MyOCR \u200b\u505a\u51fa\u200b\u8d21\u732e\u200b\uff01\u200b\u60a8\u200b\u7684\u200b\u52aa\u529b\u200b\u4f7f\u200b\u8fd9\u4e2a\u200b\u9879\u76ee\u200b\u53d8\u5f97\u200b\u66f4\u597d\u200b\u3002 </p>"},{"location":"zh/faq/","title":"FAQ - \u200b\u5e38\u89c1\u200b\u95ee\u9898\u89e3\u7b54","text":""},{"location":"zh/faq/#myocr","title":"\u95ee\u200b\uff1aMyOCR \u200b\u9ed8\u8ba4\u200b\u5728\u200b\u54ea\u91cc\u200b\u67e5\u627e\u200b\u6a21\u578b\u200b\uff1f","text":"<p>\u200b\u7b54\u200b\uff1a \u200b\u9ed8\u8ba4\u200b\u8def\u5f84\u200b\u5728\u200b <code>myocr/config.py</code> \u200b\u4e2d\u200b\u7684\u200b <code>MODEL_PATH</code> \u200b\u53d8\u91cf\u200b\u4e2d\u200b\u914d\u7f6e\u200b\uff0c\u200b\u5728\u200b Linux/macOS \u200b\u7cfb\u7edf\u200b\u4e0a\u200b\u901a\u5e38\u200b\u89e3\u6790\u200b\u4e3a\u200b <code>~/.MyOCR/models/</code> \u200b\u76ee\u5f55\u200b\u3002\u200b\u6d41\u6c34\u7ebf\u200b\u914d\u7f6e\u6587\u4ef6\u200b (<code>myocr/pipelines/config/*.yaml</code>) \u200b\u4e2d\u200b\u5f15\u7528\u200b\u7684\u200b\u6a21\u578b\u200b\u6587\u4ef6\u540d\u200b\u90fd\u200b\u662f\u200b\u76f8\u5bf9\u200b\u4e8e\u200b\u6b64\u200b\u76ee\u5f55\u200b\u7684\u200b\u3002\u200b\u5982\u679c\u200b\u60a8\u200b\u60f3\u200b\u5c06\u200b\u6a21\u578b\u200b\u5b58\u50a8\u200b\u5728\u200b\u5176\u4ed6\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u53ef\u4ee5\u200b\u66f4\u6539\u200b <code>MODEL_PATH</code> \u200b\u503c\u200b\uff0c\u200b\u6216\u200b\u5728\u200b YAML \u200b\u914d\u7f6e\u200b\u4e2d\u200b\u4f7f\u7528\u200b\u7edd\u5bf9\u8def\u5f84\u200b\u3002</p>"},{"location":"zh/faq/#cpu-gpu","title":"\u95ee\u200b\uff1a\u200b\u5982\u4f55\u200b\u5728\u200b CPU \u200b\u548c\u200b GPU \u200b\u63a8\u7406\u200b\u4e4b\u95f4\u200b\u5207\u6362\u200b\uff1f","text":"<p>\u200b\u7b54\u200b\uff1a \u200b\u5728\u200b\u521d\u59cb\u5316\u200b\u6d41\u6c34\u7ebf\u200b\u6216\u200b\u6a21\u578b\u200b\u65f6\u200b\uff0c\u200b\u4f20\u5165\u200b\u4e00\u4e2a\u200b\u6765\u81ea\u200b <code>myocr.modeling.model</code> \u200b\u7684\u200b <code>Device</code> \u200b\u5bf9\u8c61\u200b\u5373\u53ef\u200b\u3002</p> <ul> <li> <p>\u200b\u4f7f\u7528\u200b GPU\uff08\u200b\u524d\u63d0\u200b\u662f\u200b\u5df2\u200b\u6b63\u786e\u200b\u914d\u7f6e\u200b CUDA\uff09\uff1a<code>Device('cuda:0')</code>\uff08\u200b\u5bf9\u5e94\u200b\u7b2c\u4e00\u4e2a\u200b GPU\uff09\u3002</p> </li> <li> <p>\u200b\u4f7f\u7528\u200b CPU\uff1a<code>Device('cpu')</code>\u3002</p> </li> </ul> <p>\u200b\u8bf7\u200b\u786e\u4fdd\u200b\u5b89\u88c5\u200b\u4e86\u200b\u6b63\u786e\u200b\u7248\u672c\u200b\u7684\u200b <code>onnxruntime</code> \u200b\u5305\u200b\uff08CPU \u200b\u7248\u672c\u200b\u7528\u200b <code>onnxruntime</code>\uff0cGPU \u200b\u7248\u672c\u200b\u7528\u200b <code>onnxruntime-gpu</code>\uff09\uff0c\u200b\u5e76\u4e14\u200b\u5728\u200b\u4f7f\u7528\u200b GPU \u200b\u65f6\u200b\u5b89\u88c5\u200b\u4e86\u200b\u517c\u5bb9\u200b\u7684\u200b CUDA \u200b\u9a71\u52a8\u7a0b\u5e8f\u200b\u3002</p>"},{"location":"zh/faq/#structuredoutputocrpipeline","title":"\u95ee\u200b\uff1a<code>StructuredOutputOCRPipeline</code> \u200b\u4e0d\u200b\u5de5\u4f5c\u200b\u6216\u200b\u51fa\u73b0\u200b\u9519\u8bef\u200b\uff0c\u200b\u8be5\u200b\u600e\u4e48\u529e\u200b\uff1f","text":"<p>\u200b\u7b54\u200b\uff1a \u200b\u8fd9\u4e2a\u200b\u6d41\u6c34\u7ebf\u200b\u4f9d\u8d56\u4e8e\u200b\u5916\u90e8\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b (LLM)\uff0c\u200b\u8bf7\u200b\u68c0\u67e5\u200b\u4ee5\u4e0b\u51e0\u70b9\u200b\uff1a</p> <ol> <li> <p>\u200b\u914d\u7f6e\u200b\u68c0\u67e5\u200b\uff1a \u200b\u786e\u4fdd\u200b <code>myocr/pipelines/config/structured_output_pipeline.yaml</code> \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u5df2\u200b\u4e3a\u200b\u60a8\u200b\u9009\u62e9\u200b\u7684\u200b LLM \u200b\u63d0\u4f9b\u5546\u200b\uff08\u200b\u5982\u200b OpenAI\u3001Ollama \u200b\u6216\u200b\u672c\u5730\u200b\u670d\u52a1\u5668\u200b\uff09\u200b\u6b63\u786e\u200b\u914d\u7f6e\u200b\u4e86\u200b <code>model</code>\u3001<code>base_url</code> \u200b\u548c\u200b <code>api_key</code> \u200b\u53c2\u6570\u200b\u3002</p> </li> <li> <p>API \u200b\u5bc6\u94a5\u200b\uff1a \u200b\u786e\u4fdd\u200b API \u200b\u5bc6\u94a5\u200b\u5df2\u200b\u6b63\u786e\u200b\u8bbe\u7f6e\u200b\uff08\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u5728\u200b YAML \u200b\u4e2d\u200b\u6307\u5b9a\u200b\uff0c\u200b\u6216\u200b\u901a\u8fc7\u200b YAML \u200b\u6307\u5411\u200b\u7684\u200b\u73af\u5883\u53d8\u91cf\u200b\uff0c\u200b\u5982\u200b <code>OPENAI_API_KEY</code>\uff09\u3002</p> </li> <li> <p>\u200b\u8fde\u63a5\u200b\u68c0\u67e5\u200b\uff1a \u200b\u9a8c\u8bc1\u200b\u60a8\u200b\u7684\u200b\u73af\u5883\u200b\u80fd\u591f\u200b\u8bbf\u95ee\u200b LLM API \u200b\u7684\u200b <code>base_url</code>\u3002</p> </li> <li> <p>Schema \u200b\u9a8c\u8bc1\u200b\uff1a \u200b\u786e\u4fdd\u200b\u521d\u59cb\u5316\u200b\u65f6\u200b\u4f20\u5165\u200b\u7684\u200b Pydantic <code>json_schema</code> \u200b\u6709\u6548\u200b\uff0c\u200b\u5e76\u4e14\u200b\u5404\u5b57\u6bb5\u200b\u63cf\u8ff0\u200b\u80fd\u200b\u5145\u5206\u200b\u6307\u5bfc\u200b LLM \u200b\u7406\u89e3\u200b\u60a8\u200b\u7684\u200b\u9700\u6c42\u200b\u3002</p> </li> </ol>"},{"location":"zh/faq/#predictor-pipeline","title":"\u95ee\u200b\uff1aPredictor\uff08\u200b\u9884\u6d4b\u5668\u200b\uff09\u200b\u548c\u200b Pipeline\uff08\u200b\u6d41\u6c34\u7ebf\u200b\uff09\u200b\u6709\u200b\u4ec0\u4e48\u200b\u533a\u522b\u200b\uff1f","text":"<p>\u200b\u7b54\u200b\uff1a</p> <ul> <li> <p>\u200b\u9884\u6d4b\u5668\u200b\uff1a \u200b\u5e95\u5c42\u200b\u7ec4\u4ef6\u200b\uff0c\u200b\u5b83\u200b\u5c01\u88c5\u200b\u4e86\u200b\u5355\u4e2a\u200b <code>Model</code> \u200b\u53ca\u5176\u200b\u7279\u5b9a\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u548c\u200b\u540e\u5904\u7406\u200b\u903b\u8f91\u200b\uff08\u200b\u5728\u200b <code>CompositeProcessor</code> \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\uff09\u3002\u200b\u9884\u6d4b\u5668\u200b\u4e13\u6ce8\u200b\u4e8e\u200b\u5904\u7406\u200b\u5355\u4e00\u200b\u4efb\u52a1\u200b\uff08\u200b\u5982\u200b\u6587\u672c\u200b\u68c0\u6d4b\u200b\uff09\u3002</p> </li> <li> <p>\u200b\u6d41\u6c34\u7ebf\u200b\uff1a \u200b\u9ad8\u5c42\u200b\u7ec4\u4ef6\u200b\uff0c\u200b\u5b83\u200b\u534f\u8c03\u200b\u591a\u4e2a\u200b <code>Predictors</code> \u200b\u6765\u200b\u5b8c\u6210\u200b\u4e00\u4e2a\u200b\u5b8c\u6574\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6d41\u200b\uff08\u200b\u5982\u200b\u7ed3\u5408\u200b\u68c0\u6d4b\u200b\u3001\u200b\u5206\u7c7b\u200b\u548c\u200b\u8bc6\u522b\u200b\u7684\u200b\u7aef\u200b\u5230\u200b\u7aef\u200b OCR\uff09\u3002\u200b\u6d41\u6c34\u7ebf\u200b\u4e3a\u200b\u7528\u6237\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u5904\u7406\u200b\u5e38\u89c1\u200b\u4efb\u52a1\u200b\u7684\u200b\u4e3b\u8981\u200b\u63a5\u53e3\u200b\u3002</p> </li> </ul>"},{"location":"zh/faq/#_1","title":"\u95ee\u200b\uff1a\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b\u81ea\u5df1\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff1f","text":"<p>\u200b\u7b54\u200b\uff1a</p> <ul> <li> <p>ONNX \u200b\u6a21\u578b\u200b\uff1a \u200b\u5c06\u200b\u60a8\u200b\u7684\u200b <code>.onnx</code> \u200b\u6587\u4ef6\u200b\u653e\u5165\u200b\u6a21\u578b\u200b\u76ee\u5f55\u200b\uff0c\u200b\u7136\u540e\u200b\u66f4\u65b0\u200b\u76f8\u5173\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u914d\u7f6e\u200b YAML \u200b\u6587\u4ef6\u200b (<code>myocr/pipelines/config/*.yaml</code>)\uff0c\u200b\u4f7f\u200b\u5176\u200b\u6307\u5411\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u6587\u4ef6\u200b\u3002\u200b\u8be6\u60c5\u200b\u8bf7\u53c2\u9605\u200b \u200b\u6982\u89c8\u200b \u200b\u90e8\u5206\u200b\u3002</p> </li> <li> <p>\u200b\u81ea\u5b9a\u4e49\u200b PyTorch \u200b\u6a21\u578b\u200b\uff1a \u200b\u4f7f\u7528\u200b <code>myocr/modeling/</code> \u200b\u76ee\u5f55\u200b\u4e2d\u200b\u7684\u200b\u7ec4\u4ef6\u200b\uff08\u200b\u4e3b\u5e72\u200b\u7f51\u7edc\u200b\u3001\u200b\u9888\u90e8\u200b\u3001\u200b\u5934\u90e8\u200b\u6a21\u5757\u200b\uff09\u200b\u5b9a\u4e49\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\uff0c\u200b\u5e76\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u63cf\u8ff0\u200b\u8be5\u200b\u67b6\u6784\u200b\u7684\u200b YAML \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u3002\u200b\u7136\u540e\u200b\u4f7f\u7528\u200b <code>ModelLoader().load(model_format='custom', ...)</code> \u200b\u52a0\u8f7d\u200b\u5b83\u200b\uff0c\u200b\u6216\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b/\u200b\u9884\u6d4b\u5668\u200b\u3002\u200b\u5173\u4e8e\u200b <code>CustomModel</code> \u200b\u548c\u200b YAML \u200b\u914d\u7f6e\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b \u200b\u6a21\u578b\u200b\u6587\u6863\u200b\u3002</p> </li> </ul>"},{"location":"zh/getting-started/installation/","title":"\u5b89\u88c5\u200b\u6307\u5357","text":"<p>\u200b\u672c\u200b\u6307\u5357\u200b\u4ecb\u7ecd\u200b\u4e86\u200b\u5b89\u88c5\u200b MyOCR \u200b\u53ca\u5176\u200b\u4f9d\u8d56\u200b\u9879\u200b\u7684\u200b\u5fc5\u8981\u200b\u6b65\u9aa4\u200b\u3002</p>"},{"location":"zh/getting-started/installation/#_2","title":"\u7cfb\u7edf\u200b\u8981\u6c42","text":"<ul> <li>Python: \u200b\u9700\u8981\u200b 3.11 \u200b\u6216\u200b\u66f4\u200b\u9ad8\u200b\u7248\u672c\u200b\u3002</li> <li>CUDA: \u200b\u5982\u679c\u200b\u9700\u8981\u200b GPU \u200b\u52a0\u901f\u200b\uff0c\u200b\u63a8\u8350\u200b\u4f7f\u7528\u200b 12.6 \u200b\u6216\u200b\u66f4\u200b\u9ad8\u200b\u7248\u672c\u200b\u3002\u200b\u4e5f\u200b\u652f\u6301\u200b\u4ec5\u200b CPU \u200b\u6a21\u5f0f\u200b\u3002</li> <li>\u200b\u64cd\u4f5c\u7cfb\u7edf\u200b: \u200b\u652f\u6301\u200b Linux\u3001macOS \u200b\u6216\u200b Windows\u3002</li> </ul>"},{"location":"zh/getting-started/installation/#_3","title":"\u5b89\u88c5\u200b\u6b65\u9aa4","text":"<ol> <li> <p>\u200b\u514b\u9686\u200b\u4ee3\u7801\u200b\u4ed3\u5e93\u200b:</p> <pre><code>git clone https://github.com/robbyzhaox/myocr.git\ncd myocr\n</code></pre> </li> <li> <p>\u200b\u5b89\u88c5\u200b\u4f9d\u8d56\u200b\u9879\u200b:</p> <ul> <li>\u200b\u6807\u51c6\u200b\u5b89\u88c5\u200b: <pre><code># \u200b\u5b89\u88c5\u200b\u8f6f\u4ef6\u5305\u200b\u53ca\u5176\u200b\u5fc5\u9700\u200b\u7684\u200b\u4f9d\u8d56\u200b\u9879\u200b\npip install -e .\n</code></pre></li> <li>\u200b\u5f00\u53d1\u200b\u73af\u5883\u200b\u5b89\u88c5\u200b (\u200b\u5305\u62ec\u200b\u6d4b\u8bd5\u200b\u3001\u200b\u4ee3\u7801\u200b\u68c0\u67e5\u200b\u7b49\u200b\u5de5\u5177\u200b): <pre><code># \u200b\u5b89\u88c5\u200b\u6807\u51c6\u200b\u4f9d\u8d56\u200b\u9879\u53ca\u200b\u5f00\u53d1\u5de5\u5177\u200b\npip install -e \".[dev]\"\n\n# \u200b\u5b89\u88c5\u200b\u6587\u6863\u200b\u76f8\u5173\u200b\u4f9d\u8d56\u200b\u9879\u200b\npip install -e \".[docs]\"\n</code></pre></li> </ul> </li> <li> <p>\u200b\u4e0b\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b:</p> <p>MyOCR \u200b\u7684\u200b\u9ed8\u8ba4\u200b\u6d41\u6c34\u7ebf\u200b\u4f9d\u8d56\u4e8e\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6a21\u578b\u200b\uff0c\u200b\u9700\u8981\u200b\u624b\u52a8\u200b\u4e0b\u8f7d\u200b\u8fd9\u4e9b\u200b\u6a21\u578b\u200b\u3002</p> <pre><code># \u200b\u5982\u679c\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u76ee\u5f55\u200b\u4e0d\u200b\u5b58\u5728\u200b\uff0c\u200b\u521b\u5efa\u200b\u8be5\u200b\u76ee\u5f55\u200b\n# \u200b\u5728\u200b Linux/macOS \u200b\u7cfb\u7edf\u200b\u4e0a\u200b:\nmkdir -p ~/.MyOCR/models/\n# \u200b\u5728\u200b Windows \u200b\u7cfb\u7edf\u200b\u4e0a\u200b (\u200b\u4f7f\u7528\u200b Git Bash \u200b\u6216\u200b\u7c7b\u4f3c\u200b\u5de5\u5177\u200b):\n# mkdir -p ~/AppData/Local/MyOCR/models/\n# \u200b\u6216\u8005\u200b\u76f4\u63a5\u200b\u5728\u200b\u5f53\u524d\u200b\u8def\u5f84\u200b\u521b\u5efa\u200bmodels\u200b\u76ee\u5f55\u200b\n# \u200b\u6ce8\u610f\u200b: \u200b\u5982\u200b\u9700\u8981\u200b\uff0c\u200b\u8bf7\u200b\u6839\u636e\u200b\u60a8\u200b\u7684\u200b\u73af\u5883\u200b\u8c03\u6574\u200b Windows \u200b\u8def\u5f84\u200b\u3002\n\n# \u200b\u4ece\u200b\u4ee5\u4e0b\u200b\u94fe\u63a5\u200b\u4e0b\u8f7d\u200b\u6a21\u578b\u200b\u5230\u200bmodels\u200b\u76ee\u5f55\u200b\n# https://drive.google.com/drive/folders/1RXppgx4XA_pBX9Ll4HFgWyhECh5JtHnY\n# \u200b\u6216\u8005\u200b\n# https://pan.baidu.com/s/122p9zqepWfbEmZPKqkzGBA?pwd=yq6j\n</code></pre> <ul> <li>\u200b\u6ce8\u610f\u200b: MyOCR \u200b\u9ed8\u8ba4\u200b\u4ece\u200b <code>~/.MyOCR/models/</code> \u200b\u76ee\u5f55\u200b\u67e5\u627e\u200b\u6a21\u578b\u200b\u3002\u200b\u6b64\u200b\u8def\u5f84\u200b\u5728\u200b <code>myocr/config.py</code> \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u3002\u200b\u5982\u679c\u200b\u9700\u8981\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4fee\u6539\u200b\u6b64\u200b\u914d\u7f6e\u200b\u6216\u200b\u5c06\u200b\u6a21\u578b\u200b\u653e\u5728\u200b\u5176\u4ed6\u200b\u4f4d\u7f6e\u200b\uff0c\u200b\u4f46\u200b\u8fd9\u6837\u200b\u60a8\u200b\u9700\u8981\u200b\u76f8\u5e94\u200b\u5730\u200b\u8c03\u6574\u200b\u6d41\u6c34\u7ebf\u200b\u914d\u7f6e\u6587\u4ef6\u200b (<code>myocr/pipelines/config/*.yaml</code>) \u200b\u4e2d\u200b\u7684\u200b\u8def\u5f84\u200b\u3002</li> </ul> </li> </ol>"},{"location":"zh/getting-started/installation/#_4","title":"\u540e\u7eed\u200b\u6b65\u9aa4","text":"<p>\u200b\u5b8c\u6210\u200b\u5b89\u88c5\u200b\u5e76\u200b\u4e0b\u8f7d\u200b\u6a21\u578b\u200b\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u7ee7\u7eed\u200b\uff1a</p> <ul> <li>\u200b\u63a8\u7406\u200b\u6307\u5357\u200b: \u200b\u67e5\u770b\u200b\u4f7f\u7528\u200b MyOCR \u200b\u8fd0\u884c\u200b OCR \u200b\u4efb\u52a1\u200b\u7684\u200b\u793a\u4f8b\u200b\u3002</li> </ul>"},{"location":"zh/getting-started/overview/","title":"\u6982\u89c8","text":"<p>MyOCR \u200b\u662f\u200b\u4e00\u4e2a\u200b\u529f\u80fd\u5f3a\u5927\u200b\u4e14\u200b\u7075\u6d3b\u200b\u7684\u200b\u6846\u67b6\u200b\uff0c\u200b\u4e13\u200b\u4e3a\u200b\u5e2e\u52a9\u200b\u5f00\u53d1\u8005\u200b\u6784\u5efa\u200b\u548c\u200b\u90e8\u7f72\u200b\u81ea\u5b9a\u4e49\u200b OCR \u200b\u65b9\u6848\u200b\u800c\u200b\u8bbe\u8ba1\u200b\uff0c\u200b\u540c\u65f6\u200b\u517c\u987e\u200b\u4e86\u200b\u751f\u4ea7\u200b\u53ef\u7528\u6027\u200b\u4e0e\u200b\u5f00\u53d1\u200b\u4f53\u9a8c\u200b\u3002\u200b\u8be5\u5e93\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u5957\u200b\u9ad8\u5c42\u6b21\u200b\u7684\u200b\u7ec4\u4ef6\u200b\u67b6\u6784\u200b\uff0c\u200b\u4fbf\u4e8e\u200b\u5feb\u901f\u200b\u96c6\u6210\u200b\u4e0e\u200b\u6269\u5c55\u200b\u3002</p>"},{"location":"zh/getting-started/overview/#_2","title":"\u6838\u5fc3\u200b\u7ec4\u4ef6","text":"<p>MyOCR \u200b\u56f4\u7ed5\u200b\u4ee5\u4e0b\u200b\u5173\u952e\u200b\u6982\u5ff5\u200b\u6784\u5efa\u200b\uff1a</p> <p></p> <ul> <li>\u200b\u6a21\u578b\u200b (Model): \u200b\u8868\u793a\u200b\u4e00\u4e2a\u200b\u795e\u7ecf\u7f51\u7edc\u200b\u6a21\u578b\u200b\u3002MyOCR \u200b\u652f\u6301\u200b\u52a0\u8f7d\u200b ONNX \u200b\u6a21\u578b\u200b (<code>OrtModel</code>)\u3001\u200b\u6807\u51c6\u200b PyTorch \u200b\u6a21\u578b\u200b (<code>PyTorchModel</code>) \u200b\u4ee5\u53ca\u200b\u901a\u8fc7\u200b YAML \u200b\u914d\u7f6e\u200b\u5b9a\u4e49\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b PyTorch \u200b\u6a21\u578b\u200b (<code>CustomModel</code>)\u3002\u200b\u6a21\u578b\u200b\u8d1f\u8d23\u200b\u6267\u884c\u200b\u6838\u5fc3\u200b\u8ba1\u7b97\u200b\u3002<ul> <li>\u200b\u66f4\u200b\u591a\u200b\u8be6\u60c5\u200b\u8bf7\u53c2\u9605\u200b \u200b\u6a21\u578b\u200b\u90e8\u5206\u200b\u3002</li> </ul> </li> <li>\u200b\u5904\u7406\u5668\u200b (<code>CompositeProcessor</code>): \u200b\u8d1f\u8d23\u200b\u4e3a\u200b\u6a21\u578b\u200b\u51c6\u5907\u200b\u8f93\u5165\u200b\u6570\u636e\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u539f\u59cb\u200b\u8f93\u51fa\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u66f4\u200b\u6613\u7528\u200b\u7684\u200b\u683c\u5f0f\u200b\u3002\u200b\u6bcf\u4e2a\u200b\u9884\u6d4b\u5668\u200b\u90fd\u200b\u914d\u5907\u200b\u4e86\u200b\u7279\u5b9a\u200b\u7684\u200b\u5904\u7406\u5668\u200b\u3002<ul> <li>\u200b\u5904\u7406\u5668\u200b\u8be6\u60c5\u200b\u8bf7\u53c2\u9605\u200b \u200b\u9884\u6d4b\u5668\u200b\u90e8\u5206\u200b\u3002</li> </ul> </li> <li>\u200b\u9884\u6d4b\u5668\u200b (Predictor): \u200b\u5c06\u200b\u4e00\u4e2a\u200b <code>Model</code> \u200b\u548c\u200b\u4e00\u4e2a\u200b <code>Processor</code> \u200b\u7ed3\u5408\u200b\u8d77\u6765\u200b\u6267\u884c\u200b\u7279\u5b9a\u200b\u7684\u200b\u63a8\u7406\u200b\u4efb\u52a1\u200b\uff08\u200b\u5982\u200b\u6587\u672c\u200b\u68c0\u6d4b\u200b\uff09\u3002\u200b\u5b83\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u7528\u6237\u200b\u53cb\u597d\u200b\u7684\u200b\u63a5\u53e3\u200b\uff0c\u200b\u63a5\u53d7\u200b\u6807\u51c6\u200b\u8f93\u5165\u200b\uff08\u200b\u5982\u200b PIL \u200b\u56fe\u50cf\u200b\uff09\u200b\u5e76\u200b\u8fd4\u56de\u200b\u5904\u7406\u200b\u540e\u200b\u7684\u200b\u7ed3\u679c\u200b\uff08\u200b\u5982\u200b\u8fb9\u754c\u200b\u6846\u200b\uff09\u3002<ul> <li>\u200b\u53ef\u7528\u200b\u9884\u6d4b\u5668\u200b\u5217\u8868\u200b\u8bf7\u53c2\u9605\u200b \u200b\u9884\u6d4b\u5668\u200b\u90e8\u5206\u200b\u3002</li> </ul> </li> <li>\u200b\u6d41\u6c34\u7ebf\u200b (Pipeline): \u200b\u534f\u8c03\u200b\u591a\u4e2a\u200b <code>Predictors</code> \u200b\u6765\u200b\u6267\u884c\u200b\u590d\u6742\u200b\u7684\u200b\u591a\u200b\u6b65\u9aa4\u200b\u4efb\u52a1\u200b\uff0c\u200b\u5982\u7aef\u200b\u5230\u200b\u7aef\u200b OCR\u3002\u200b\u6d41\u6c34\u7ebf\u200b\u4e3a\u200b\u6700\u200b\u5e38\u89c1\u200b\u7684\u200b\u7528\u4f8b\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u6700\u9ad8\u200b\u5c42\u6b21\u200b\u7684\u200b\u63a5\u53e3\u200b\u3002<ul> <li>\u200b\u53ef\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u5217\u8868\u200b\u8bf7\u53c2\u9605\u200b \u200b\u6d41\u6c34\u7ebf\u200b\u90e8\u5206\u200b\u3002</li> </ul> </li> </ul> <p>\u200b\u7c7b\u56fe\u200b </p>"},{"location":"zh/getting-started/overview/#_3","title":"\u5b9a\u5236\u200b\u4e0e\u200b\u6269\u5c55","text":"<p>MyOCR \u200b\u7684\u200b\u6a21\u5757\u5316\u200b\u8bbe\u8ba1\u200b\u8ba9\u200b\u5b9a\u5236\u200b\u53d8\u5f97\u200b\u7b80\u5355\u200b\uff1a</p> <ul> <li>\u200b\u6dfb\u52a0\u200b\u65b0\u200b\u6a21\u578b\u200b: \u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u901a\u8fc7\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u5668\u200b\u5f15\u5165\u200b\u65b0\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u9884\u6d4b\u5668\u200b: \u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u5229\u7528\u200b <code>Model</code> \u200b\u548c\u200b <code>CompositeProcessor</code> \u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b <code>Predictor</code>\u3002</li> <li>\u200b\u6784\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b: \u200b\u4e86\u89e3\u200b\u5982\u4f55\u200b\u5c06\u200b\u591a\u4e2a\u200b <code>Predictor</code> \u200b\u7ec4\u5408\u6210\u200b\u5b8c\u6574\u200b\u7684\u200b <code>Pipeline</code>\u3002</li> </ul>"},{"location":"zh/inference/local/","title":"\u672c\u5730\u200b\u63a8\u7406","text":"<p>\u200b\u672c\u200b\u8282\u200b\u63cf\u8ff0\u200b\u5982\u4f55\u200b\u4f7f\u7528\u200b MyOCR \u200b\u5e93\u200b\u6267\u884c\u200b\u63a8\u7406\u200b\uff0c\u200b\u4e3b\u8981\u200b\u901a\u8fc7\u200b\u4f7f\u7528\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u3002</p>"},{"location":"zh/inference/local/#_2","title":"\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\u8fdb\u884c\u200b\u63a8\u7406","text":"<p>\u200b\u6267\u884c\u200b\u7aef\u5230\u200b\u7aef\u200b OCR \u200b\u7684\u200b\u63a8\u8350\u200b\u65b9\u6cd5\u200b\u662f\u200b\u901a\u8fc7\u200b <code>myocr.pipelines</code> \u200b\u4e2d\u200b\u63d0\u4f9b\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u7c7b\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u6d41\u6c34\u7ebf\u200b\u5904\u7406\u200b\u5fc5\u8981\u200b\u6a21\u578b\u200b\u7684\u200b\u52a0\u8f7d\u200b\u4ee5\u53ca\u200b\u68c0\u6d4b\u200b\u3001\u200b\u5206\u7c7b\u200b\u548c\u200b\u8bc6\u522b\u200b\u6b65\u9aa4\u200b\u7684\u200b\u7f16\u6392\u200b\u3002</p>"},{"location":"zh/inference/local/#commonocrpipeline-ocr","title":"\u4f7f\u7528\u200b <code>CommonOCRPipeline</code> \u200b\u8fdb\u884c\u200b\u6807\u51c6\u200b OCR","text":"<p>\u200b\u6b64\u200b\u6d41\u6c34\u7ebf\u200b\u9002\u7528\u200b\u4e8e\u200b\u901a\u7528\u200b OCR \u200b\u4efb\u52a1\u200b\uff0c\u200b\u76ee\u6807\u200b\u662f\u4ece\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u6240\u6709\u200b\u6587\u672c\u200b\u53ca\u5176\u200b\u4f4d\u7f6e\u200b\u3002</p> <pre><code>from myocr.pipelines import CommonOCRPipeline\n\n# Initialize common OCR pipeline (using GPU)\npipeline = CommonOCRPipeline(\"cuda:0\")  # Use \"cpu\" for CPU mode\n\n# Perform OCR recognition on an image\nresult = pipeline(\"path/to/your/image.jpg\")\nprint(result)\n</code></pre>"},{"location":"zh/inference/local/#structuredoutputocrpipeline","title":"\u4f7f\u7528\u200b <code>StructuredOutputOCRPipeline</code> \u200b\u8fdb\u884c\u200b\u7ed3\u6784\u5316\u200b\u6570\u636e\u200b\u63d0\u53d6","text":"<p>\u200b\u5f53\u200b\u60a8\u200b\u9700\u8981\u200b\u4ece\u200b\u6587\u6863\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u7279\u5b9a\u200b\u4fe1\u606f\u200b\u5e76\u200b\u6839\u636e\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b schema \u200b\u5c06\u200b\u5176\u200b\u683c\u5f0f\u5316\u200b\u4e3a\u200b JSON \u200b\u65f6\u200b\uff0c\u200b\u8bf7\u200b\u4f7f\u7528\u200b\u6b64\u200b\u6d41\u6c34\u7ebf\u200b\u3002</p> <pre><code>chat_bot:\n  model: qwen2.5:14b\n  base_url: http://127.0.0.1:11434/v1\n  api_key: 'key'\n</code></pre> <pre><code>from pydantic import BaseModel, Field\nfrom myocr.pipelines import StructuredOutputOCRPipeline\n\n# Define output data model, refer to:\nfrom myocr.pipelines.response_format import InvoiceModel\n\n# Initialize structured OCR pipeline\npipeline = StructuredOutputOCRPipeline(\"cuda:0\", InvoiceModel)\n\n# Process image and get structured data\nresult = pipeline(\"path/to/invoice.jpg\")\nprint(result.to_dict())\n</code></pre>"},{"location":"zh/inference/local/#_3","title":"\u76f4\u63a5\u200b\u4f7f\u7528\u200b\u9884\u6d4b\u5668\u200b\uff08\u200b\u9ad8\u7ea7\u200b\uff09","text":"<p>\u200b\u867d\u7136\u200b\u63a8\u8350\u200b\u4f7f\u7528\u200b\u6d41\u6c34\u7ebf\u200b\uff0c\u200b\u4f46\u200b\u5982\u679c\u200b\u60a8\u200b\u9700\u8981\u200b\u5bf9\u200b\u8fc7\u7a0b\u200b\u8fdb\u884c\u200b\u66f4\u200b\u7cbe\u7ec6\u200b\u7684\u200b\u63a7\u5236\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4ec5\u200b\u4f7f\u7528\u200b\u68c0\u6d4b\u200b\uff0c\u200b\u6216\u200b\u63d0\u4f9b\u200b\u9884\u5904\u7406\u200b\u8f93\u5165\u200b\uff09\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\u5355\u4e2a\u200b\u9884\u6d4b\u5668\u200b\u3002\u200b\u6709\u5173\u200b\u521d\u59cb\u5316\u200b\u548c\u200b\u4f7f\u7528\u200b\u6bcf\u4e2a\u200b\u9884\u6d4b\u5668\u200b/\u200b\u5904\u7406\u5668\u200b\u5bf9\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u9884\u6d4b\u5668\u200b\u90e8\u5206\u200b\u6587\u6863\u200b\u3002</p>"},{"location":"zh/inference/local/#_4","title":"\u6027\u80fd\u200b\u6ce8\u610f\u4e8b\u9879","text":"<ul> <li>\u200b\u8bbe\u5907\u200b\u9009\u62e9\u200b\uff1a \u200b\u4f7f\u7528\u200b\u652f\u6301\u200b CUDA \u200b\u7684\u200b GPU\uff08<code>Device('cuda:0')</code>\uff09\u200b\u6bd4\u200b CPU\uff08<code>Device('cpu')</code>\uff09\u200b\u663e\u8457\u200b\u52a0\u5feb\u200b\u63a8\u7406\u200b\u901f\u5ea6\u200b\u3002\u200b\u786e\u4fdd\u60a8\u200b\u5b89\u88c5\u200b\u4e86\u200b\u5fc5\u8981\u200b\u7684\u200b\u9a71\u52a8\u7a0b\u5e8f\u200b\u548c\u200b ONNX Runtime GPU \u200b\u6784\u5efa\u200b\u3002</li> <li>\u200b\u6a21\u578b\u200b\u9009\u62e9\u200b\uff1a \u200b\u6d41\u6c34\u7ebf\u200b YAML \u200b\u6587\u4ef6\u200b\u4e2d\u200b\u914d\u7f6e\u200b\u7684\u200b\u7279\u5b9a\u200b ONNX \u200b\u6a21\u578b\u200b\u4f1a\u200b\u5f71\u54cd\u200b\u6027\u80fd\u200b\u548c\u200b\u51c6\u786e\u6027\u200b\u3002</li> <li>\u200b\u6279\u5904\u7406\u200b\uff1a \u200b\u867d\u7136\u200b\u5f53\u524d\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u793a\u4f8b\u200b\u5904\u7406\u200b\u5355\u4e2a\u200b\u56fe\u50cf\u200b\uff0c\u200b\u4f46\u200b\u9884\u6d4b\u5668\u200b\u901a\u5e38\u200b\u5728\u200b\u5185\u90e8\u200b\u5904\u7406\u200b\u6279\u200b\u8f93\u5165\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5728\u200b\u8bc6\u522b\u200b\u4e2d\u200b\u540c\u65f6\u200b\u5904\u7406\u200b\u6240\u6709\u200b\u68c0\u6d4b\u200b\u5230\u200b\u7684\u200b\u6846\u200b\uff09\u3002\u200b\u5bf9\u4e8e\u200b\u5904\u7406\u200b\u5927\u91cf\u200b\u56fe\u50cf\u200b\uff0c\u200b\u5982\u679c\u200b\u9700\u8981\u200b\uff0c\u200b\u8003\u8651\u200b\u5728\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u7ea7\u522b\u200b\u8fdb\u884c\u200b\u5e76\u884c\u6267\u884c\u200b\u6216\u200b\u6279\u5904\u7406\u200b\u3002</li> </ul>"},{"location":"zh/inference/rest/","title":"\u901a\u8fc7\u200b REST API \u200b\u8fdb\u884c\u200b\u63a8\u7406","text":"<p>MyOCR \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u5185\u7f6e\u200b\u7684\u200b RESTful API \u200b\u670d\u52a1\u200b\uff0c\u200b\u8ba9\u200b\u60a8\u200b\u80fd\u591f\u200b\u901a\u8fc7\u200b HTTP \u200b\u8bf7\u6c42\u200b\u6267\u884c\u200b OCR \u200b\u4efb\u52a1\u200b\u3002\u200b\u8fd9\u200b\u5bf9\u4e8e\u200b\u5c06\u200b MyOCR \u200b\u96c6\u6210\u200b\u5230\u200b\u7f51\u9875\u200b\u5e94\u7528\u200b\u3001\u200b\u5fae\u200b\u670d\u52a1\u200b\u6216\u200b\u5176\u4ed6\u200b\u7f16\u7a0b\u8bed\u8a00\u200b\u4e2d\u200b\u7279\u522b\u200b\u6709\u7528\u200b\u3002</p> <p>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u8fd0\u884c\u200b\u6b64\u200b API \u200b\u670d\u52a1\u200b\u8fdb\u884c\u200b\u5f00\u53d1\u200b\uff0c\u200b\u6216\u8005\u200b\u4f7f\u7528\u200b Docker \u200b\u8fdb\u884c\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u90e8\u7f72\u200b\u3002</p>"},{"location":"zh/inference/rest/#_1","title":"\u65b9\u5f0f\u200b\u4e00\u200b\uff1a\u200b\u76f4\u63a5\u200b\u8fd0\u884c\u200b\uff08\u200b\u9002\u7528\u200b\u4e8e\u200b\u5f00\u53d1\u200b\u73af\u5883\u200b\uff09","text":"<p>\u200b\u6b64\u200b\u65b9\u6cd5\u200b\u4f1a\u200b\u76f4\u63a5\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u4e3b\u673a\u200b\u4e0a\u200b\u8fd0\u884c\u200b API \u200b\u670d\u52a1\u200b\uff0c\u200b\u901a\u5e38\u200b\u9002\u5408\u200b\u672c\u5730\u200b\u5f00\u53d1\u200b\u548c\u200b\u6d4b\u8bd5\u200b\u3002</p> <p>1. \u200b\u524d\u63d0\u6761\u4ef6\u200b\uff1a</p> <ul> <li>\u200b\u786e\u4fdd\u60a8\u200b\u5df2\u200b\u5b8c\u6210\u200b \u200b\u5b89\u88c5\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u5305\u62ec\u200b\u5b89\u88c5\u200b\u4f9d\u8d56\u200b\u9879\u200b\u548c\u200b\u4e0b\u8f7d\u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u786e\u4fdd\u60a8\u200b\u4f4d\u4e8e\u200b <code>myocr</code> \u200b\u9879\u76ee\u200b\u7684\u200b\u6839\u76ee\u5f55\u200b\u3002</li> </ul> <p>2. \u200b\u542f\u52a8\u200b\u670d\u52a1\u5668\u200b\uff1a</p> <pre><code># \u200b\u4f7f\u7528\u200b python \u200b\u542f\u52a8\u200b\u670d\u52a1\u5668\u200b\uff08\u200b\u8bf7\u200b\u67e5\u770b\u200b main.py \u200b\u4e86\u89e3\u200b\u786e\u5207\u200b\u7684\u200b\u4e3b\u673a\u200b/\u200b\u7aef\u53e3\u914d\u7f6e\u200b\uff09\n# \u200b\u8fd9\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u4f7f\u7528\u200b\u5f00\u53d1\u200b\u670d\u52a1\u5668\u200b\uff08\u200b\u5982\u200b Flask \u200b\u7684\u200b\u9ed8\u8ba4\u200b\u670d\u52a1\u5668\u200b\uff09\u200b\u548c\u200b\u9ed8\u8ba4\u200b\u7aef\u53e3\u200b\uff08\u200b\u5982\u200b 5000\uff09\npython main.py \n</code></pre> <ul> <li>\u200b\u670d\u52a1\u5668\u200b\u4f7f\u7528\u200b\u9879\u76ee\u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u7684\u200b\u6a21\u578b\u200b\u548c\u200b\u914d\u7f6e\u200b\u3002</li> <li>\u200b\u7aef\u53e3\u200b\u548c\u200b\u4e3b\u673a\u200b\u53d6\u51b3\u4e8e\u200b <code>main.py</code> \u200b\u7684\u200b\u914d\u7f6e\u200b\u65b9\u5f0f\u200b\u3002</li> <li>\u200b\u6ce8\u610f\u200b\uff1a \u200b\u5bf9\u4e8e\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\u90e8\u7f72\u200b\uff0c\u200b\u5efa\u8bae\u200b\u4f7f\u7528\u200b Docker \u200b\u548c\u200b Gunicorn\uff08\u200b\u65b9\u5f0f\u200b\u4e8c\u200b\uff09\u3002</li> </ul> <p>3. API \u200b\u7aef\u70b9\u200b\uff08\u200b\u793a\u4f8b\u200b\u4f7f\u7528\u200b\u7aef\u53e3\u200b 5000 - \u200b\u8bf7\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u8c03\u6574\u200b\uff09\uff1a</p> <ul> <li><code>GET /ping</code>\uff1a\u200b\u68c0\u67e5\u200b\u670d\u52a1\u200b\u662f\u5426\u200b\u6b63\u5728\u200b\u8fd0\u884c\u200b\u3002     <pre><code>curl http://127.0.0.1:5000/ping\n</code></pre></li> <li> <p><code>POST /ocr</code>\uff1a\u200b\u5bf9\u200b\u4e0a\u4f20\u200b\u7684\u200b\u56fe\u50cf\u200b\u6267\u884c\u200b\u57fa\u672c\u200b OCR\u3002</p> <ul> <li> <p>\u200b\u8bf7\u6c42\u200b\uff1a \u200b\u53d1\u9001\u200b\u4e00\u4e2a\u200b <code>POST</code> \u200b\u8bf7\u6c42\u200b\uff0c\u200b\u56fe\u50cf\u200b\u4ee5\u200b base64 \u200b\u7f16\u7801\u200b\u5b57\u7b26\u4e32\u200b\u5f62\u5f0f\u200b\u63d0\u4f9b\u200b\u3002 <pre><code>curl -X POST \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"image\": \"BASE64_IMAGE\"}'' \\\n    http://127.0.0.1:5000/ocr\n</code></pre></p> </li> <li> <p>\u200b\u54cd\u5e94\u200b\uff1a \u200b\u8fd4\u56de\u200b\u5305\u542b\u200b\u8bc6\u522b\u200b\u6587\u672c\u200b\u548c\u200b\u8fb9\u754c\u200b\u6846\u200b\u4fe1\u606f\u200b\u7684\u200b JSON \u200b\u5bf9\u8c61\u200b\uff08\u200b\u7c7b\u4f3c\u200b\u4e8e\u200b <code>CommonOCRPipeline</code> \u200b\u7684\u200b\u8f93\u51fa\u200b\uff09\u3002</p> </li> </ul> </li> <li> <p><code>POST /ocr-json</code>\uff1a\u200b\u6267\u884c\u200b OCR \u200b\u5e76\u200b\u6839\u636e\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b schema \u200b\u63d0\u53d6\u200b\u7ed3\u6784\u5316\u200b\u4fe1\u606f\u200b\u3002</p> <ul> <li>\u200b\u8bf7\u6c42\u200b\uff1a \u200b\u53d1\u9001\u200b\u4e00\u4e2a\u200b <code>POST</code> \u200b\u8bf7\u6c42\u200b\uff0c\u200b\u5305\u542b\u200b\u56fe\u50cf\u200b\u7684\u200b base64 \u200b\u5b57\u7b26\u4e32\u200b\u3002</li> </ul> <pre><code>curl -X POST \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"image\": \"BASE64_IMAGE\"}'' \\\n    http://127.0.0.1:5000/ocr-json\n</code></pre> <ul> <li>\u200b\u54cd\u5e94\u200b\uff1a \u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u7b26\u5408\u200b\u63d0\u4f9b\u200b schema \u200b\u7684\u200b JSON \u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u4ece\u200b\u56fe\u50cf\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u7684\u200b\u6570\u636e\u200b\u3002</li> </ul> </li> </ul> <p>4. \u200b\u53ef\u200b\u9009\u200b\u7528\u6237\u754c\u9762\u200b\uff1a</p> <p>\u200b\u6709\u200b\u4e00\u4e2a\u200b\u57fa\u4e8e\u200b Next.js \u200b\u7684\u200b\u72ec\u7acb\u200b\u7528\u6237\u754c\u9762\u200b\u53ef\u200b\u7528\u4e8e\u200b\u4e0e\u200b\u8fd9\u4e9b\u200b API \u200b\u7aef\u70b9\u200b\u4ea4\u4e92\u200b\uff1adoc-insight-ui\u3002</p>"},{"location":"zh/inference/rest/#docker","title":"\u65b9\u5f0f\u200b\u4e8c\u200b\uff1a\u200b\u4f7f\u7528\u200b Docker \u200b\u90e8\u7f72\u200b\uff08\u200b\u63a8\u8350\u200b\u7528\u4e8e\u200b\u751f\u4ea7\u200b\u73af\u5883\u200b\uff09","text":"<p>Docker \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u5bb9\u5668\u200b\u5316\u200b\u73af\u5883\u200b\u6765\u200b\u8fd0\u884c\u200b API \u200b\u670d\u52a1\u200b\uff0c\u200b\u786e\u4fdd\u200b\u4e86\u200b\u4e00\u81f4\u6027\u200b\u5e76\u200b\u5229\u7528\u200b Gunicorn \u200b\u63d0\u9ad8\u200b\u6027\u80fd\u200b\u3002</p> <p>1. \u200b\u524d\u63d0\u6761\u4ef6\u200b\uff1a</p> <ul> <li>\u200b\u5df2\u200b\u5b89\u88c5\u200b Docker\u3002</li> <li>\u200b\u5bf9\u4e8e\u200b GPU \u200b\u652f\u6301\u200b\uff1a\u200b\u5df2\u200b\u5b89\u88c5\u200b NVIDIA Container Toolkit\u3002</li> <li>\u200b\u5728\u200b\u6784\u5efa\u200b\u955c\u50cf\u200b\u524d\u200b\uff0c\u200b\u786e\u4fdd\u200b\u5df2\u200b\u5c06\u200b\u6a21\u578b\u200b\u4e0b\u8f7d\u200b\u5230\u200b\u4e3b\u673a\u200b\u4e0a\u200b\u7684\u200b\u9ed8\u8ba4\u200b\u4f4d\u7f6e\u200b (<code>~/.MyOCR/models/</code>)\uff0c\u200b\u56e0\u4e3a\u200b Docker \u200b\u6784\u5efa\u200b\u8fc7\u7a0b\u200b\u53ef\u80fd\u200b\u4f1a\u200b\u590d\u5236\u200b\u8fd9\u4e9b\u200b\u6587\u4ef6\u200b\u3002</li> </ul> <p>2. \u200b\u4f7f\u7528\u200b\u8f85\u52a9\u200b\u811a\u672c\u200b\u6784\u5efa\u200b Docker \u200b\u955c\u50cf\u200b\uff1a</p> <p>\u200b\u63a8\u8350\u200b\u4f7f\u7528\u200b\u63d0\u4f9b\u200b\u7684\u200b\u811a\u672c\u200b\u6765\u200b\u6784\u5efa\u200b\u955c\u50cf\u200b\uff0c\u200b\u5b83\u200b\u80fd\u200b\u81ea\u52a8\u200b\u5904\u7406\u200b\u6b63\u786e\u200b\u7684\u200b\u7248\u672c\u200b\u6807\u7b7e\u200b\u3002</p> <pre><code># \u200b\u786e\u4fdd\u200b\u811a\u672c\u200b\u5177\u6709\u200b\u6267\u884c\u200b\u6743\u9650\u200b\nchmod +x scripts/build_docker_image.sh\n\n# \u200b\u83b7\u53d6\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u7248\u672c\u200b\nVERSION=$(python -c 'import myocr.version; print(myocr.version.VERSION)')\n\n# \u200b\u6784\u5efa\u200b\u6240\u200b\u9700\u200b\u955c\u50cf\u200b\uff08\u200b\u5c06\u200b [cpu|gpu] \u200b\u66ff\u6362\u200b\u4e3a\u200b 'cpu' \u200b\u6216\u200b 'gpu'\uff09\nbash scripts/build_docker_image.sh [cpu|gpu]\n\n# \u200b\u793a\u4f8b\u200b\uff1a\u200b\u4e3a\u200b\u5f53\u524d\u200b\u7248\u672c\u200b\u6784\u5efa\u200b CPU \u200b\u955c\u50cf\u200b\n# bash scripts/build_docker_image.sh cpu \n\n# \u200b\u811a\u672c\u200b\u4f1a\u200b\u8f93\u51fa\u200b\u6700\u7ec8\u200b\u7684\u200b\u955c\u50cf\u200b\u6807\u7b7e\u200b\uff08\u200b\u4f8b\u5982\u200b myocr:cpu-0.1.0\uff09\n</code></pre> <p>3. \u200b\u8fd0\u884c\u200b Docker \u200b\u5bb9\u5668\u200b\uff1a</p> <p>\u200b\u4f7f\u7528\u200b\u6784\u5efa\u200b\u811a\u672c\u200b\u751f\u6210\u200b\u7684\u200b\u955c\u50cf\u200b\u6807\u7b7e\u200b\uff08\u200b\u5982\u200b <code>myocr:cpu-X.Y.Z</code> \u200b\u6216\u200b <code>myocr:gpu-X.Y.Z</code>\uff09\u3002\u200b\u5bb9\u5668\u200b\u5185\u200b\u7684\u200b\u670d\u52a1\u200b\u8fd0\u884c\u200b\u5728\u200b\u7aef\u53e3\u200b 8000 \u200b\u4e0a\u200b\u3002</p> <p>\u200b\u63d0\u793a\u200b</p> <p>\u200b\u6839\u636e\u200b\u9700\u8981\u200b\u8bbe\u7f6e\u200b\u4e0b\u5217\u200b\u73af\u5883\u53d8\u91cf\u200b\uff1a</p> <p>CHAT_BOT_MODEL=qwen2.5:14b</p> <p>CHAT_BOT_BASEURL=http://127.0.0.1:11434/v1</p> <p>CHAT_BOT_APIKEY=key</p> <ul> <li>GPU \u200b\u7248\u672c\u200b\uff08\u200b\u5c06\u200b $IMAGE_TAG \u200b\u66ff\u6362\u200b\u4e3a\u200b\u5b9e\u9645\u200b\u6807\u7b7e\u200b\uff09\uff1a <pre><code># \u200b\u793a\u4f8b\u200b: docker run -d --gpus all -p 8000:8000 --name myocr-service myocr:gpu-0.1.0\ndocker run -d --gpus all -p 8000:8000 --name myocr-service $IMAGE_TAG\n</code></pre></li> <li>CPU \u200b\u7248\u672c\u200b\uff08\u200b\u5c06\u200b $IMAGE_TAG \u200b\u66ff\u6362\u200b\u4e3a\u200b\u5b9e\u9645\u200b\u6807\u7b7e\u200b\uff09\uff1a <pre><code># \u200b\u793a\u4f8b\u200b: docker run -d -p 8000:8000 --name myocr-service myocr:cpu-0.1.0\ndocker run -d -p 8000:8000 --name myocr-service $IMAGE_TAG\n</code></pre></li> <li><code>-p 8000:8000</code> \u200b\u53c2\u6570\u200b\u5c06\u200b\u4e3b\u673a\u200b\u4e0a\u200b\u7684\u200b\u7aef\u53e3\u200b 8000 \u200b\u6620\u5c04\u200b\u5230\u200b\u5bb9\u5668\u200b\u5185\u200b\u7684\u200b\u7aef\u53e3\u200b 8000\u3002</li> </ul> <p>4. \u200b\u8bbf\u95ee\u200b API \u200b\u7aef\u70b9\u200b\uff08Docker\uff09\uff1a</p> <p>\u200b\u5bb9\u5668\u200b\u8fd0\u884c\u200b\u540e\u200b\uff0c\u200b\u4f7f\u7528\u200b\u4e3b\u673a\u200b\u7684\u200b IP/\u200b\u4e3b\u673a\u540d\u200b\uff08\u200b\u6216\u200b <code>localhost</code>\uff09\u200b\u548c\u200b\u6620\u5c04\u200b\u7684\u200b\u7aef\u53e3\u200b\uff08\u200b\u793a\u4f8b\u200b\u4e2d\u4e3a\u200b 8000\uff09\u200b\u8bbf\u95ee\u200b API \u200b\u7aef\u70b9\u200b\uff1a</p> <pre><code># Ping \u200b\u6d4b\u8bd5\u200b\ncurl http://localhost:8000/ping \n\n# \u200b\u56fe\u50cf\u200b base64 \u200b\u7f16\u7801\u200b\nIMAGE_PATH=\"your_image.jpg\"\n\nBASE64_IMAGE=$(base64 -w 0 \"$IMAGE_PATH\")  # Linux\n#BASE64_IMAGE=$(base64 -i \"$IMAGE_PATH\" | tr -d '\\n') # macOS\n\n# \u200b\u57fa\u672c\u200b OCR \u200b\u793a\u4f8b\u200b\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"image\\\": \\\"${BASE64_IMAGE}\\\"}\" \\\n  http://localhost:8000/ocr\n\n# \u200b\u7ed3\u6784\u5316\u200b OCR \u200b\u793a\u4f8b\u200b\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"image\\\": \\\"${BASE64_IMAGE}\\\"}\" \\\n  http://localhost:8000/ocr-json\n</code></pre> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u8bf7\u200b\u5c06\u200b <code>your_image.jpg</code> \u200b\u66ff\u6362\u200b\u4e3a\u200b\u60a8\u200b\u8fd0\u884c\u200b <code>curl</code> \u200b\u547d\u4ee4\u200b\u7684\u200b\u673a\u5668\u200b\u4e0a\u200b\u5b9e\u9645\u200b\u56fe\u50cf\u6587\u4ef6\u200b\u7684\u200b\u8def\u5f84\u200b\u3002 </p>"},{"location":"zh/models/","title":"\u6a21\u578b","text":"<p>\u200b\u672c\u200b\u8282\u200b\u63d0\u4f9b\u200b\u6709\u5173\u200b MyOCR \u200b\u9879\u76ee\u200b\u4e2d\u200b\u7528\u4e8e\u200b\u6587\u672c\u200b\u68c0\u6d4b\u200b\u3001\u200b\u8bc6\u522b\u200b\u548c\u200b\u65b9\u5411\u200b\u5206\u7c7b\u200b\u7b49\u200b\u4efb\u52a1\u200b\u7684\u200b\u6df1\u5ea6\u200b\u5b66\u4e60\u200b\u6a21\u578b\u200b\u7684\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u3002</p>"},{"location":"zh/models/#_2","title":"\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u4e0e\u200b\u7ba1\u7406","text":"<p>MyOCR \u200b\u5229\u7528\u200b <code>myocr/modeling/model.py</code> \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u7684\u200b\u7075\u6d3b\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u7cfb\u7edf\u200b\u3002\u200b\u5b83\u200b\u652f\u6301\u200b\u52a0\u8f7d\u200b\u4e0d\u540c\u200b\u683c\u5f0f\u200b\u7684\u200b\u6a21\u578b\u200b\uff1a</p> <ul> <li>ONNX (<code>OrtModel</code>): \u200b\u4f7f\u7528\u200b ONNX Runtime (<code>onnxruntime</code>) \u200b\u52a0\u8f7d\u200b\u5e76\u200b\u8fd0\u884c\u200b\u4f18\u5316\u200b\u540e\u200b\u7684\u200b\u6a21\u578b\u200b\u3002\u200b\u7531\u4e8e\u200b\u6027\u80fd\u200b\u4f18\u52bf\u200b\uff0c\u200b\u8fd9\u200b\u901a\u5e38\u200b\u662f\u200b\u63a8\u7406\u200b\u7684\u200b\u9996\u9009\u200b\u683c\u5f0f\u200b\u3002</li> <li>PyTorch (<code>PyTorchModel</code>): \u200b\u52a0\u8f7d\u200b\u6807\u51c6\u200b\u7684\u200b PyTorch \u200b\u6a21\u578b\u200b\uff0c\u200b\u53ef\u80fd\u200b\u5229\u7528\u200b\u6765\u81ea\u200b <code>torchvision</code> \u200b\u7b49\u5e93\u200b\u7684\u200b\u9884\u5b9a\u200b\u4e49\u200b\u67b6\u6784\u200b\u3002</li> <li>\u200b\u81ea\u5b9a\u4e49\u200b PyTorch (<code>CustomModel</code>): \u200b\u52a0\u8f7d\u200b\u901a\u8fc7\u200b YAML \u200b\u914d\u7f6e\u6587\u4ef6\u200b\u5b9a\u4e49\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b PyTorch \u200b\u6a21\u578b\u200b\u3002\u200b\u8fd9\u4e9b\u200b\u914d\u7f6e\u200b\u4f7f\u7528\u200b <code>myocr/modeling/</code> \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u7684\u200b\u7ec4\u4ef6\u200b\u6765\u200b\u6307\u5b9a\u200b\u6a21\u578b\u200b\u7684\u200b\u67b6\u6784\u200b\uff0c\u200b\u5305\u62ec\u200b\u4e3b\u5e72\u200b\u7f51\u7edc\u200b (backbones)\u3001\u200b\u9888\u90e8\u200b (necks) \u200b\u548c\u200b\u5934\u90e8\u200b (heads)\u3002</li> </ul> <p><code>ModelLoader</code> \u200b\u7c7b\u200b\u5145\u5f53\u200b\u5de5\u5382\u200b\uff0c\u200b\u6839\u636e\u200b\u6307\u5b9a\u200b\u7684\u200b\u683c\u5f0f\u200b (<code>onnx</code>, <code>pt</code>, <code>custom</code>) \u200b\u5b9e\u4f8b\u200b\u5316\u200b\u6b63\u786e\u200b\u7684\u200b\u6a21\u578b\u200b\u7c7b\u578b\u200b\u3002</p> <pre><code># \u200b\u793a\u4f8b\u200b (\u200b\u6982\u5ff5\u6027\u200b)\nfrom myocr.modeling.model import ModelLoader, Device\n\n# \u200b\u52a0\u8f7d\u200b\u7528\u4e8e\u200b CPU \u200b\u63a8\u7406\u200b\u7684\u200b ONNX \u200b\u6a21\u578b\u200b\nloader = ModelLoader()\nonnx_model = loader.load(model_format='onnx', model_name_path='path/to/your/model.onnx', device=Device('cpu'))\n\n# \u200b\u52a0\u8f7d\u200b\u7531\u200b YAML \u200b\u5b9a\u4e49\u200b\u7684\u200b\u7528\u4e8e\u200b GPU \u200b\u63a8\u7406\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\ncustom_model = loader.load(model_format='custom', model_name_path='path/to/your/config.yaml', device=Device('cuda:0'))\n</code></pre>"},{"location":"zh/models/#_3","title":"\u6a21\u578b\u200b\u67b6\u6784","text":"<p><code>myocr/modeling/</code> \u200b\u76ee\u5f55\u200b\u5305\u542b\u200b\u4e86\u200b\u6784\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u7684\u200b\u57fa\u77f3\u200b\uff1a</p> <ul> <li><code>architectures/</code>: \u200b\u5b9a\u4e49\u200b\u8fde\u63a5\u200b\u4e3b\u5e72\u200b\u7f51\u7edc\u200b\u3001\u200b\u9888\u90e8\u200b\u548c\u200b\u5934\u90e8\u200b\u7684\u200b\u6574\u4f53\u200b\u7ed3\u6784\u200b\uff08\u200b\u4f8b\u5982\u200b <code>DBNet</code>, <code>CRNN</code>\uff09\u3002</li> <li><code>backbones/</code>: \u200b\u5305\u542b\u200b\u7279\u5f81\u63d0\u53d6\u200b\u7f51\u7edc\u200b\uff08\u200b\u4f8b\u5982\u200b <code>ResNet</code>, <code>MobileNetV3</code>\uff09\u3002</li> <li><code>necks/</code>: \u200b\u5305\u62ec\u200b\u7279\u5f81\u200b\u878d\u5408\u200b\u6a21\u5757\u200b\uff08\u200b\u4f8b\u5982\u200b <code>FPN</code> - \u200b\u7279\u5f81\u200b\u91d1\u5b57\u5854\u200b\u7f51\u7edc\u200b\uff09\u3002</li> <li><code>heads/</code>: \u200b\u5b9a\u4e49\u200b\u8d1f\u8d23\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u7684\u200b\u6700\u7ec8\u200b\u5c42\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u68c0\u6d4b\u200b\u6982\u7387\u200b\u56fe\u200b\u3001\u200b\u5e8f\u5217\u200b\u89e3\u7801\u200b\uff09\u3002</li> </ul>"},{"location":"zh/models/#_4","title":"\u53ef\u7528\u200b\u6a21\u578b","text":""},{"location":"zh/models/#dbnet","title":"\u6587\u672c\u200b\u68c0\u6d4b\u200b (DBNet++)","text":"<ul> <li>DBNet++: \u200b\u57fa\u4e8e\u200b DBNet \u200b\u67b6\u6784\u200b\u7684\u200b\u6700\u200b\u5148\u8fdb\u200b\u7684\u200b\u6587\u672c\u200b\u68c0\u6d4b\u200b\u6a21\u578b\u200b</li> <li>\u200b\u8f93\u5165\u200b\uff1aRGB \u200b\u56fe\u50cf\u200b</li> <li>\u200b\u8f93\u51fa\u200b\uff1a\u200b\u6587\u672c\u200b\u533a\u57df\u200b\u591a\u8fb9\u5f62\u200b</li> <li>\u200b\u7279\u70b9\u200b\uff1a<ul> <li>\u200b\u5bf9\u200b\u4efb\u610f\u200b\u5f62\u72b6\u200b\u6587\u672c\u200b\u7684\u200b\u9ad8\u7cbe\u5ea6\u200b</li> <li>\u200b\u5feb\u901f\u200b\u63a8\u7406\u200b\u901f\u5ea6\u200b</li> <li>\u200b\u5bf9\u200b\u5404\u79cd\u200b\u6587\u672c\u200b\u65b9\u5411\u200b\u7684\u200b\u9c81\u68d2\u6027\u200b</li> </ul> </li> <li>\u200b\u67b6\u6784\u200b\uff1a     <pre><code>Backbone: ResNet\nNeck: FPN\nHead: DBHead\n</code></pre></li> </ul>"},{"location":"zh/models/#crnn","title":"\u6587\u672c\u200b\u8bc6\u522b\u200b (CRNN)","text":"<ul> <li>CRNN: \u200b\u7528\u4e8e\u200b\u6587\u672c\u200b\u8bc6\u522b\u200b\u7684\u200b\u6df7\u5408\u200b CNN-RNN \u200b\u6a21\u578b\u200b</li> <li>\u200b\u8f93\u5165\u200b\uff1a\u200b\u88c1\u526a\u200b\u7684\u200b\u6587\u672c\u200b\u533a\u57df\u200b</li> <li>\u200b\u8f93\u51fa\u200b\uff1a\u200b\u8bc6\u522b\u200b\u7684\u200b\u6587\u672c\u200b</li> <li>\u200b\u7279\u70b9\u200b\uff1a<ul> <li>\u200b\u652f\u6301\u200b\u4e2d\u6587\u200b\u548c\u200b\u82f1\u6587\u200b\u5b57\u7b26\u200b</li> <li>\u200b\u5904\u7406\u200b\u53ef\u53d8\u200b\u957f\u5ea6\u200b\u6587\u672c\u200b</li> <li>\u200b\u5bf9\u200b\u4e0d\u540c\u200b\u5b57\u4f53\u200b\u548c\u200b\u6837\u5f0f\u200b\u7684\u200b\u9c81\u68d2\u6027\u200b</li> </ul> </li> <li>\u200b\u67b6\u6784\u200b\uff1a     <pre><code>Backbone: CNN\nNeck: BiLSTM\nHead: CTC\n</code></pre></li> </ul>"},{"location":"zh/models/#_5","title":"\u6587\u672c\u200b\u5206\u7c7b\u200b\u6a21\u578b","text":"<ul> <li>\u200b\u6587\u672c\u200b\u65b9\u5411\u200b\u5206\u7c7b\u5668\u200b: \u200b\u786e\u5b9a\u200b\u6587\u672c\u200b\u65b9\u5411\u200b</li> <li>\u200b\u8f93\u5165\u200b\uff1a\u200b\u6587\u672c\u200b\u533a\u57df\u200b</li> <li>\u200b\u8f93\u51fa\u200b\uff1a\u200b\u65b9\u5411\u200b\u89d2\u5ea6\u200b</li> <li>\u200b\u7279\u70b9\u200b\uff1a<ul> <li>0\u00b0 \u200b\u548c\u200b 180\u00b0 \u200b\u5206\u7c7b\u200b</li> <li>\u200b\u5e2e\u52a9\u200b\u63d0\u9ad8\u200b\u8bc6\u522b\u200b\u51c6\u786e\u6027\u200b</li> </ul> </li> </ul>"},{"location":"zh/models/#_6","title":"\u6a21\u578b\u200b\u6027\u80fd","text":"<ul> <li>\u200b\u5f85\u200b\u66f4\u65b0\u200b</li> </ul>"},{"location":"zh/models/add-model/","title":"\u6dfb\u52a0\u200b\u65b0\u200b\u6a21\u578b","text":"<p>MyOCR \u200b\u7684\u200b\u6a21\u5757\u5316\u200b\u8bbe\u8ba1\u200b\u5141\u8bb8\u200b\u60a8\u200b\u5c06\u200b\u65b0\u200b\u7684\u200b\u6216\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b\u6a21\u578b\u200b\u96c6\u6210\u200b\u5230\u200b\u7cfb\u7edf\u200b\u4e2d\u200b\u3002\u200b\u8be5\u200b\u8fc7\u7a0b\u200b\u53d6\u51b3\u4e8e\u200b\u60a8\u200b\u8981\u200b\u6dfb\u52a0\u200b\u7684\u200b\u6a21\u578b\u200b\u7c7b\u578b\u200b\u3002</p>"},{"location":"zh/models/add-model/#pytorch","title":"\u65b9\u5f0f\u200b\u4e00\u200b\uff1a\u200b\u6dfb\u52a0\u200b\u81ea\u5b9a\u4e49\u200b PyTorch \u200b\u6a21\u578b\u200b\uff08\u200b\u67b6\u6784\u200b\u4e0e\u200b\u6743\u91cd\u200b\uff09","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u6709\u200b\u5728\u200b PyTorch \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff08\u200b\u53ef\u80fd\u200b\u4f7f\u7528\u200b\u6765\u81ea\u200b <code>myocr.modeling</code> \u200b\u6216\u200b\u5916\u90e8\u200b\u5e93\u200b\u7684\u200b\u7ec4\u4ef6\u200b\uff09\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b MyOCR \u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u529f\u80fd\u200b\u5c06\u200b\u5176\u200b\u96c6\u6210\u200b\u3002</p> <ol> <li> <p>\u200b\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b\uff08\u200b\u5982\u679c\u200b\u662f\u200b\u65b0\u200b\u7684\u200b\uff09\uff1a</p> <ul> <li>\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u67b6\u6784\u200b\u5c1a\u672a\u200b\u5b9a\u4e49\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u6309\u7167\u200b <code>myocr/modeling/</code> \u200b\u5185\u200b\u7684\u200b\u7ed3\u6784\u200b\u6765\u200b\u5b9e\u73b0\u200b\u5176\u200b\u7ec4\u4ef6\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u65b0\u200b\u7684\u200b\u4e3b\u5e72\u200b\u7f51\u7edc\u200b\u3001\u200b\u5934\u90e8\u200b\uff09\u3002</li> </ul> </li> <li> <p>\u200b\u521b\u5efa\u200b YAML \u200b\u914d\u7f6e\u200b\uff1a</p> <ul> <li>\u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b <code>.yaml</code> \u200b\u6587\u4ef6\u200b\uff0c\u200b\u5b9a\u4e49\u200b\u60a8\u200b\u7684\u200b\u67b6\u6784\u200b\u7ec4\u4ef6\u200b\u5982\u4f55\u200b\u8fde\u63a5\u200b\u3002\u200b\u8be5\u200b\u6587\u4ef6\u200b\u6307\u5b9a\u200b\u4e3b\u5e72\u200b\u7f51\u7edc\u200b\u3001\u200b\u9888\u90e8\u200b\uff08\u200b\u53ef\u200b\u9009\u200b\uff09\u200b\u548c\u200b\u5934\u90e8\u200b\u7684\u200b\u7c7b\u200b\uff0c\u200b\u4ee5\u53ca\u200b\u5b83\u4eec\u200b\u7684\u200b\u53c2\u6570\u200b\u3002</li> <li>\uff08\u200b\u53ef\u200b\u9009\u200b\uff09\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200b <code>pretrained:</code> \u200b\u952e\u200b\uff0c\u200b\u6307\u5411\u200b\u5305\u542b\u200b\u6574\u4e2a\u200b\u6a21\u578b\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\u7684\u200b <code>.pth</code> \u200b\u6587\u4ef6\u200b\u3002</li> </ul> <pre><code># \u200b\u793a\u4f8b\u200b\uff1a config/my_custom_detector.yaml\nArchitecture:\n  model_type: det\n  backbone:\n    name: YourCustomBackbone # myocr.modeling.backbones \u200b\u4e0b\u200b\u7684\u200b\u7c7b\u540d\u200b\n    param1: value1\n  neck:\n    name: YourCustomNeck\n    param2: value2\n  head:\n    name: YourCustomHead\n    param3: value3\n\npretrained: /path/to/your/custom_model_weights.pth # \u200b\u53ef\u200b\u9009\u200b\uff1a\u200b\u5b8c\u6574\u200b\u7684\u200b\u6a21\u578b\u200b\u6743\u91cd\u200b\n</code></pre> </li> <li> <p>\u200b\u52a0\u8f7d\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200b <code>ModelLoader</code> \u200b\u6216\u200b <code>CustomModel</code> \u200b\u7c7b\u200b\u901a\u8fc7\u200b\u5176\u200b YAML \u200b\u914d\u7f6e\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u3002</li> </ul> <pre><code>from myocr.modeling.model import ModelLoader, Device\n\nloader = ModelLoader()\ndevice = Device('cuda:0')\ncustom_model = loader.load(\n    model_format='custom',\n    model_name_path='config/my_custom_detector.yaml',\n    device=device\n)\n</code></pre> </li> <li> <p>\u200b\u521b\u5efa\u200b\u9884\u6d4b\u5668\u200b\uff08\u200b\u4f7f\u7528\u200b\u5408\u9002\u200b\u7684\u200b\u5904\u7406\u5668\u200b\uff09\uff1a</p> <ul> <li>\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b\u4e0e\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u7684\u200b\u8f93\u5165\u200b\u9884\u5904\u7406\u200b\u548c\u200b\u8f93\u51fa\u200b\u540e\u5904\u7406\u200b\u9700\u6c42\u200b\u76f8\u5339\u914d\u200b\u7684\u200b <code>CompositeProcessor</code>\u3002\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u91cd\u7528\u200b\u73b0\u6709\u200b\u7684\u200b\u5904\u7406\u5668\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u8f93\u51fa\u200b\u7c7b\u4f3c\u200b\uff0c\u200b\u5219\u200b\u4f7f\u7528\u200b <code>TextDetectionProcessor</code>\uff09\uff0c\u200b\u6216\u8005\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u521b\u5efa\u200b\u7ee7\u627f\u200b\u81ea\u200b <code>myocr.base.CompositeProcessor</code> \u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u5904\u7406\u5668\u200b\u7c7b\u200b\u3002</li> </ul> <pre><code># \u200b\u65b9\u5f0f\u200b A\uff1a\u200b\u91cd\u7528\u200b\u73b0\u6709\u200b\u5904\u7406\u5668\u200b\uff08\u200b\u5982\u679c\u200b\u517c\u5bb9\u200b\uff09\nfrom myocr.processors import TextDetectionProcessor\npredictor = custom_model.predictor(TextDetectionProcessor(custom_model.device))\n\n# \u200b\u65b9\u5f0f\u200b B\uff1a\u200b\u521b\u5efa\u200b\u5e76\u200b\u4f7f\u7528\u200b\u81ea\u5b9a\u4e49\u200b\u5904\u7406\u5668\u200b\n# from my_custom_processors import MyCustomProcessor \n# predictor = custom_model.predictor(MyCustomProcessor(...))\n</code></pre> </li> <li> <p>\u200b\u96c6\u6210\u200b\u5230\u200b\u6d41\u6c34\u7ebf\u200b\uff08\u200b\u53ef\u200b\u9009\u200b\uff09\uff1a</p> <ul> <li>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u76f4\u63a5\u200b\u4f7f\u7528\u200b\u60a8\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u9884\u6d4b\u5668\u200b\uff0c\u200b\u6216\u200b\u5c06\u200b\u5176\u200b\u96c6\u6210\u200b\u5230\u200b\u7ee7\u627f\u200b\u81ea\u200b <code>myocr.base.Pipeline</code> \u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b\u7c7b\u4e2d\u200b\u3002</li> </ul> </li> </ol>"},{"location":"zh/models/add-model/#onnx","title":"\u65b9\u5f0f\u200b\u4e8c\u200b\uff1a\u200b\u6dfb\u52a0\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b ONNX \u200b\u6a21\u578b","text":"<p>\u200b\u8fd9\u200b\u662f\u200b\u6700\u200b\u7b80\u5355\u200b\u7684\u200b\u65b9\u6cd5\u200b\uff0c\u200b\u7279\u522b\u200b\u662f\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u9002\u7528\u200b\u4e8e\u200b\u6807\u51c6\u200b\u4efb\u52a1\u200b\u4e4b\u4e00\u200b\uff08\u200b\u68c0\u6d4b\u200b\u3001\u200b\u5206\u7c7b\u200b\u3001\u200b\u8bc6\u522b\u200b\uff09\uff0c\u200b\u5e76\u4e14\u200b\u5176\u200b\u8f93\u5165\u200b/\u200b\u8f93\u51fa\u200b\u683c\u5f0f\u200b\u4e0e\u200b\u73b0\u6709\u200b\u7684\u200b <code>CompositeProcessor</code> \u200b\u7c7b\u200b\u517c\u5bb9\u200b\u3002</p> <ol> <li> <p>\u200b\u653e\u7f6e\u200b\u6a21\u578b\u200b\u6587\u4ef6\u200b\uff1a</p> <ul> <li>\u200b\u5c06\u200b\u60a8\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b <code>.onnx</code> \u200b\u6a21\u578b\u200b\u6587\u4ef6\u200b\u590d\u5236\u5230\u200b\u9ed8\u8ba4\u200b\u6a21\u578b\u200b\u76ee\u5f55\u200b (<code>~/.MyOCR/models/</code>) \u200b\u6216\u200b\u5e94\u7528\u7a0b\u5e8f\u200b\u53ef\u200b\u8bbf\u95ee\u200b\u7684\u200b\u5176\u4ed6\u200b\u4f4d\u7f6e\u200b\u3002</li> </ul> </li> <li> <p>\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b <pre><code>from myocr.modeling.model import ModelLoader, Device\n\n# Load an ONNX model for CPU inference\nloader = ModelLoader()\nonnx_model = loader.load(model_format='onnx', model_name_path='path/to/your/model.onnx', device=Device('cpu'))\n</code></pre> \u200b\u5176\u5b83\u200b\u6b65\u9aa4\u200b\u540c\u200b\u65b9\u5f0f\u200b\u4e00\u200b</p> </li> </ol>"},{"location":"zh/models/add-model/#pytorch_1","title":"\u65b9\u5f0f\u200b\u4e09\u200b\uff1a\u200b\u52a0\u8f7d\u200b\u73b0\u6709\u200b\u7684\u200b PyTorch \u200b\u6a21\u578b","text":"<p>\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u7684\u200b PyTorch \u200b\u6a21\u578b\u200b\u53ca\u5176\u200b\u6743\u91cd\u200b\u975e\u5e38\u7b80\u5355\u200b\uff0c\u200b\u5982\u4e0b\u200b\u6240\u793a\u200b\uff1a</p> <pre><code>from myocr.modeling.model import ModelZoo\nmodel = ModelZoo.load_model(\"pt\", \"resnet152\", \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n</code></pre>"},{"location":"zh/models/train-model/","title":"\u8bad\u7ec3\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b","text":"<p>MyOCR \u200b\u5141\u8bb8\u200b\u4f7f\u7528\u200b\u5176\u200b\u57fa\u4e8e\u200b PyTorch \u200b\u7684\u200b\u5efa\u6a21\u200b\u7ec4\u4ef6\u200b (<code>myocr.modeling</code>) \u200b\u6765\u200b\u8bad\u7ec3\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u3002\u200b\u6838\u5fc3\u601d\u60f3\u200b\u662f\u200b\u5728\u200b\u6807\u51c6\u200b\u7684\u200b PyTorch \u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u4e2d\u200b\u5229\u7528\u200b\u4ece\u200b YAML \u200b\u914d\u7f6e\u200b\u52a0\u8f7d\u200b\u7684\u200b <code>CustomModel</code> \u200b\u7c7b\u200b\u3002</p> <p>\u200b\u514d\u8d23\u200b\u58f0\u660e\u200b: \u200b\u672c\u200b\u6307\u5357\u200b\u6982\u8ff0\u200b\u4e86\u200b\u901a\u7528\u200b\u65b9\u6cd5\u200b\u3002\u200b\u9879\u76ee\u200b\u4e2d\u200b\u5305\u542b\u200b\u7684\u200b <code>myocr/training/</code> \u200b\u76ee\u5f55\u200b\u53ef\u80fd\u200b\u5305\u542b\u200b\u4e3a\u200b MyOCR \u200b\u91cf\u8eab\u200b\u5b9a\u5236\u200b\u7684\u200b\u7279\u5b9a\u200b\u8bad\u7ec3\u200b\u811a\u672c\u200b\u3001\u200b\u5b9e\u7528\u7a0b\u5e8f\u200b\u3001\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u6216\u200b\u6570\u636e\u200b\u96c6\u200b\u5904\u7406\u7a0b\u5e8f\u200b\u3002\u200b\u5728\u200b\u4ece\u5934\u5f00\u59cb\u200b\u7f16\u5199\u200b\u8bad\u7ec3\u200b\u5faa\u73af\u200b\u4e4b\u524d\u200b\uff0c\u200b\u5f3a\u70c8\u5efa\u8bae\u200b\u5148\u200b\u63a2\u7d22\u200b <code>myocr/training/</code> \u200b\u7684\u200b\u5185\u5bb9\u200b\uff0c\u200b\u4ee5\u200b\u4e86\u89e3\u200b\u6846\u67b6\u200b\u7279\u5b9a\u200b\u7684\u200b\u5b9e\u73b0\u200b\u548c\u200b\u8f85\u52a9\u5de5\u5177\u200b\u3002</p>"},{"location":"zh/models/train-model/#1","title":"1. \u200b\u51c6\u5907\u200b\u6570\u636e","text":"<ul> <li>\u200b\u6570\u636e\u200b\u96c6\u200b: \u200b\u60a8\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b\u9002\u7528\u200b\u4e8e\u200b\u60a8\u200b\u4efb\u52a1\u200b\u7684\u200b\u5e26\u200b\u6807\u7b7e\u200b\u6570\u636e\u200b\u96c6\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u7528\u4e8e\u200b OCR \u200b\u7684\u200b\u5e26\u6709\u200b\u8fb9\u754c\u200b\u6846\u200b\u548c\u200b\u8f6c\u5f55\u200b\u6587\u672c\u200b\u7684\u200b\u56fe\u50cf\u200b\uff09\u3002</li> <li>PyTorch Dataset \u200b\u7c7b\u200b: \u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b <code>torch.utils.data.Dataset</code> \u200b\u7c7b\u6765\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b\u56fe\u50cf\u200b\u548c\u200b\u6807\u7b7e\u200b\uff0c\u200b\u5e76\u200b\u6267\u884c\u200b\u5fc5\u8981\u200b\u7684\u200b\u521d\u59cb\u200b\u8f6c\u6362\u200b\u3002</li> <li>DataLoader: \u200b\u4f7f\u7528\u200b <code>torch.utils.data.DataLoader</code> \u200b\u6765\u200b\u521b\u5efa\u200b\u7528\u4e8e\u200b\u8bad\u7ec3\u200b\u548c\u200b\u9a8c\u8bc1\u200b\u7684\u200b\u6570\u636e\u200b\u6279\u6b21\u200b\u3002</li> </ul>"},{"location":"zh/models/train-model/#2-yaml","title":"2. \u200b\u914d\u7f6e\u200b\u6a21\u578b\u200b\u67b6\u6784\u200b (YAML)","text":"<ul> <li>\u200b\u5728\u200b YAML \u200b\u914d\u7f6e\u6587\u4ef6\u200b\uff08\u200b\u4f8b\u5982\u200b <code>config/my_trainable_model.yaml</code>\uff09\u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u60a8\u200b\u8981\u200b\u8bad\u7ec3\u200b\u7684\u200b\u6a21\u578b\u200b\u7684\u200b\u67b6\u6784\u200b\u3002</li> <li>\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4ece\u5934\u5f00\u59cb\u200b\u8bad\u7ec3\u200b\uff0c\u200b\u4e5f\u200b\u53ef\u4ee5\u200b\u4e3a\u200b\u7279\u5b9a\u200b\u7ec4\u4ef6\u200b\u52a0\u8f7d\u200b\u9884\u200b\u8bad\u7ec3\u200b\u6743\u91cd\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5728\u200b YAML \u200b\u7684\u200b <code>backbone</code> \u200b\u90e8\u5206\u200b\u6307\u5b9a\u200b\u7684\u200b\u9884\u200b\u8bad\u7ec3\u200b\u4e3b\u5e72\u200b\u7f51\u7edc\u200b\uff09\u3002</li> </ul>"},{"location":"zh/models/train-model/#3","title":"3. \u200b\u8bbe\u7f6e\u200b\u8bad\u7ec3\u200b\u5faa\u73af","text":"<ul> <li>\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b: \u200b\u4f7f\u7528\u200b <code>ModelLoader</code> \u200b\u4ece\u200b YAML \u200b\u914d\u7f6e\u200b\u52a0\u8f7d\u200b\u60a8\u200b\u7684\u200b <code>CustomModel</code>\u3002</li> <li>\u200b\u5b9a\u4e49\u200b\u635f\u5931\u200b: \u200b\u4e3a\u200b\u60a8\u200b\u7684\u200b\u4efb\u52a1\u200b\u9009\u62e9\u200b\u6216\u200b\u5b9e\u73b0\u200b\u4e00\u4e2a\u200b\u5408\u9002\u200b\u7684\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u7528\u4e8e\u200b\u8bc6\u522b\u200b\u7684\u200b <code>torch.nn.CTCLoss</code>\uff0c\u200b\u57fa\u4e8e\u200b DBNet \u200b\u539f\u7406\u200b\u7684\u200b\u7528\u4e8e\u200b\u68c0\u6d4b\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u635f\u5931\u200b\uff09\u3002\u200b\u68c0\u67e5\u200b <code>myocr/modeling/</code> \u200b\u6216\u200b <code>myocr/training/</code> \u200b\u4e2d\u200b\u53ef\u80fd\u200b\u9884\u5b9a\u200b\u4e49\u200b\u7684\u200b\u635f\u5931\u200b\u51fd\u6570\u200b\u3002</li> <li>\u200b\u5b9a\u4e49\u200b\u4f18\u5316\u200b\u5668\u200b: \u200b\u9009\u62e9\u200b\u4e00\u4e2a\u200b PyTorch \u200b\u4f18\u5316\u200b\u5668\u200b\uff08\u200b\u4f8b\u5982\u200b <code>torch.optim.Adam</code>, <code>SGD</code>\uff09\u3002</li> <li>\u200b\u8bad\u7ec3\u200b\u8bbe\u5907\u200b: \u200b\u8bbe\u7f6e\u200b\u8bbe\u5907\u200b\uff08CPU \u200b\u6216\u200b GPU\uff09\u3002</li> </ul> <pre><code>import torch\nimport torch.optim as optim\nfrom myocr.modeling.model import ModelLoader, Device\n\n# --- \u200b\u914d\u7f6e\u200b ---\nMODEL_CONFIG_PATH = 'config/my_trainable_model.yaml'\nLEARNING_RATE = 1e-4\nNUM_EPOCHS = 50\nOUTPUT_DIR = \"./trained_models\"\n\n# --- \u200b\u8bbe\u7f6e\u200b ---\ndevice = Device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# \u200b\u52a0\u8f7d\u200b\u81ea\u5b9a\u4e49\u200b\u6a21\u578b\u200b\u7ed3\u6784\u200b\nloader = ModelLoader()\nmodel = loader.load(model_format='custom', model_name_path=MODEL_CONFIG_PATH, device=device)\n\n# \u200b\u5b9a\u4e49\u200b\u635f\u5931\u200b\u51fd\u6570\u200b (CTC \u200b\u793a\u4f8b\u200b)\n# criterion = torch.nn.CTCLoss(blank=0).to(device.name) \n# \u200b\u6216\u200b\u67e5\u627e\u200b/\u200b\u5b9e\u73b0\u200b\u60a8\u200b\u7684\u200b\u7279\u5b9a\u200b\u635f\u5931\u200b\ncriterion = ... \n\n# \u200b\u5b9a\u4e49\u200b\u4f18\u5316\u200b\u5668\u200b\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n# \u200b\u53ef\u200b\u9009\u200b: \u200b\u5b66\u4e60\u200b\u7387\u200b\u8c03\u5ea6\u200b\u5668\u200b\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n</code></pre>"},{"location":"zh/models/train-model/#4","title":"4. \u200b\u8fd0\u884c\u200b\u8bad\u7ec3\u200b\u5faa\u73af","text":"<ul> <li>\u200b\u8fed\u4ee3\u200b\u5468\u671f\u200b (epochs) \u200b\u548c\u200b\u6279\u6b21\u200b (batches)\u3002</li> <li>\u200b\u5c06\u200b\u6a21\u578b\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u8bad\u7ec3\u200b\u6a21\u5f0f\u200b (<code>model.train()</code>)\u3002</li> <li>\u200b\u6267\u884c\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\uff0c\u200b\u8ba1\u7b97\u200b\u635f\u5931\u200b\uff0c\u200b\u6267\u884c\u200b\u53cd\u5411\u200b\u4f20\u64ad\u200b\uff0c\u200b\u5e76\u200b\u66f4\u65b0\u200b\u4f18\u5316\u200b\u5668\u200b\u3002</li> <li>\u200b\u5305\u542b\u200b\u4e00\u4e2a\u200b\u4f7f\u7528\u200b <code>model.eval()</code> \u200b\u548c\u200b <code>torch.no_grad()</code> \u200b\u7684\u200b\u9a8c\u8bc1\u200b\u5faa\u73af\u200b\u6765\u200b\u76d1\u63a7\u200b\u6027\u80fd\u200b\u3002</li> <li>\u200b\u5b9a\u671f\u200b\u4fdd\u5b58\u200b\u6a21\u578b\u200b\u68c0\u67e5\u70b9\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u6839\u636e\u200b\u9a8c\u8bc1\u200b\u635f\u5931\u200b\u4fdd\u5b58\u200b\u6027\u80fd\u200b\u6700\u4f73\u200b\u7684\u200b\u6a21\u578b\u200b\uff09\u3002</li> </ul> <pre><code>import os\n\nprint(f\"\u200b\u5728\u200b {device.name} \u200b\u4e0a\u200b\u5f00\u59cb\u200b\u8bad\u7ec3\u200b...\")\ntrainer = Trainer(model,[], nn.CrossEntropyLoss(), optimizer=Adam(model.parameters(), lr=0.001), num_epochs=50, batch_size = 64)\ntrainer.fit(train_dataset, val_dataset)\n\nprint('\u200b\u8bad\u7ec3\u200b\u5b8c\u6210\u200b')\n\n# \u200b\u4fdd\u5b58\u200b\u6700\u7ec8\u200b\u6a21\u578b\u200b\nfinal_model_path = os.path.join(OUTPUT_DIR, \"final_model.pth\")\ntorch.save(model.loaded_model.state_dict(), final_model_path)\nprint(f\"\u200b\u5df2\u200b\u5c06\u200b\u6700\u7ec8\u200b\u6a21\u578b\u200b\u4fdd\u5b58\u200b\u5230\u200b {final_model_path}\")\n</code></pre>"},{"location":"zh/models/train-model/#5","title":"5. \u200b\u8bad\u7ec3\u200b\u540e","text":"<ul> <li>\u200b\u8bc4\u4f30\u200b: \u200b\u5c06\u200b\u60a8\u200b\u4fdd\u5b58\u200b\u7684\u200b\u6743\u91cd\u200b\uff08<code>.pth</code> \u200b\u6587\u4ef6\u200b\uff09\u200b\u52a0\u8f7d\u200b\u5230\u200b <code>CustomModel</code> \u200b\u4e2d\u200b\uff08\u200b\u53ef\u80fd\u200b\u901a\u8fc7\u200b\u5728\u200b YAML \u200b\u914d\u7f6e\u200b\u4e2d\u5c06\u200b <code>pretrained</code> \u200b\u952e\u200b\u8bbe\u7f6e\u200b\u4e3a\u200b\u60a8\u200b\u4fdd\u5b58\u200b\u7684\u200b\u8def\u5f84\u200b\uff09\u200b\u5e76\u200b\u8fd0\u884c\u200b\u8bc4\u4f30\u200b\u3002</li> <li>ONNX \u200b\u5bfc\u51fa\u200b (\u200b\u53ef\u200b\u9009\u200b): \u200b\u4e3a\u4e86\u200b\u4f18\u5316\u200b\u63a8\u7406\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u4f7f\u7528\u200b <code>CustomModel</code> \u200b\u7684\u200b <code>to_onnx</code> \u200b\u65b9\u6cd5\u200b\u5c06\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200b PyTorch \u200b\u6a21\u578b\u200b\u8f6c\u6362\u200b\u4e3a\u200b ONNX \u200b\u683c\u5f0f\u200b\u3002</li> </ul> <p><pre><code># \u200b\u52a0\u8f7d\u200b\u8bad\u7ec3\u200b\u597d\u200b\u7684\u200b\u6a21\u578b\u200b\uff08\u200b\u5047\u8bbe\u200b YAML \u200b\u901a\u8fc7\u200b 'pretrained' \u200b\u952e\u200b\u6307\u5411\u200b\u4fdd\u5b58\u200b\u7684\u200b .pth \u200b\u6587\u4ef6\u200b\uff09\n# trained_model = loader.load('custom', MODEL_CONFIG_PATH, device)\n\n# --- \u200b\u6216\u8005\u200b\u5728\u200b\u52a0\u8f7d\u200b\u67b6\u6784\u200b\u540e\u200b\u624b\u52a8\u200b\u52a0\u8f7d\u200b state dict --- \nmodel_for_export = loader.load('custom', MODEL_CONFIG_PATH, device)\nmodel_for_export.loaded_model.load_state_dict(torch.load(best_model_path, map_location=device.name))\nmodel_for_export.eval()\n\n# \u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u5177\u6709\u200b\u6b63\u786e\u200b\u5f62\u72b6\u200b\u548c\u200b\u7c7b\u578b\u200b\u7684\u200b\u865a\u62df\u200b\u8f93\u5165\u200b\ndummy_input = torch.randn(1, 3, 640, 640).to(device.name) # \u200b\u6839\u636e\u200b\u9700\u8981\u200b\u8c03\u6574\u200b\u5f62\u72b6\u200b\n\nonnx_output_path = os.path.join(OUTPUT_DIR, \"trained_model.onnx\")\n\nmodel_for_export.to_onnx(onnx_output_path, dummy_input)\nprint(f\"\u200b\u5df2\u200b\u5c06\u200b\u6a21\u578b\u200b\u5bfc\u51fa\u200b\u5230\u200b {onnx_output_path}\")\n</code></pre> *   \u200b\u7136\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u6309\u7167\u200b\u6dfb\u52a0\u200b\u65b0\u200b\u6a21\u578b\u200b\u4e2d\u200b\u7684\u200b\u6b65\u9aa4\u200b\u4f7f\u7528\u200b\u8fd9\u4e2a\u200b\u5bfc\u51fa\u200b\u7684\u200b ONNX \u200b\u6a21\u578b\u200b\u3002 </p>"},{"location":"zh/pipelines/","title":"\u6d41\u6c34\u7ebf","text":"<p>MyOCR \u200b\u6d41\u6c34\u7ebf\u200b\u534f\u8c03\u200b\u591a\u4e2a\u200b\u7ec4\u4ef6\u200b\uff08\u200b\u9884\u6d4b\u5668\u200b\u3001\u200b\u6a21\u578b\u200b\uff09\u200b\u6765\u200b\u6267\u884c\u200b\u7aef\u5230\u200b\u7aef\u7684\u200b OCR \u200b\u4efb\u52a1\u200b\u3002\u200b\u5b83\u4eec\u200b\u4e3a\u200b\u5904\u7406\u200b\u56fe\u50cf\u200b\u6216\u200b\u6587\u6863\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u4e00\u4e2a\u200b\u9ad8\u7ea7\u200b\u63a5\u53e3\u200b\u3002</p>"},{"location":"zh/pipelines/#_2","title":"\u53ef\u7528\u200b\u6d41\u6c34\u7ebf","text":""},{"location":"zh/pipelines/#commonocrpipeline","title":"<code>CommonOCRPipeline</code>","text":"<p>\u200b\u5b9a\u4e49\u200b\u5728\u200b <code>myocr/pipelines/common_ocr_pipeline.py</code> \u200b\u4e2d\u200b\u3002</p> <p>\u200b\u6b64\u200b\u6d41\u6c34\u7ebf\u200b\u6267\u884c\u200b\u6807\u51c6\u200b OCR\uff1a\u200b\u6587\u672c\u200b\u68c0\u6d4b\u200b\u3001\u200b\u53ef\u9009\u200b\u7684\u200b\u6587\u672c\u200b\u65b9\u5411\u200b\u5206\u7c7b\u200b\u548c\u200b\u6587\u672c\u200b\u8bc6\u522b\u200b\u3002</p> <p>\u200b\u521d\u59cb\u5316\u200b:</p> <pre><code>from myocr.pipelines import CommonOCRPipeline\nfrom myocr.modeling.model import Device\n\n# \u200b\u521d\u59cb\u5316\u200b\u7528\u4e8e\u200b GPU (\u200b\u6216\u200b 'cpu') \u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\npipeline = CommonOCRPipeline(device=Device('cuda:0'))\n</code></pre> <p>\u200b\u914d\u7f6e\u200b:</p> <p>\u200b\u6d41\u6c34\u7ebf\u200b\u4ece\u200b <code>myocr/pipelines/config/common_ocr_pipeline.yaml</code> \u200b\u52a0\u8f7d\u200b\u914d\u7f6e\u200b\u3002\u200b\u8be5\u200b\u6587\u4ef6\u200b\u6307\u5b9a\u200b\u4e86\u200b\u7528\u4e8e\u200b\u68c0\u6d4b\u200b\u3001\u200b\u5206\u7c7b\u200b\u548c\u200b\u8bc6\u522b\u200b\u7684\u200b ONNX \u200b\u6a21\u578b\u200b\u7684\u200b\u8def\u5f84\u200b\uff0c\u200b\u8fd9\u4e9b\u200b\u8def\u5f84\u200b\u662f\u200b\u76f8\u5bf9\u200b\u4e8e\u200b <code>myocr.config</code> \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\u7684\u200b <code>MODEL_PATH</code> \u200b\u7684\u200b\u3002</p> <pre><code># \u200b\u793a\u4f8b\u200b: myocr/pipelines/config/common_ocr_pipeline.yaml\nmodel:\n  detection: \"dbnet++.onnx\"\n  cls_direction: \"cls.onnx\"\n  recognition: \"rec.onnx\"\n</code></pre> <p>\u200b\u5904\u7406\u200b:</p> <p><code>__call__</code> \u200b\u65b9\u6cd5\u200b\u63a5\u6536\u200b\u4e00\u4e2a\u200b\u56fe\u50cf\u6587\u4ef6\u200b\u7684\u200b\u8def\u5f84\u200b\u3002</p> <pre><code>image_path = 'path/to/your/image.png'\nocr_results = pipeline(image_path)\n\nif ocr_results:\n    # \u200b\u8bbf\u95ee\u200b\u8bc6\u522b\u200b\u7684\u200b\u6587\u672c\u200b\u548c\u200b\u8fb9\u754c\u200b\u6846\u200b\n    print(ocr_results)\n</code></pre> <p>\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b:</p> <ol> <li>\u200b\u52a0\u8f7d\u200b\u56fe\u50cf\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200b <code>TextDetectionPredictor</code> \u200b\u67e5\u627e\u200b\u6587\u672c\u200b\u533a\u57df\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200b <code>TextDirectionPredictor</code> \u200b\u5bf9\u200b\u68c0\u6d4b\u200b\u5230\u200b\u7684\u200b\u533a\u57df\u200b\u8fdb\u884c\u200b\u65b9\u5411\u200b\u5206\u7c7b\u200b\u3002</li> <li>\u200b\u4f7f\u7528\u200b <code>TextRecognitionPredictor</code> \u200b\u8bc6\u522b\u200b\u6bcf\u4e2a\u200b\u5b9a\u5411\u200b\u533a\u57df\u200b\u5185\u200b\u7684\u200b\u6587\u672c\u200b\u3002</li> <li>\u200b\u8fd4\u56de\u200b\u4e00\u4e2a\u200b\u7ed3\u679c\u200b\u5bf9\u8c61\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u542b\u200b\u8fb9\u754c\u200b\u6846\u200b\u3001\u200b\u6587\u672c\u200b\u548c\u200b\u53ef\u80fd\u200b\u7684\u200b\u7f6e\u4fe1\u5ea6\u200b\u5206\u6570\u200b\uff08\u200b\u8be6\u7ec6\u4fe1\u606f\u200b\u53d6\u51b3\u4e8e\u200b <code>Predictor</code> \u200b\u7684\u200b\u5b9e\u73b0\u200b\uff09\u3002</li> </ol>"},{"location":"zh/pipelines/#structuredoutputocrpipeline","title":"<code>StructuredOutputOCRPipeline</code>","text":"<p>\u200b\u5b9a\u4e49\u200b\u5728\u200b <code>myocr/pipelines/structured_output_pipeline.py</code> \u200b\u4e2d\u200b\u3002</p> <p>\u200b\u6b64\u200b\u6d41\u6c34\u7ebf\u200b\u901a\u8fc7\u200b\u6dfb\u52a0\u200b\u4e00\u4e2a\u200b\u6b65\u9aa4\u200b\u6765\u200b\u6269\u5c55\u200b <code>CommonOCRPipeline</code>\uff0c\u200b\u8be5\u200b\u6b65\u9aa4\u200b\u4f7f\u7528\u200b\u5927\u578b\u200b\u8bed\u8a00\u200b\u6a21\u578b\u200b\uff08LLM\uff09\u200b\u901a\u8fc7\u200b <code>OpenAiChatExtractor</code> \u200b\u4ece\u200b\u8bc6\u522b\u200b\u7684\u200b\u6587\u672c\u200b\u4e2d\u200b\u63d0\u53d6\u200b\u7ed3\u6784\u5316\u200b\u4fe1\u606f\u200b\uff08\u200b\u4f8b\u5982\u200b JSON\uff09\u3002</p> <p>\u200b\u521d\u59cb\u5316\u200b:</p> <p>\u200b\u9700\u8981\u200b\u4e00\u4e2a\u200b\u8bbe\u5907\u200b\u548c\u200b\u4e00\u4e2a\u200b\u5b9a\u4e49\u200b\u6240\u200b\u9700\u200b JSON \u200b\u8f93\u51fa\u200b\u6a21\u5f0f\u200b\u7684\u200b Pydantic \u200b\u6a21\u578b\u200b\u3002</p> <pre><code>from myocr.pipelines import StructuredOutputOCRPipeline\nfrom myocr.modeling.model import Device\nfrom pydantic import BaseModel, Field\n\n# \u200b\u5b9a\u4e49\u200b\u60a8\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u8f93\u51fa\u200b\u7ed3\u6784\u200b\nclass InvoiceData(BaseModel):\n    invoice_number: str = Field(description=\"\u200b\u53d1\u7968\u200b\u53f7\u7801\u200b\")\n    total_amount: float = Field(description=\"\u200b\u5e94\u4ed8\u200b\u603b\u989d\u200b\")\n    due_date: str = Field(description=\"\u200b\u4ed8\u6b3e\u200b\u622a\u6b62\u200b\u65e5\u671f\u200b\")\n\n# \u200b\u521d\u59cb\u5316\u200b\u6d41\u6c34\u7ebf\u200b\npipeline = StructuredOutputOCRPipeline(device=Device('cuda:0'), json_schema=InvoiceData)\n</code></pre> <p>\u200b\u914d\u7f6e\u200b:</p> <p>\u200b\u6b64\u200b\u6d41\u6c34\u7ebf\u200b\u4ece\u200b <code>myocr/pipelines/config/structured_output_pipeline.yaml</code> \u200b\u52a0\u8f7d\u200b\u5176\u200b\u7279\u5b9a\u200b\u914d\u7f6e\u200b\uff0c\u200b\u5176\u4e2d\u200b\u5305\u62ec\u200b <code>OpenAiChatExtractor</code> \u200b\u7684\u200b\u8bbe\u7f6e\u200b\uff08LLM \u200b\u6a21\u578b\u200b\u540d\u79f0\u200b\u3001API \u200b\u57fa\u7840\u200b URL\u3001API \u200b\u5bc6\u94a5\u200b\uff09\u3002</p> <pre><code># \u200b\u793a\u4f8b\u200b: myocr/pipelines/config/structured_output_pipeline.yaml\nchat_bot:\n  model: \"gpt-4o\"\n  base_url: \"https://api.openai.com/v1\"\n  api_key: \"YOUR_API_KEY\"\n</code></pre> <p>\u200b\u5904\u7406\u200b:</p> <p><code>__call__</code> \u200b\u65b9\u6cd5\u200b\u63a5\u6536\u200b\u4e00\u4e2a\u200b\u56fe\u50cf\u200b\u8def\u5f84\u200b\u3002</p> <pre><code>image_path = 'path/to/your/invoice.pdf'\nstructured_data = pipeline(image_path)\n\nif structured_data:\n    print(structured_data)\n</code></pre> <p>\u200b\u5de5\u4f5c\u200b\u6d41\u7a0b\u200b:</p> <ol> <li>\u200b\u4f7f\u7528\u200b\u7ee7\u627f\u200b\u7684\u200b <code>CommonOCRPipeline</code> \u200b\u6267\u884c\u200b\u6807\u51c6\u200b OCR \u200b\u4ee5\u200b\u83b7\u53d6\u200b\u539f\u59cb\u200b\u8bc6\u522b\u200b\u6587\u672c\u200b\u3002</li> <li>\u200b\u5982\u679c\u200b\u627e\u5230\u200b\u6587\u672c\u200b\uff0c\u200b\u5219\u200b\u5c06\u200b\u6587\u672c\u200b\u5185\u5bb9\u200b\u4f20\u9012\u200b\u7ed9\u200b <code>OpenAiChatExtractor</code>\u3002</li> <li>\u200b\u63d0\u53d6\u200b\u5668\u200b\u4e0e\u200b\u914d\u7f6e\u200b\u7684\u200b LLM \u200b\u4ea4\u4e92\u200b\uff0c\u200b\u63d0\u4f9b\u200b\u6587\u672c\u200b\u548c\u200b\u6240\u200b\u9700\u200b\u7684\u200b <code>json_schema</code>\uff08Pydantic \u200b\u6a21\u578b\u200b\uff09\u200b\u4f5c\u4e3a\u200b\u6307\u4ee4\u200b\u3002</li> <li>LLM \u200b\u5c1d\u8bd5\u200b\u63d0\u53d6\u200b\u76f8\u5173\u200b\u4fe1\u606f\u200b\u5e76\u200b\u6839\u636e\u200b\u6a21\u5f0f\u200b\u5bf9\u200b\u5176\u200b\u8fdb\u884c\u200b\u683c\u5f0f\u5316\u200b\u3002</li> <li>\u200b\u8fd4\u56de\u200b\u586b\u5145\u200b\u4e86\u200b\u63d0\u53d6\u200b\u6570\u636e\u200b\u7684\u200b\u6240\u200b\u63d0\u4f9b\u200b Pydantic \u200b\u6a21\u578b\u200b\u7684\u200b\u5b9e\u4f8b\u200b\u3002</li> </ol>"},{"location":"zh/pipelines/#_3","title":"\u6027\u80fd\u200b\u4f18\u5316","text":""},{"location":"zh/pipelines/#_4","title":"\u6279\u5904\u7406","text":"<pre><code># \u200b\u5904\u7406\u200b\u591a\u4e2a\u200b\u56fe\u50cf\u200b\nresults = [pipeline(img_path) for img_path in image_paths]\n</code></pre>"},{"location":"zh/pipelines/#gpu","title":"GPU \u200b\u52a0\u901f","text":"<pre><code># \u200b\u4f7f\u7528\u200b GPU \u200b\u8fdb\u884c\u200b\u66f4\u5feb\u200b\u7684\u200b\u5904\u7406\u200b\npipeline = CommonOCRPipeline(\"cuda:0\")\n</code></pre>"},{"location":"zh/pipelines/#_5","title":"\u5185\u5b58\u200b\u7ba1\u7406","text":"<pre><code># \u200b\u6e05\u7406\u200b GPU \u200b\u5185\u5b58\u200b\nimport torch\ntorch.cuda.empty_cache()\n</code></pre>"},{"location":"zh/pipelines/#_6","title":"\u9519\u8bef\u5904\u7406","text":"<p>\u200b\u6d41\u6c34\u7ebf\u200b\u5904\u7406\u200b\u5404\u79cd\u200b\u9519\u8bef\u200b\u60c5\u51b5\u200b\uff1a</p> <ul> <li>\u200b\u65e0\u6548\u200b\u7684\u200b\u56fe\u50cf\u683c\u5f0f\u200b</li> <li>\u200b\u7f3a\u5931\u200b\u7684\u200b\u6a21\u578b\u200b\u6587\u4ef6\u200b</li> <li>GPU \u200b\u5185\u5b58\u4e0d\u8db3\u200b</li> <li>\u200b\u65e0\u6548\u200b\u7684\u200b\u914d\u7f6e\u200b</li> </ul> <p>\u200b\u6709\u5173\u200b\u5e38\u89c1\u95ee\u9898\u200b\u548c\u200b\u89e3\u51b3\u65b9\u6848\u200b\uff0c\u200b\u8bf7\u53c2\u9605\u200b\u6545\u969c\u200b\u6392\u9664\u200b\u6307\u5357\u200b\u3002 </p>"},{"location":"zh/pipelines/build-pipeline/","title":"\u6784\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf","text":"<p>MyOCR \u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u534f\u8c03\u200b\u591a\u4e2a\u200b\u9884\u6d4b\u5668\u200b\u6765\u200b\u6267\u884c\u200b\u590d\u6742\u200b\u7684\u200b\u4efb\u52a1\u200b\u3002\u200b\u867d\u7136\u200b\u5e93\u200b\u63d0\u4f9b\u200b\u4e86\u200b\u50cf\u200b <code>CommonOCRPipeline</code> \u200b\u548c\u200b <code>StructuredOutputOCRPipeline</code> \u200b\u8fd9\u6837\u200b\u7684\u200b\u6807\u51c6\u200b\u6d41\u6c34\u7ebf\u200b\uff0c\u200b\u4f46\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u4e3a\u200b\u7279\u5b9a\u200b\u7684\u200b\u5de5\u4f5c\u200b\u6d41\u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b\uff0c\u200b\u4f8b\u5982\u200b\uff1a</p> <ul> <li>\u200b\u4f7f\u7528\u200b\u4e0d\u540c\u200b\u7684\u200b\u6a21\u578b\u200b\u6216\u200b\u9884\u6d4b\u5668\u200b\u7ec4\u5408\u200b\u3002</li> <li>\u200b\u6dfb\u52a0\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u6216\u200b\u540e\u5904\u7406\u200b\u6b65\u9aa4\u200b\u3002</li> <li>\u200b\u96c6\u6210\u200b\u6807\u51c6\u200b OCR \u200b\u4e4b\u5916\u200b\u7684\u200b\u7ec4\u4ef6\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0cOCR \u200b\u524d\u200b\u7684\u200b\u56fe\u50cf\u589e\u5f3a\u200b\u3001\u200b\u5e03\u5c40\u200b\u5206\u6790\u200b\uff09\u3002</li> <li>\u200b\u5904\u7406\u200b\u4e0d\u540c\u200b\u7684\u200b\u8f93\u5165\u200b/\u200b\u8f93\u51fa\u200b\u7c7b\u578b\u200b\u3002</li> </ul> <p>\u200b\u672c\u200b\u6307\u5357\u200b\u89e3\u91ca\u200b\u4e86\u200b\u6784\u5efa\u200b\u60a8\u200b\u81ea\u5df1\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b\u6b65\u9aa4\u200b\u3002</p>"},{"location":"zh/pipelines/build-pipeline/#1-basepipeline","title":"1. \u200b\u7ee7\u627f\u200b\u81ea\u200b <code>base.Pipeline</code>","text":"<p>\u200b\u6240\u6709\u200b\u6d41\u6c34\u7ebf\u200b\u90fd\u200b\u5e94\u200b\u7ee7\u627f\u200b\u81ea\u200b\u62bd\u8c61\u200b\u57fa\u7c7b\u200b <code>myocr.base.Pipeline</code>\u3002</p>"},{"location":"zh/pipelines/build-pipeline/#2-__init__","title":"2. \u200b\u5728\u200b <code>__init__</code> \u200b\u4e2d\u200b\u521d\u59cb\u5316\u200b\u9884\u6d4b\u5668","text":"<p><code>__init__</code> \u200b\u65b9\u6cd5\u200b\u901a\u5e38\u200b\u662f\u200b\u60a8\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\u5e76\u200b\u521b\u5efa\u200b\u6d41\u6c34\u7ebf\u200b\u5c06\u200b\u4f7f\u7528\u200b\u7684\u200b\u9884\u6d4b\u5668\u200b\u5b9e\u4f8b\u200b\u7684\u200b\u5730\u65b9\u200b\u3002</p> <ul> <li>\u200b\u52a0\u8f7d\u200b\u6a21\u578b\u200b\uff1a \u200b\u4f7f\u7528\u200b <code>myocr.modeling.model.ModelLoader</code> \u200b\u52a0\u8f7d\u200b\u6240\u200b\u9700\u200b\u7684\u200b ONNX \u200b\u6216\u200b\u81ea\u5b9a\u4e49\u200b PyTorch \u200b\u6a21\u578b\u200b\u3002</li> <li>\u200b\u5b9e\u4f8b\u200b\u5316\u200b\u5904\u7406\u5668\u200b\uff1a \u200b\u521b\u5efa\u200b\u6240\u200b\u9700\u200b\u7684\u200b <code>CompositeProcessor</code> \u200b\u7c7b\u200b\u7684\u200b\u5b9e\u4f8b\u200b\uff08\u200b\u4f8b\u5982\u200b <code>TextDetectionProcessor</code>\u3001<code>TextRecognitionProcessor</code> \u200b\u6216\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b\u5904\u7406\u5668\u200b\uff09\u3002</li> <li>\u200b\u521b\u5efa\u200b\u9884\u6d4b\u5668\u200b\uff1a \u200b\u4f7f\u7528\u200b <code>Predictor(processor)</code> \u200b\u65b9\u6cd5\u200b\u7ec4\u5408\u200b\u52a0\u8f7d\u200b\u7684\u200b\u6a21\u578b\u200b\u548c\u200b\u5904\u7406\u5668\u200b\u3002</li> <li>\u200b\u5b58\u50a8\u200b\u9884\u6d4b\u5668\u200b\uff1a \u200b\u5c06\u200b\u521b\u5efa\u200b\u7684\u200b\u9884\u6d4b\u5668\u200b\u5b9e\u4f8b\u200b\u5b58\u50a8\u200b\u4e3a\u200b\u6d41\u6c34\u7ebf\u200b\u7c7b\u200b\u7684\u200b\u5c5e\u6027\u200b\uff08\u200b\u4f8b\u5982\u200b <code>self.det_predictor</code>\uff09\u3002</li> </ul>"},{"location":"zh/pipelines/build-pipeline/#3-process","title":"3. \u200b\u5b9e\u73b0\u200b <code>process</code> \u200b\u65b9\u6cd5","text":"<p>\u200b\u6b64\u200b\u65b9\u6cd5\u200b\u5b9a\u4e49\u200b\u4e86\u200b\u60a8\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b\u6838\u5fc3\u200b\u903b\u8f91\u200b\u3002\u200b\u5b83\u200b\u63a5\u6536\u200b\u8f93\u5165\u200b\u6570\u636e\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u56fe\u50cf\u200b\u8def\u5f84\u200b\u3001PIL \u200b\u56fe\u50cf\u200b\uff09\uff0c\u200b\u6309\u200b\u987a\u5e8f\u8c03\u7528\u200b\u521d\u59cb\u5316\u200b\u7684\u200b\u9884\u6d4b\u5668\u200b\u7684\u200b <code>predict</code> \u200b\u65b9\u6cd5\u200b\uff0c\u200b\u5904\u7406\u200b\u4e2d\u95f4\u200b\u7ed3\u679c\u200b\uff0c\u200b\u5e76\u200b\u8fd4\u56de\u200b\u6700\u7ec8\u200b\u8f93\u51fa\u200b\u3002</p> <pre><code>from PIL import Image\nfrom typing import Optional\nfrom myocr.types import OCRResult # \u200b\u5bfc\u5165\u200b\u5fc5\u8981\u200b\u7684\u200b\u6570\u636e\u7ed3\u6784\u200b\n\nclass MyDetectionOnlyPipeline(Pipeline):\n    def __init__(self, device: Device, detection_model_name: str = \"dbnet++.onnx\"):\n        # ... (\u200b\u4e0a\u200b\u4e00\u6b65\u200b\u7684\u200b\u521d\u59cb\u5316\u200b\u4ee3\u7801\u200b) ...\n        super().__init__()\n        self.device = device\n\n        det_model_path = MODEL_PATH + detection_model_name\n        det_model = ModelLoader().load(\"onnx\", det_model_path, self.device)\n        det_processor = TextDetectionProcessor(det_model.device)\n        self.det_predictor = Predictor(det_processor)\n        logger.info(f\"DetectionOnlyPipeline \u200b\u4f7f\u7528\u200b {detection_model_name} \u200b\u5728\u200b {device.name} \u200b\u4e0a\u200b\u521d\u59cb\u5316\u200b\u5b8c\u6210\u200b\")\n\n    def process(self, image_path: str) -&gt; Optional[OCRResult]:\n        \"\"\"\u200b\u5904\u7406\u200b\u56fe\u50cf\u6587\u4ef6\u200b\u5e76\u200b\u8fd4\u56de\u200b\u68c0\u6d4b\u200b\u5230\u200b\u7684\u200b\u5bf9\u8c61\u200b\u3002\"\"\"\n        # 1. \u200b\u52a0\u8f7d\u200b\u56fe\u50cf\u200b (\u200b\u793a\u4f8b\u200b\uff1a\u200b\u5904\u7406\u200b\u8def\u5f84\u200b\u8f93\u5165\u200b)\n        image = Image.open(image_path).convert(\"RGB\")\n        if image is None:\n            return None\n\n        # 2. \u200b\u8fd0\u884c\u200b\u68c0\u6d4b\u200b\u9884\u6d4b\u5668\u200b\n        detected_objects = self.det_predictor.predict(image)\n\n        # 3. \u200b\u8fd4\u56de\u200b\u7ed3\u679c\u200b\n        if detected_objects:\n            logger.info(f\"\u200b\u68c0\u6d4b\u200b\u6210\u529f\u200b\uff1a\u200b\u627e\u5230\u200b {len(detected_objects.bounding_boxes)} \u200b\u4e2a\u6846\u200b\u3002\")\n        else:\n            logger.info(\"\u200b\u68c0\u6d4b\u200b\u6210\u529f\u200b\uff1a\u200b\u672a\u627e\u5230\u200b\u6587\u672c\u6846\u200b\u3002\")\n\n        return detected_objects # \u200b\u8fd4\u56de\u200b\u68c0\u6d4b\u200b\u9884\u6d4b\u5668\u200b\u7684\u200b\u8f93\u51fa\u200b\n</code></pre>"},{"location":"zh/pipelines/build-pipeline/#4","title":"4. \u200b\u4f7f\u7528\u200b\u60a8\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf","text":"<p>\u200b\u5b9a\u4e49\u200b\u540e\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u50cf\u200b\u4f7f\u7528\u200b\u5185\u7f6e\u200b\u6d41\u6c34\u7ebf\u200b\u4e00\u6837\u200b\u5bfc\u5165\u200b\u548c\u200b\u4f7f\u7528\u200b\u60a8\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b\u3002</p> <pre><code># from your_module import MyDetectionOnlyPipeline # \u200b\u6216\u200b MyFullOCRPipeline\nfrom myocr.modeling.model import Device\n\npipeline = MyDetectionOnlyPipeline(device=Device('cuda:0'))\nresults = pipeline.process('path/to/image.jpg')\n\nif results:\n    # \u200b\u5904\u7406\u200b\u6765\u81ea\u200b\u60a8\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b\u7ed3\u679c\u200b\n    print(f\"\u200b\u627e\u5230\u200b {len(results.bounding_boxes)} \u200b\u4e2a\u200b\u6587\u672c\u200b\u533a\u57df\u200b\u3002\")\n</code></pre> <p>\u200b\u8bf7\u200b\u8bb0\u5f97\u200b\u5728\u200b\u60a8\u200b\u7684\u200b\u6d41\u6c34\u7ebf\u200b\u903b\u8f91\u200b\u4e2d\u200b\u5904\u7406\u200b\u6a21\u578b\u200b\u52a0\u8f7d\u200b\u6216\u200b\u9884\u6d4b\u200b\u6b65\u9aa4\u200b\u4e2d\u200b\u53ef\u80fd\u200b\u51fa\u73b0\u200b\u7684\u200b\u9519\u8bef\u200b\u3002 </p>"},{"location":"zh/predictors/","title":"\u9884\u6d4b\u5668","text":"<p>\u200b\u9884\u6d4b\u5668\u200b\u8d1f\u8d23\u200b\u5904\u7406\u200b MyOCR \u200b\u4e2d\u200b\u7279\u5b9a\u200b\u6a21\u578b\u200b\uff08\u200b\u68c0\u6d4b\u200b\u3001\u200b\u8bc6\u522b\u200b\u3001\u200b\u5206\u7c7b\u200b\uff09\u200b\u7684\u200b\u63a8\u7406\u200b\u903b\u8f91\u200b\u3002\u200b\u5b83\u4eec\u200b\u901a\u8fc7\u200b\u6574\u5408\u200b\u9884\u5904\u7406\u200b\u548c\u200b\u540e\u5904\u7406\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u5f25\u5408\u200b\u4e86\u200b\u539f\u59cb\u200b\u6a21\u578b\u200b\u8f93\u51fa\u200b\u4e0e\u200b\u53ef\u7528\u200b\u7ed3\u679c\u200b\u4e4b\u95f4\u200b\u7684\u200b\u5dee\u8ddd\u200b\u3002</p> <p>\u200b\u9884\u6d4b\u5668\u200b\u901a\u5e38\u200b\u4e0e\u200b\u4e00\u4e2a\u200b <code>Model</code> \u200b\u5bf9\u8c61\u200b\u548c\u200b\u4e00\u4e2a\u200b <code>CompositeProcessor</code> \u200b\u76f8\u5173\u8054\u200b\u3002</p> <ul> <li>\u200b\u6a21\u578b\u200b (Model): \u200b\u63d0\u4f9b\u200b\u6838\u5fc3\u200b\u7684\u200b <code>forward_internal</code> \u200b\u65b9\u6cd5\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0cONNX \u200b\u4f1a\u8bdd\u200b\u8fd0\u884c\u200b\u3001PyTorch \u200b\u6a21\u578b\u200b\u524d\u5411\u200b\u4f20\u64ad\u200b\uff09\u3002</li> <li>CompositeProcessor: \u200b\u5904\u7406\u200b\u5c06\u200b\u8f93\u5165\u200b\u6570\u636e\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6a21\u578b\u200b\u671f\u671b\u200b\u7684\u200b\u683c\u5f0f\u200b\uff0c\u200b\u5e76\u200b\u5c06\u200b\u6a21\u578b\u200b\u7684\u200b\u539f\u59cb\u200b\u8f93\u51fa\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u7ed3\u6784\u5316\u200b\u7684\u200b\u3001\u200b\u6709\u200b\u610f\u4e49\u200b\u7684\u200b\u683c\u5f0f\u200b\u3002</li> </ul>"},{"location":"zh/predictors/#_2","title":"\u57fa\u7840\u200b\u7ec4\u4ef6","text":"<ul> <li><code>myocr.base.Predictor</code>: \u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u5305\u88c5\u200b\u5668\u200b\uff0c\u200b\u8c03\u7528\u200b <code>CompositeProcessor</code> \u200b\u7684\u200b\u8f93\u5165\u200b\u8f6c\u6362\u200b\u3001<code>Model</code> \u200b\u7684\u200b\u524d\u200b\u5411\u200b\u4f20\u64ad\u200b\u4ee5\u53ca\u200b <code>CompositeProcessor</code> \u200b\u7684\u200b\u8f93\u51fa\u200b\u8f6c\u6362\u200b\u3002</li> <li><code>myocr.base.CompositeProcessor</code>: \u200b\u5b9a\u4e49\u200b\u4e86\u200b <code>preprocess</code> \u200b\u548c\u200b <code>postprocess</code> \u200b\u65b9\u6cd5\u200b\u7684\u200b\u62bd\u8c61\u200b\u57fa\u7c7b\u200b\u3002</li> </ul>"},{"location":"zh/predictors/#_3","title":"\u53ef\u7528\u200b\u7684\u200b\u9884\u6d4b\u5668\u200b\u548c\u200b\u5904\u7406\u5668","text":"<p>\u200b\u9884\u6d4b\u5668\u200b\u662f\u200b\u5728\u200b\u52a0\u8f7d\u200b\u7684\u200b <code>Model</code> \u200b\u5b9e\u4f8b\u200b\u4e0a\u200b\u8c03\u7528\u200b <code>Predictor(processor)</code> \u200b\u65b9\u6cd5\u200b\u65f6\u9690\u5f0f\u200b\u521b\u5efa\u200b\u7684\u200b\u3002\u200b\u5173\u952e\u200b\u7ec4\u4ef6\u200b\u662f\u200b <code>CompositeProcessor</code> \u200b\u7684\u200b\u5b9e\u73b0\u200b\uff1a</p>"},{"location":"zh/predictors/#textdetectionprocessor","title":"\u6587\u672c\u200b\u68c0\u6d4b\u200b (<code>TextDetectionProcessor</code>)","text":"<ul> <li>\u200b\u6587\u4ef6\u200b: <code>myocr/processors/text_detection_processor.py</code></li> <li>\u200b\u5173\u8054\u200b\u6a21\u578b\u200b: \u200b\u901a\u5e38\u200b\u662f\u200b DBNet/DBNet++ ONNX \u200b\u6a21\u578b\u200b\u3002</li> </ul>"},{"location":"zh/predictors/#textdirectionprocessor","title":"\u6587\u672c\u200b\u65b9\u5411\u200b\u5206\u7c7b\u200b (<code>TextDirectionProcessor</code>)","text":"<ul> <li>\u200b\u6587\u4ef6\u200b: <code>myocr/processors/text_direction_processor.py</code></li> <li>\u200b\u5173\u8054\u200b\u6a21\u578b\u200b: \u200b\u901a\u5e38\u200b\u662f\u200b\u7b80\u5355\u200b\u7684\u200b CNN \u200b\u5206\u7c7b\u5668\u200b ONNX \u200b\u6a21\u578b\u200b\u3002</li> </ul>"},{"location":"zh/predictors/#textrecognitionprocessor","title":"\u6587\u672c\u200b\u8bc6\u522b\u200b (<code>TextRecognitionProcessor</code>)","text":"<ul> <li>\u200b\u6587\u4ef6\u200b: <code>myocr/processors/text_recognition_processor.py</code></li> <li>\u200b\u5173\u8054\u200b\u6a21\u578b\u200b: \u200b\u901a\u5e38\u200b\u662f\u200b\u57fa\u4e8e\u200b CRNN \u200b\u7684\u200b ONNX \u200b\u6a21\u578b\u200b\u3002</li> </ul>"},{"location":"zh/predictors/#_4","title":"\u6027\u80fd\u200b\u63d0\u793a","text":""},{"location":"zh/predictors/#_5","title":"\u6279\u5904\u7406","text":"<pre><code># \u200b\u5904\u7406\u200b\u591a\u4e2a\u200b\u533a\u57df\u200b\nresults = [predictor.predict(region) for region in regions]\n</code></pre>"},{"location":"zh/predictors/create-predictor/","title":"\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u9884\u6d4b\u5668","text":"<p>MyOCR \u200b\u4e2d\u200b\u7684\u200b\u9884\u6d4b\u5668\u200b\u5145\u5f53\u200b\u5df2\u200b\u52a0\u8f7d\u200b <code>Model</code>\uff08ONNX \u200b\u6216\u200b PyTorch\uff09\u200b\u4e0e\u200b\u6700\u7ec8\u7528\u6237\u200b\u6216\u200b\u6d41\u6c34\u7ebf\u200b\u4e4b\u95f4\u200b\u7684\u200b\u6865\u6881\u200b\u3002\u200b\u5b83\u4eec\u200b\u5c01\u88c5\u200b\u4e86\u200b\u5fc5\u8981\u200b\u7684\u200b\u9884\u5904\u7406\u200b\u548c\u200b\u540e\u5904\u7406\u200b\u903b\u8f91\u200b\uff0c\u200b\u4ee5\u4fbf\u200b\u6a21\u578b\u200b\u80fd\u591f\u200b\u8f7b\u677e\u200b\u5730\u200b\u7528\u4e8e\u200b\u7279\u5b9a\u200b\u4efb\u52a1\u200b\u3002</p> <p>\u200b\u867d\u7136\u200b MyOCR \u200b\u63d0\u4f9b\u200b\u4e86\u200b\u6807\u51c6\u200b\u9884\u6d4b\u5668\u200b\uff08\u200b\u901a\u8fc7\u200b <code>TextDetectionProcessor</code>\u3001<code>TextRecognitionProcessor</code> \u200b\u7b49\u200b\u5904\u7406\u5668\u200b\uff09\uff0c\u200b\u4f46\u200b\u5728\u200b\u4ee5\u4e0b\u200b\u60c5\u51b5\u200b\u4e0b\u200b\uff0c\u200b\u60a8\u200b\u53ef\u80fd\u200b\u9700\u8981\u200b\u81ea\u5b9a\u4e49\u200b\u9884\u6d4b\u5668\u200b\uff1a</p> <ul> <li>\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u9700\u8981\u200b\u72ec\u7279\u200b\u7684\u200b\u8f93\u5165\u200b\u9884\u5904\u7406\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4e0d\u540c\u200b\u7684\u200b\u5f52\u4e00\u5316\u200b\u3001\u200b\u8c03\u6574\u200b\u5927\u5c0f\u200b\u3001\u200b\u8f93\u5165\u200b\u683c\u5f0f\u200b\uff09\u3002</li> <li>\u200b\u60a8\u200b\u7684\u200b\u6a21\u578b\u200b\u4ea7\u751f\u200b\u7684\u200b\u8f93\u51fa\u200b\u9700\u8981\u200b\u81ea\u5b9a\u4e49\u200b\u89e3\u7801\u200b\u6216\u200b\u683c\u5f0f\u5316\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u4e0d\u540c\u200b\u7684\u200b\u8fb9\u754c\u200b\u6846\u200b\u683c\u5f0f\u200b\u3001\u200b\u4e13\u95e8\u200b\u7684\u200b\u5206\u7c7b\u200b\u6807\u7b7e\u200b\u3001\u200b\u73b0\u6709\u200b\u6d41\u6c34\u7ebf\u200b\u65e0\u6cd5\u200b\u5904\u7406\u200b\u7684\u200b\u7ed3\u6784\u5316\u200b\u8f93\u51fa\u200b\uff09\u3002</li> <li>\u200b\u60a8\u200b\u60f3\u200b\u4e3a\u200b\u68c0\u6d4b\u200b\u3001\u200b\u8bc6\u522b\u200b\u6216\u200b\u5206\u7c7b\u200b\u4e4b\u5916\u200b\u7684\u200b\u5168\u65b0\u200b\u4efb\u52a1\u200b\u521b\u5efa\u200b\u9884\u6d4b\u5668\u200b\u3002</li> </ul> <p>\u200b\u6784\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u9884\u6d4b\u5668\u200b\u7684\u200b\u5173\u952e\u200b\u662f\u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b\u7684\u200b <code>CompositeProcessor</code> \u200b\u7c7b\u200b\u3002</p>"},{"location":"zh/predictors/create-predictor/#1-compositeprocessor","title":"1. \u200b\u7406\u89e3\u200b <code>CompositeProcessor</code> \u200b\u7684\u200b\u4f5c\u7528","text":"<p>\u200b\u9884\u6d4b\u5668\u200b\u672c\u8eab\u200b\u662f\u200b\u4e00\u4e2a\u200b\u7b80\u5355\u200b\u7684\u200b\u5305\u88c5\u200b\u5668\u200b\uff08\u200b\u5728\u200b <code>myocr.base.Predictor</code> \u200b\u4e2d\u200b\u5b9a\u4e49\u200b\uff09\u3002\u200b\u5b9e\u9645\u200b\u5de5\u4f5c\u200b\u5728\u200b\u5176\u200b\u5173\u8054\u200b\u7684\u200b <code>CompositeProcessor</code>\uff08\u200b\u7ee7\u627f\u200b\u81ea\u200b <code>myocr.base.CompositeProcessor</code> \u200b\u7684\u200b\u7c7b\u200b\uff09\u200b\u4e2d\u200b\u8fdb\u884c\u200b\u3002\u200b\u5904\u7406\u5668\u200b\u4e3b\u8981\u200b\u6709\u200b\u4e24\u4e2a\u200b\u4efb\u52a1\u200b\uff1a</p> <ol> <li><code>preprocess(user_input)</code>: \u200b\u63a5\u6536\u200b\u7528\u6237\u200b\u6216\u200b\u6d41\u6c34\u7ebf\u200b\u63d0\u4f9b\u200b\u7684\u200b\u6570\u636e\u200b\uff08\u200b\u4f8b\u5982\u200b PIL \u200b\u56fe\u50cf\u200b\uff09\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6a21\u578b\u200b\u63a8\u7406\u65b9\u6cd5\u200b\u6240\u200b\u671f\u671b\u200b\u7684\u200b\u7cbe\u786e\u200b\u683c\u5f0f\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5f52\u4e00\u5316\u200b\u7684\u200b\u3001\u200b\u5177\u6709\u200b\u6279\u6b21\u200b\u7ef4\u5ea6\u200b\u7684\u200b NumPy \u200b\u6570\u7ec4\u200b\uff09\u3002</li> <li><code>postprocess(model_output)</code>: \u200b\u63a5\u6536\u200b\u6a21\u578b\u200b\u7684\u200b\u539f\u59cb\u200b\u63a8\u7406\u200b\u8f93\u51fa\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u8868\u793a\u200b\u70ed\u200b\u529b\u56fe\u200b\u6216\u200b\u5e8f\u5217\u200b\u6982\u7387\u200b\u7684\u200b NumPy \u200b\u6570\u7ec4\u200b\uff09\uff0c\u200b\u5e76\u200b\u5c06\u200b\u5176\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u7528\u6237\u200b\u53cb\u597d\u200b\u7684\u200b\u3001\u200b\u7ed3\u6784\u5316\u200b\u7684\u200b\u683c\u5f0f\u200b\uff08\u200b\u4f8b\u5982\u200b\uff0c\u200b\u5e26\u6709\u200b\u6587\u672c\u200b\u548c\u200b\u5206\u6570\u200b\u7684\u200b\u8fb9\u754c\u200b\u6846\u200b\u5217\u8868\u200b\uff0c\u200b\u5982\u200b <code>TextRegion</code>\uff09\u3002</li> </ol>"},{"location":"zh/predictors/create-predictor/#2-compositeprocessor","title":"2. \u200b\u521b\u5efa\u200b\u81ea\u5b9a\u4e49\u200b <code>CompositeProcessor</code> \u200b\u7c7b","text":"<ol> <li>\u200b\u7ee7\u627f\u200b: \u200b\u521b\u5efa\u200b\u4e00\u4e2a\u200b\u7ee7\u627f\u200b\u81ea\u200b <code>myocr.base.CompositeProcessor</code> \u200b\u7684\u200b Python \u200b\u7c7b\u200b\u3002</li> <li>\u200b\u6307\u5b9a\u200b\u7c7b\u578b\u200b (\u200b\u53ef\u9009\u200b\u4f46\u200b\u63a8\u8350\u200b): \u200b\u4f7f\u7528\u200b\u6cdb\u578b\u200b\u6765\u200b\u6307\u793a\u200b <code>preprocess</code> \u200b\u7684\u200b\u9884\u671f\u200b\u8f93\u5165\u200b\u7c7b\u578b\u200b\u548c\u200b <code>postprocess</code> \u200b\u7684\u200b\u8f93\u51fa\u200b\u7c7b\u578b\u200b\u3002\u200b\u4f8b\u5982\u200b\uff0c<code>CompositeProcessor[PIL.Image.Image, List[RectBoundingBox]]</code> \u200b\u8868\u793a\u200b\u5b83\u200b\u63a5\u6536\u200b PIL \u200b\u56fe\u50cf\u200b\u5e76\u200b\u8fd4\u56de\u200b <code>List[RectBoundingBox]</code>\u3002</li> <li>\u200b\u5b9e\u73b0\u200b <code>__init__</code>: \u200b\u521d\u59cb\u5316\u200b\u4efb\u4f55\u200b\u5fc5\u8981\u200b\u7684\u200b\u53c2\u6570\u200b\uff0c\u200b\u4f8b\u5982\u200b\u9608\u503c\u200b\u3001\u200b\u6807\u7b7e\u200b\u6620\u5c04\u200b\u6216\u200b\u8f6c\u6362\u200b\u671f\u95f4\u200b\u9700\u8981\u200b\u7684\u200b\u5f15\u7528\u200b\u3002</li> <li>\u200b\u5b9e\u73b0\u200b <code>preprocess</code>: \u200b\u7f16\u5199\u200b\u4ee3\u7801\u200b\u5c06\u200b\u8f93\u5165\u200b\u6570\u636e\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6a21\u578b\u200b\u5c31\u7eea\u200b\u683c\u5f0f\u200b\u3002</li> <li>\u200b\u5b9e\u73b0\u200b <code>postprocess</code>: \u200b\u7f16\u5199\u200b\u4ee3\u7801\u200b\u5c06\u200b\u539f\u59cb\u200b\u6a21\u578b\u200b\u8f93\u51fa\u200b\u8f6c\u6362\u200b\u4e3a\u200b\u6240\u200b\u9700\u200b\u7684\u200b\u7ed3\u6784\u5316\u200b\u7ed3\u679c\u200b\u3002</li> </ol> <p>\u200b\u6ce8\u610f\u200b\uff1a\u200b\u5177\u4f53\u200b\u4ee3\u7801\u200b\u8bf7\u200b\u53c2\u8003\u200b\u5df2\u6709\u200b\u9884\u6d4b\u5668\u200b</p>"},{"location":"zh/predictors/create-predictor/#3","title":"3. \u200b\u521b\u5efa\u200b\u9884\u6d4b\u5668\u200b\u5b9e\u4f8b","text":"<p>\u200b\u4e00\u65e6\u200b\u60a8\u200b\u6709\u200b\u4e86\u200b\u81ea\u5b9a\u4e49\u200b <code>CompositeProcessor</code> \u200b\u5e76\u200b\u52a0\u8f7d\u200b\u4e86\u200b\u6a21\u578b\u200b\uff0c\u200b\u5c31\u200b\u53ef\u4ee5\u200b\u521b\u5efa\u200b\u9884\u6d4b\u5668\u200b\u5b9e\u4f8b\u200b\u3002</p>"},{"location":"zh/predictors/create-predictor/#4","title":"4. \u200b\u96c6\u6210\u200b\u5230\u200b\u6d41\u6c34\u7ebf\u200b (\u200b\u53ef\u200b\u9009\u200b)","text":"<p>\u200b\u5982\u679c\u200b\u60a8\u200b\u7684\u200b\u81ea\u5b9a\u4e49\u200b\u9884\u6d4b\u5668\u200b\u662f\u200b\u66f4\u200b\u5927\u200b\u5de5\u4f5c\u200b\u6d41\u200b\u7684\u200b\u4e00\u90e8\u5206\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5c06\u200b\u5176\u200b\u96c6\u6210\u200b\u5230\u200b \u200b\u81ea\u5b9a\u4e49\u200b\u6d41\u6c34\u7ebf\u200b \u200b\u4e2d\u200b\uff0c\u200b\u65b9\u6cd5\u200b\u662f\u200b\u5728\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b <code>__init__</code> \u200b\u65b9\u6cd5\u200b\u4e2d\u200b\u521d\u59cb\u5316\u200b\u5b83\u200b\uff0c\u200b\u5e76\u200b\u5728\u200b\u6d41\u6c34\u7ebf\u200b\u7684\u200b <code>process</code> \u200b\u65b9\u6cd5\u200b\u4e2d\u200b\u8c03\u7528\u200b\u5176\u200b <code>predict</code> \u200b\u65b9\u6cd5\u200b\u3002</p> <p>\u200b\u901a\u8fc7\u200b\u8fd9\u4e9b\u200b\u6b65\u9aa4\u200b\uff0c\u200b\u60a8\u200b\u53ef\u4ee5\u200b\u5728\u200b MyOCR \u200b\u6846\u67b6\u200b\u5185\u200b\u521b\u5efa\u200b\u9488\u5bf9\u200b\u7279\u5b9a\u200b\u6a21\u578b\u200b\u548c\u200b\u4efb\u52a1\u200b\u7684\u200b\u9884\u6d4b\u5668\u200b\u3002 </p>"}]}